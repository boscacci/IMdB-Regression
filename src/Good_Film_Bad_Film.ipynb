{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good Film // Bad Film\n",
    "## Regression for Box Office Revenue and IMdB Critic Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook builds and evaluates a handful of regression models which predict critical reception scores for films. Independent variables include plot synopsis free text, social media metrics on the leading actors, and other categorical variables such as film genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:00.245407Z",
     "start_time": "2020-04-07T01:11:00.239537Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Data Wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "# Viz\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# Python Extras\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "from unicodedata import normalize\n",
    "\n",
    "# API Calls and Parsing\n",
    "import requests\n",
    "from pycountry import languages\n",
    "\n",
    "# NLP Tools\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Model Building and Prep\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import mean_squared_error, median_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From https://www.kaggle.com/tmdb/tmdb-movie-metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:00.273372Z",
     "start_time": "2020-04-07T01:11:00.247461Z"
    }
   },
   "outputs": [],
   "source": [
    "kaggle_data = pd.read_csv('../data/imdb_5000_movies.csv') # Just a big Kaggle dataset full of movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:00.278981Z",
     "start_time": "2020-04-07T01:11:00.274614Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5043, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Metadata from TheMovieDB.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One good thing about this dataset is that it provides the unique IMdB movie ID's, which we can pass to a third-party API in order to supplement our data with more features. Here we parse out those IMdB ID's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:00.301058Z",
     "start_time": "2020-04-07T01:11:00.280095Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>director_name</th>\n",
       "      <th>num_critic_for_reviews</th>\n",
       "      <th>duration</th>\n",
       "      <th>director_facebook_likes</th>\n",
       "      <th>actor_3_facebook_likes</th>\n",
       "      <th>actor_2_name</th>\n",
       "      <th>actor_1_facebook_likes</th>\n",
       "      <th>gross</th>\n",
       "      <th>genres</th>\n",
       "      <th>...</th>\n",
       "      <th>num_user_for_reviews</th>\n",
       "      <th>language</th>\n",
       "      <th>country</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>budget</th>\n",
       "      <th>title_year</th>\n",
       "      <th>actor_2_facebook_likes</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>movie_facebook_likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5038</th>\n",
       "      <td>Color</td>\n",
       "      <td>Scott Smith</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>Daphne Zuniga</td>\n",
       "      <td>637.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>English</td>\n",
       "      <td>Canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5039</th>\n",
       "      <td>Color</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>319.0</td>\n",
       "      <td>Valorie Curry</td>\n",
       "      <td>841.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Crime|Drama|Mystery|Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>359.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>593.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>16.00</td>\n",
       "      <td>32000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5040</th>\n",
       "      <td>Color</td>\n",
       "      <td>Benjamin Roberds</td>\n",
       "      <td>13.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maxwell Moody</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drama|Horror|Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5041</th>\n",
       "      <td>Color</td>\n",
       "      <td>Daniel Hsia</td>\n",
       "      <td>14.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>Daniel Henney</td>\n",
       "      <td>946.0</td>\n",
       "      <td>10443.0</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>719.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.35</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5042</th>\n",
       "      <td>Color</td>\n",
       "      <td>Jon Gunn</td>\n",
       "      <td>43.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Brian Herzlinger</td>\n",
       "      <td>86.0</td>\n",
       "      <td>85222.0</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>...</td>\n",
       "      <td>84.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1.85</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      color     director_name  num_critic_for_reviews  duration  \\\n",
       "5038  Color       Scott Smith                     1.0      87.0   \n",
       "5039  Color               NaN                    43.0      43.0   \n",
       "5040  Color  Benjamin Roberds                    13.0      76.0   \n",
       "5041  Color       Daniel Hsia                    14.0     100.0   \n",
       "5042  Color          Jon Gunn                    43.0      90.0   \n",
       "\n",
       "      director_facebook_likes  actor_3_facebook_likes      actor_2_name  \\\n",
       "5038                      2.0                   318.0     Daphne Zuniga   \n",
       "5039                      NaN                   319.0     Valorie Curry   \n",
       "5040                      0.0                     0.0     Maxwell Moody   \n",
       "5041                      0.0                   489.0     Daniel Henney   \n",
       "5042                     16.0                    16.0  Brian Herzlinger   \n",
       "\n",
       "      actor_1_facebook_likes    gross                        genres  ...  \\\n",
       "5038                   637.0      NaN                  Comedy|Drama  ...   \n",
       "5039                   841.0      NaN  Crime|Drama|Mystery|Thriller  ...   \n",
       "5040                     0.0      NaN         Drama|Horror|Thriller  ...   \n",
       "5041                   946.0  10443.0          Comedy|Drama|Romance  ...   \n",
       "5042                    86.0  85222.0                   Documentary  ...   \n",
       "\n",
       "     num_user_for_reviews language  country  content_rating  budget  \\\n",
       "5038                  6.0  English   Canada             NaN     NaN   \n",
       "5039                359.0  English      USA           TV-14     NaN   \n",
       "5040                  3.0  English      USA             NaN  1400.0   \n",
       "5041                  9.0  English      USA           PG-13     NaN   \n",
       "5042                 84.0  English      USA              PG  1100.0   \n",
       "\n",
       "      title_year actor_2_facebook_likes imdb_score  aspect_ratio  \\\n",
       "5038      2013.0                  470.0        7.7           NaN   \n",
       "5039         NaN                  593.0        7.5         16.00   \n",
       "5040      2013.0                    0.0        6.3           NaN   \n",
       "5041      2012.0                  719.0        6.3          2.35   \n",
       "5042      2004.0                   23.0        6.6          1.85   \n",
       "\n",
       "     movie_facebook_likes  \n",
       "5038                   84  \n",
       "5039                32000  \n",
       "5040                   16  \n",
       "5041                  660  \n",
       "5042                  456  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab IMdB ID numbers for each film and append to dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:00.306106Z",
     "start_time": "2020-04-07T01:11:00.302109Z"
    }
   },
   "outputs": [],
   "source": [
    "imdb_ids = kaggle_data['movie_imdb_link'].str[26:35]\n",
    "# imdb_ids[3000:3005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:00.310073Z",
     "start_time": "2020-04-07T01:11:00.307260Z"
    }
   },
   "outputs": [],
   "source": [
    "kaggle_data['imdb_ids'] = imdb_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we make the API calls, and persist our data to little .json files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:00.314222Z",
     "start_time": "2020-04-07T01:11:00.312112Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('../data/movie_metadata')\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__This will make lots of API calls, be warned and use sparingly__, to avoid burning out your API key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to enter your own API key in the API_KEY.py file (remove the .template suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:00.317605Z",
     "start_time": "2020-04-07T01:11:00.315610Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from API_KEY import API_KEY\n",
    "# i=0; j=0; total=len(imdb_ids)\n",
    "\n",
    "# for id in imdb_ids:\n",
    "#     print(f\"Downloading movie {i} of {total}...\")\n",
    "#     i+=1\n",
    "#     query_string = f'https://api.themoviedb.org/3/movie/{id}?api_key={API_KEY}'\n",
    "#     json = requests.get(query_string).text\n",
    "#     if \"could not be found\" in json:\n",
    "#         j+=1\n",
    "#         print(f\"{round(j/i, 2)}% of movies not found\")\n",
    "#         continue\n",
    "#     f = open(f'../data/movie_metadata/movie_{id}.json', 'w+')\n",
    "#     f.write(json)\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Kaggle Dataset and TheMovieDB API Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.831040Z",
     "start_time": "2020-04-07T01:11:00.318728Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-336a4110d86e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"movie\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mthis_movie\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"../data/movie_metadata/{filename}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtmdb_movies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthis_movie\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtmdb_movies\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtmdb_movies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmdb_movies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Good-Film-Bad-Film-vaMlpeB4/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Good-Film-Bad-Film-vaMlpeB4/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             new_data = concatenate_block_managers(\n\u001b[0;32m--> 497\u001b[0;31m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m             )\n\u001b[1;32m    499\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Good-Film-Bad-Film-vaMlpeB4/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m   2020\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2021\u001b[0m             b = make_block(\n\u001b[0;32m-> 2022\u001b[0;31m                 \u001b[0mconcatenate_join_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2023\u001b[0m                 \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2024\u001b[0m             )\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Good-Film-Bad-Film-vaMlpeB4/lib/python3.7/site-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36mconcatenate_join_units\u001b[0;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[1;32m    246\u001b[0m     to_concat = [\n\u001b[1;32m    247\u001b[0m         \u001b[0mju\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_reindexed_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupcasted_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupcasted_na\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mju\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     ]\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Good-Film-Bad-Film-vaMlpeB4/lib/python3.7/site-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    246\u001b[0m     to_concat = [\n\u001b[1;32m    247\u001b[0m         \u001b[0mju\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_reindexed_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupcasted_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupcasted_na\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mju\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     ]\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Good-Film-Bad-Film-vaMlpeB4/lib/python3.7/site-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36mget_reindexed_values\u001b[0;34m(self, empty_dtype, upcasted_na)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Good-Film-Bad-Film-vaMlpeB4/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m   1619\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1620\u001b[0m                 \u001b[0;31m# check if promotion is actually required based on indexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1622\u001b[0m                 \u001b[0mneeds_masking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m                 \u001b[0mmask_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_masking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tmdb_movies = pd.DataFrame()\n",
    "\n",
    "for filename in os.listdir(path='../data/movie_metadata/'):\n",
    "    if \"movie\" in filename:\n",
    "        this_movie = pd.read_json(f\"../data/movie_metadata/{filename}\", lines=True)\n",
    "        tmdb_movies = pd.concat([this_movie,tmdb_movies], axis=0)\n",
    "\n",
    "tmdb_movies = tmdb_movies.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.922026Z",
     "start_time": "2020-04-07T01:10:59.510Z"
    }
   },
   "outputs": [],
   "source": [
    "df_merged = tmdb_movies.merge(kaggle_data, \n",
    "                              how='left',\n",
    "                              left_on='imdb_id',\n",
    "                              right_on='imdb_ids',\n",
    "                              suffixes=(\"_kaggle\",\"_api\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.923414Z",
     "start_time": "2020-04-07T01:10:59.531Z"
    }
   },
   "outputs": [],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep only interesting columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.924152Z",
     "start_time": "2020-04-07T01:10:59.551Z"
    }
   },
   "outputs": [],
   "source": [
    "df_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.925142Z",
     "start_time": "2020-04-07T01:10:59.571Z"
    }
   },
   "outputs": [],
   "source": [
    "desired_cols = (\"imdb_id duration adult budget_api budget_kaggle language original_language \"\n",
    "                \"production_countries runtime spoken_languages color genres_api \"\n",
    "                \"title movie_title original_title overview content_rating \"\n",
    "                \"actor_1_facebook_likes actor_2_facebook_likes actor_3_facebook_likes \"\n",
    "                \"director_facebook_likes cast_total_facebook_likes facenumber_in_poster \"\n",
    "                \"aspect_ratio imdb_score revenue\").split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.925898Z",
     "start_time": "2020-04-07T01:10:59.589Z"
    }
   },
   "outputs": [],
   "source": [
    "df_lesscols = df_merged[desired_cols]\n",
    "df_lesscols.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.926627Z",
     "start_time": "2020-04-07T01:10:59.608Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_lesscols[\n",
    "    df_lesscols.imdb_id.duplicated(keep=False)\n",
    "].sort_values('imdb_id')[\n",
    "    \"imdb_id duration title language\".split()\n",
    "].head(51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.927301Z",
     "start_time": "2020-04-07T01:10:59.640Z"
    }
   },
   "outputs": [],
   "source": [
    "df_lesscols[\n",
    "    df_lesscols.imdb_id.duplicated(keep=False)\n",
    "].sort_values('imdb_id')[\n",
    "    \"imdb_id duration title language\".split()\n",
    "].tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.928032Z",
     "start_time": "2020-04-07T01:10:59.658Z"
    }
   },
   "outputs": [],
   "source": [
    "df_lesscols = df_lesscols.drop_duplicates(subset='imdb_id').set_index(\"imdb_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.929250Z",
     "start_time": "2020-04-07T01:10:59.674Z"
    }
   },
   "outputs": [],
   "source": [
    "df_lesscols.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null Values Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are all of the truly \"null\" values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.930447Z",
     "start_time": "2020-04-07T01:10:59.743Z"
    }
   },
   "outputs": [],
   "source": [
    "nulls = df_lesscols.isna().sum()[df_lesscols.isna().sum() > 0].sort_values(ascending=False)\n",
    "\n",
    "nulls.plot(kind='bar', figsize=(15,8)).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gotta start somewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Budget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two disparate budget columns to draw from. We want whatever seems most plausible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.933179Z",
     "start_time": "2020-04-07T01:10:59.769Z"
    }
   },
   "outputs": [],
   "source": [
    "df_lesscols[[\"budget_api\", \"budget_kaggle\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of nulls in budget_api, lots of zeroes in budget_kaggle. How best to handle this? And are there other columns where we just have a bunch of zero values instead of nulls (revenue??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.934412Z",
     "start_time": "2020-04-07T01:10:59.788Z"
    }
   },
   "outputs": [],
   "source": [
    "def best_guess_budget(row):\n",
    "    # When budget_api is NaN and budget_kaggle is non-zero, take budget_kaggle.\n",
    "    if row.isna()[\"budget_api\"] and row['budget_kaggle'] != 0:\n",
    "        return row['budget_kaggle']\n",
    "    \n",
    "    # When budget_api is not NaN but budget_kaggle is zero, take budget_api.\n",
    "    elif not row.isna()[\"budget_api\"] and row['budget_kaggle'] == 0:\n",
    "        return row['budget_api']\n",
    "    \n",
    "    # When both values are not NaN / non-zero, take the mean?\n",
    "    elif not row.isna()[\"budget_api\"] and row['budget_kaggle'] != 0:\n",
    "        return np.mean((row['budget_kaggle'], row['budget_api']))\n",
    "        \n",
    "    # When budget_api is NaN AND budget_kaggle is zero...that's tough. Maybe drop row. Consider imputing values?\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.935698Z",
     "start_time": "2020-04-07T01:10:59.804Z"
    }
   },
   "outputs": [],
   "source": [
    "df_lesscols.head(10).apply(best_guess_budget, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the desired behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.936838Z",
     "start_time": "2020-04-07T01:10:59.823Z"
    }
   },
   "outputs": [],
   "source": [
    "best_budget = df_lesscols.apply(best_guess_budget, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.937737Z",
     "start_time": "2020-04-07T01:10:59.840Z"
    }
   },
   "outputs": [],
   "source": [
    "df_best_guess_budget = df_lesscols.assign(best_budget=best_budget\n",
    "                                         ).drop(\"budget_api budget_kaggle\".split(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.938865Z",
     "start_time": "2020-04-07T01:10:59.856Z"
    }
   },
   "outputs": [],
   "source": [
    "df_best_guess_budget.best_budget.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5% of budget values are missing. I think I will in fact impute the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.940012Z",
     "start_time": "2020-04-07T01:10:59.873Z"
    }
   },
   "outputs": [],
   "source": [
    "budget_med = df_best_guess_budget.best_budget.dropna().median()\n",
    "budget_mean = df_best_guess_budget.best_budget.dropna().mean()\n",
    "budget_med, budget_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.940846Z",
     "start_time": "2020-04-07T01:10:59.892Z"
    }
   },
   "outputs": [],
   "source": [
    "df_filled_budget = df_best_guess_budget.assign(\n",
    "    filled_budget = df_best_guess_budget[\"best_budget\"].fillna(budget_med)\n",
    ").drop([\"best_budget\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.941623Z",
     "start_time": "2020-04-07T01:10:59.909Z"
    }
   },
   "outputs": [],
   "source": [
    "df_filled_budget.filled_budget.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.942459Z",
     "start_time": "2020-04-07T01:10:59.927Z"
    }
   },
   "outputs": [],
   "source": [
    "df_filled_budget.filled_budget.median(), df_filled_budget.filled_budget.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't seem to have shifted the mean much, that's good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aspect Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.943244Z",
     "start_time": "2020-04-07T01:10:59.946Z"
    }
   },
   "outputs": [],
   "source": [
    "df_filled_budget.aspect_ratio.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6% of aspect ratios are null."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a categorical describing the dimensions of the projected image. Your TV set is 16x9 aka 1.77 aspect ratio, whereas lots of hollywood films are 1.85 ratio or 2.40, much \"wider-screen\". 2.40 might be \"artsier\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.944315Z",
     "start_time": "2020-04-07T01:10:59.968Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aspect ratio of 16 I take to mean 16x9 aka 1.77:\n",
    "df_filled_budget.aspect_ratio = df_filled_budget.aspect_ratio.apply(lambda x: 1.77 if x==16 else x)\n",
    "df_filled_budget.aspect_ratio.value_counts().sort_index().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think I will lump some of these together and impute 1.85 on null values. It's not *quite* the mode but it's a sort of middle-of-the road aspect ratio. The DCI standard lists 2.39 and 1.85 for theatrical projection. 16x9 or 1.77 is also common, and 4/3 or 1.33 is like an old-timey boxey aspect ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.945097Z",
     "start_time": "2020-04-07T01:10:59.985Z"
    }
   },
   "outputs": [],
   "source": [
    "aspect_bins = [0, np.mean((1.33, 1.77)), np.mean((1.77,1.85)), np.mean((1.85,2.39)), np.inf]\n",
    "aspect_labels = \"1.33 1.77 1.85 2.39\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.946671Z",
     "start_time": "2020-04-07T01:11:00.002Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.cut(df_filled_budget.aspect_ratio, \n",
    "       bins=aspect_bins, \n",
    "       labels=aspect_labels,\n",
    "       include_lowest=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lump values and impute 1.85:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.947672Z",
     "start_time": "2020-04-07T01:11:00.020Z"
    }
   },
   "outputs": [],
   "source": [
    "df_fixed_aspect = df_filled_budget.assign(fixed_aspect = pd.cut(df_filled_budget.aspect_ratio, \n",
    "                                                         bins=aspect_bins, \n",
    "                                                         labels=aspect_labels,\n",
    "                                                         include_lowest=True\n",
    "                                                               ).fillna(\"1.85\")\n",
    "                                         ).drop([\"aspect_ratio\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.948520Z",
     "start_time": "2020-04-07T01:11:00.036Z"
    }
   },
   "outputs": [],
   "source": [
    "df_fixed_aspect.fixed_aspect.value_counts().sort_index().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.949237Z",
     "start_time": "2020-04-07T01:11:00.054Z"
    }
   },
   "outputs": [],
   "source": [
    "df_fixed_aspect.content_rating.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.950702Z",
     "start_time": "2020-04-07T01:11:00.071Z"
    }
   },
   "outputs": [],
   "source": [
    "df_fixed_aspect.content_rating.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just gonna fill nulls with PG-13 and condense redundant ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.951790Z",
     "start_time": "2020-04-07T01:11:00.088Z"
    }
   },
   "outputs": [],
   "source": [
    "df_content_rating_filled = df_fixed_aspect.assign(\n",
    "                                content_rating=df_fixed_aspect.content_rating.fillna(\"PG-13\")\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.953082Z",
     "start_time": "2020-04-07T01:11:00.106Z"
    }
   },
   "outputs": [],
   "source": [
    "def rating_mapper(rating):\n",
    "    if rating == \"Not Rated\":\n",
    "        return \"Unrated\"\n",
    "    elif rating in \"Approved Passed M TV-14\".split():\n",
    "        return \"PG-13\"\n",
    "    elif rating in \"TV-G GP G TV-PG\".split():\n",
    "        return \"PG\"\n",
    "    elif rating in [\"NC-17\"]:\n",
    "        return \"X\"\n",
    "    else:\n",
    "        return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.953763Z",
     "start_time": "2020-04-07T01:11:00.123Z"
    }
   },
   "outputs": [],
   "source": [
    "df_content_rating_condensed = df_content_rating_filled.assign(\n",
    "                                content_rating = df_content_rating_filled.content_rating.map(rating_mapper)\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.954571Z",
     "start_time": "2020-04-07T01:11:00.140Z"
    }
   },
   "outputs": [],
   "source": [
    "df_content_rating_condensed.content_rating.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.955307Z",
     "start_time": "2020-04-07T01:11:00.157Z"
    }
   },
   "outputs": [],
   "source": [
    "df_content_rating_condensed.content_rating.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are we doing on null values globally?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.955892Z",
     "start_time": "2020-04-07T01:11:00.175Z"
    }
   },
   "outputs": [],
   "source": [
    "nulls_update = df_content_rating_condensed.isna().sum()[\n",
    "    df_content_rating_condensed.isna().sum() > 0\n",
    "].sort_values(ascending=False)\n",
    "\n",
    "nulls_update.plot(kind='bar', figsize=(15,8), rot=45).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearing some memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.956658Z",
     "start_time": "2020-04-07T01:11:00.193Z"
    }
   },
   "outputs": [],
   "source": [
    "del nulls\n",
    "del imdb_ids\n",
    "del kaggle_data\n",
    "del best_budget\n",
    "del df_lesscols\n",
    "del df_best_guess_budget\n",
    "del df_filled_budget\n",
    "del df_content_rating_filled\n",
    "del df_fixed_aspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facebook Like Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.957588Z",
     "start_time": "2020-04-07T01:11:00.212Z"
    }
   },
   "outputs": [],
   "source": [
    "facebook_like_cols = [col for col in df_content_rating_condensed if \"facebook\" in col]\n",
    "likes = df_content_rating_condensed[facebook_like_cols]\n",
    "\n",
    "df_content_rating_condensed.drop(facebook_like_cols, axis=1, inplace=True)\n",
    "\n",
    "likes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.958366Z",
     "start_time": "2020-04-07T01:11:00.230Z"
    }
   },
   "outputs": [],
   "source": [
    "(round(likes.isna().mean()*100,2)).sort_values(ascending=False).astype('str')+\"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not that many values are missing. Will just use the medians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.958974Z",
     "start_time": "2020-04-07T01:11:00.250Z"
    }
   },
   "outputs": [],
   "source": [
    "likes.fillna({col:likes[col].median() for col in likes.columns}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.959676Z",
     "start_time": "2020-04-07T01:11:00.268Z"
    }
   },
   "outputs": [],
   "source": [
    "df_likes_filled = pd.concat([df_content_rating_condensed,\n",
    "                             likes], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.960358Z",
     "start_time": "2020-04-07T01:11:00.286Z"
    }
   },
   "outputs": [],
   "source": [
    "del df_content_rating_condensed\n",
    "del likes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time for another check-in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.961153Z",
     "start_time": "2020-04-07T01:11:00.305Z"
    }
   },
   "outputs": [],
   "source": [
    "nulls_update = df_likes_filled.isna().sum()[\n",
    "    df_likes_filled.isna().sum() > 0\n",
    "].sort_values(ascending=False)\n",
    "\n",
    "nulls_update.plot(kind='bar', figsize=(15,8), rot=45).plot()\n",
    "\n",
    "del nulls_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.961939Z",
     "start_time": "2020-04-07T01:11:00.325Z"
    }
   },
   "outputs": [],
   "source": [
    "df_likes_filled.color = df_likes_filled.color.str.lstrip()\n",
    "df_likes_filled.color.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems safe to assume that the last dozen films are in color..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.962718Z",
     "start_time": "2020-04-07T01:11:00.344Z"
    }
   },
   "outputs": [],
   "source": [
    "df_likes_filled.color = df_likes_filled.color.fillna(df_likes_filled.color.mode()[0])\n",
    "df_color_filled = df_likes_filled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.963479Z",
     "start_time": "2020-04-07T01:11:00.358Z"
    }
   },
   "outputs": [],
   "source": [
    "del df_likes_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.964214Z",
     "start_time": "2020-04-07T01:11:00.375Z"
    }
   },
   "outputs": [],
   "source": [
    "df_color_filled.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.965448Z",
     "start_time": "2020-04-07T01:11:00.390Z"
    }
   },
   "outputs": [],
   "source": [
    "df_color_filled.color.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Number in Poster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.967018Z",
     "start_time": "2020-04-07T01:11:00.407Z"
    }
   },
   "outputs": [],
   "source": [
    "df_color_filled.facenumber_in_poster.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero seems to be a placeholder for \"idk\" in this dataset, I'll drop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.967875Z",
     "start_time": "2020-04-07T01:11:00.425Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_facenums = df_color_filled.drop(['facenumber_in_poster'],axis=1)\n",
    "del df_color_filled\n",
    "df_no_facenums.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language (\"original... spoken... language\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.968692Z",
     "start_time": "2020-04-07T01:11:00.442Z"
    }
   },
   "outputs": [],
   "source": [
    "langs = df_no_facenums[[col for col in df_no_facenums.columns if \"language\" in col]]\n",
    "langs.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.969519Z",
     "start_time": "2020-04-07T01:11:00.459Z"
    }
   },
   "outputs": [],
   "source": [
    "langs.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.970315Z",
     "start_time": "2020-04-07T01:11:00.475Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_facenums.iloc[13,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"language\" column looks not great. \"original language\" is probably a better bet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.971033Z",
     "start_time": "2020-04-07T01:11:00.491Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_facenums.spoken_languages.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.971763Z",
     "start_time": "2020-04-07T01:11:00.506Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_facenums.original_language.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah I think that's probably the best column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.972761Z",
     "start_time": "2020-04-07T01:11:00.522Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_facenums.original_language.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a python package to make language codes human-readable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.973695Z",
     "start_time": "2020-04-07T01:11:00.539Z"
    }
   },
   "outputs": [],
   "source": [
    "lang_decoder = {lang.alpha_2: lang.name for lang in languages if hasattr(lang,'alpha_2')}\n",
    "list(lang_decoder.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.974707Z",
     "start_time": "2020-04-07T01:11:00.554Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_facenums.original_language = df_no_facenums.original_language.map(lang_decoder)\n",
    "df_no_facenums.original_language.value_counts()[2:].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just eyeballing it...I think anything after German, in terms of frequency, is gonna have to go in \"other\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grabbing most popular languages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.975658Z",
     "start_time": "2020-04-07T01:11:00.572Z"
    }
   },
   "outputs": [],
   "source": [
    "top_langs = df_no_facenums.original_language.value_counts().index[:3].tolist()\n",
    "top_langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.976350Z",
     "start_time": "2020-04-07T01:11:00.587Z"
    }
   },
   "outputs": [],
   "source": [
    "def language_lumper(lang):\n",
    "    if lang not in top_langs:\n",
    "        return \"Other\"\n",
    "    else:\n",
    "        return lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.976943Z",
     "start_time": "2020-04-07T01:11:00.603Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_facenums.original_language = df_no_facenums.original_language.apply(language_lumper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.977620Z",
     "start_time": "2020-04-07T01:11:00.619Z"
    }
   },
   "outputs": [],
   "source": [
    "df_langs_lumped = df_no_facenums.drop(\"language spoken_languages\".split(),axis=1)\n",
    "del df_no_facenums\n",
    "del langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.978400Z",
     "start_time": "2020-04-07T01:11:00.635Z"
    }
   },
   "outputs": [],
   "source": [
    "df_langs_lumped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.979114Z",
     "start_time": "2020-04-07T01:11:00.651Z"
    }
   },
   "outputs": [],
   "source": [
    "df_langs_lumped.original_language.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.980558Z",
     "start_time": "2020-04-07T01:11:00.668Z"
    }
   },
   "outputs": [],
   "source": [
    "nulls = df_langs_lumped.isna().sum()[df_langs_lumped.isna().sum() > 0].sort_values(ascending=False)\n",
    "\n",
    "nulls.plot(kind='bar', figsize=(15,8)).plot()\n",
    "\n",
    "del nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration / Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.981326Z",
     "start_time": "2020-04-07T01:11:00.685Z"
    }
   },
   "outputs": [],
   "source": [
    "durs = df_langs_lumped[\"duration runtime\".split()]\n",
    "durs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T02:47:21.610275Z",
     "start_time": "2020-04-02T02:47:21.606596Z"
    }
   },
   "source": [
    "How different are these columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.982165Z",
     "start_time": "2020-04-07T01:11:00.705Z"
    }
   },
   "outputs": [],
   "source": [
    "(durs.duration - durs.runtime).plot(kind='hist')\n",
    "(durs.duration - durs.runtime).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not very."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.982891Z",
     "start_time": "2020-04-07T01:11:00.721Z"
    }
   },
   "outputs": [],
   "source": [
    "df_langs_lumped.drop([\"duration\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.983739Z",
     "start_time": "2020-04-07T01:11:00.737Z"
    }
   },
   "outputs": [],
   "source": [
    "df_runtimes_filled = df_langs_lumped.assign(\n",
    "    durations=df_langs_lumped.runtime.fillna(\n",
    "        df_langs_lumped.runtime.median()\n",
    "    )\n",
    ").drop([\"runtime\"],axis=1)\n",
    "\n",
    "del df_langs_lumped\n",
    "del durs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.984540Z",
     "start_time": "2020-04-07T01:11:00.754Z"
    }
   },
   "outputs": [],
   "source": [
    "df_runtimes_filled.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No more obvious nulls!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.985239Z",
     "start_time": "2020-04-07T01:11:00.770Z"
    }
   },
   "outputs": [],
   "source": [
    "df_runtimes_filled.to_pickle(\"../data/pickles/df_no_nulls.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.986063Z",
     "start_time": "2020-04-07T01:11:00.786Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_nulls = pd.read_pickle(\"../data/pickles/df_no_nulls.pkl\")\n",
    "df_no_nulls.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Adult\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.986810Z",
     "start_time": "2020-04-07T01:11:00.804Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_nulls.adult.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single-value column. Drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.987734Z",
     "start_time": "2020-04-07T01:11:00.822Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_adult = df_no_nulls.drop([\"adult\"],axis=1)\n",
    "del df_no_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.988516Z",
     "start_time": "2020-04-07T01:11:00.838Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_adult.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Production Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.989169Z",
     "start_time": "2020-04-07T01:11:00.855Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_adult['production_countries'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm list of dict. Let's just grab the human-readable names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.990147Z",
     "start_time": "2020-04-07T01:11:00.875Z"
    }
   },
   "outputs": [],
   "source": [
    "def prod_countries_extractor(countries):\n",
    "    if len(countries)!=0:\n",
    "        return {country['name'] for country in countries}\n",
    "    else:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.990977Z",
     "start_time": "2020-04-07T01:11:00.890Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_adult.production_countries = df_no_adult.production_countries.apply(prod_countries_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.991734Z",
     "start_time": "2020-04-07T01:11:00.905Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_adult.production_countries.iloc[29:34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.992614Z",
     "start_time": "2020-04-07T01:11:00.921Z"
    }
   },
   "outputs": [],
   "source": [
    "# Turns out pandas vectorized string operations work on lists too\n",
    "ax = df_no_adult.production_countries.str.len().value_counts().sort_index().plot(kind='bar')\n",
    "ax.set_xlabel(\"N countries\")\n",
    "ax.set_ylabel(\"N Films\")\n",
    "ax.plot()\n",
    "del ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I feel like that ^ can become an int column, after the zeroes are fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.993299Z",
     "start_time": "2020-04-07T01:11:00.937Z"
    }
   },
   "outputs": [],
   "source": [
    "# If it's not in English, can we guess where it was filmed?\n",
    "df_no_adult[(\n",
    "                df_no_adult.production_countries.str.len()==0\n",
    "            )&(\n",
    "                df_no_adult.original_language!=\"English\"\n",
    "            )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.994101Z",
     "start_time": "2020-04-07T01:11:00.953Z"
    }
   },
   "outputs": [],
   "source": [
    "guesses = {480:\"Germany\", \n",
    "           2051:\"Germany\",\n",
    "           2260:\"India\",\n",
    "           3242:\"India\"}\n",
    "\n",
    "for index, country in guesses.items():\n",
    "    df_no_adult['production_countries'].iloc[index] = country\n",
    "    \n",
    "del index\n",
    "del country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.995020Z",
     "start_time": "2020-04-07T01:11:00.968Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame([df_no_adult.iloc[i,:] for i in guesses.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.995935Z",
     "start_time": "2020-04-07T01:11:00.983Z"
    }
   },
   "outputs": [],
   "source": [
    "del guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.996645Z",
     "start_time": "2020-04-07T01:11:01.000Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_adult.production_countries.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.997377Z",
     "start_time": "2020-04-07T01:11:01.016Z"
    }
   },
   "outputs": [],
   "source": [
    "def fill_with_USA(country_set):\n",
    "    return {\"United States of America\"} if country_set == {} else country_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.998436Z",
     "start_time": "2020-04-07T01:11:01.032Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_adult[\"production_countries\"] = df_no_adult.production_countries.apply(fill_with_USA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:26.999195Z",
     "start_time": "2020-04-07T01:11:01.047Z"
    }
   },
   "outputs": [],
   "source": [
    "df_filled_USA = df_no_adult.copy()\n",
    "del df_no_adult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Might need to split into USA and not-USA to deal with class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.000077Z",
     "start_time": "2020-04-07T01:11:01.064Z"
    }
   },
   "outputs": [],
   "source": [
    "def usa_or_not(country_set):\n",
    "    return 0 if country_set=={\"United States of America\"} else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.000788Z",
     "start_time": "2020-04-07T01:11:01.079Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = df_filled_USA.production_countries.apply(usa_or_not).value_counts().plot(kind='bar')\n",
    "ax.set_xlabel(\"Shot only in USA\")\n",
    "del ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.001528Z",
     "start_time": "2020-04-07T01:11:01.095Z"
    }
   },
   "outputs": [],
   "source": [
    "df_filled_USA['shot_only_in_USA'] = df_filled_USA.production_countries.apply(usa_or_not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.002220Z",
     "start_time": "2020-04-07T01:11:01.111Z"
    }
   },
   "outputs": [],
   "source": [
    "def shot_in_usa_and_abroad(country_set):\n",
    "    if len(country_set)>1 and \"United States of America\" in country_set:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.002778Z",
     "start_time": "2020-04-07T01:11:01.127Z"
    }
   },
   "outputs": [],
   "source": [
    "df_filled_USA['shot_in_USA_and_abroad'] = df_filled_USA.production_countries.apply(shot_in_usa_and_abroad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.003403Z",
     "start_time": "2020-04-07T01:11:01.143Z"
    }
   },
   "outputs": [],
   "source": [
    "df_filled_USA['shot_in_USA_and_abroad'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.004457Z",
     "start_time": "2020-04-07T01:11:01.158Z"
    }
   },
   "outputs": [],
   "source": [
    "df_filled_USA['n_production_countries'] = df_filled_USA.production_countries.str.len()\n",
    "df_filled_USA['n_production_countries'].plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.005654Z",
     "start_time": "2020-04-07T01:11:01.174Z"
    }
   },
   "outputs": [],
   "source": [
    "df_n_countries = df_filled_USA.drop([\"production_countries\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.006212Z",
     "start_time": "2020-04-07T01:11:01.189Z"
    }
   },
   "outputs": [],
   "source": [
    "del df_filled_USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.007004Z",
     "start_time": "2020-04-07T01:11:01.207Z"
    }
   },
   "outputs": [],
   "source": [
    "df_n_countries.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.007881Z",
     "start_time": "2020-04-07T01:11:01.223Z"
    }
   },
   "outputs": [],
   "source": [
    "df_n_countries['genre'] = df_n_countries['genres_api'].str.split(\"|\")\n",
    "df_n_countries['genre'] = df_n_countries['genre'].apply(lambda x: set(x))\n",
    "del df_n_countries[\"genres_api\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.008633Z",
     "start_time": "2020-04-07T01:11:01.239Z"
    }
   },
   "outputs": [],
   "source": [
    "df_n_countries['genre'].apply(lambda x: set(x)).value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.009697Z",
     "start_time": "2020-04-07T01:11:01.255Z"
    }
   },
   "outputs": [],
   "source": [
    "genre_cats = \"Drama Comedy Romance Crime Thriller Horror Action Mystery Sci-Fi Adventure Documentary\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.010399Z",
     "start_time": "2020-04-07T01:11:01.270Z"
    }
   },
   "outputs": [],
   "source": [
    "def genre_encoder(genre_set):\n",
    "    new = pd.Series(0, index=genre_cats)\n",
    "    for genre in genre_set:\n",
    "        if genre in genre_cats:\n",
    "            new[genre] = 1\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.011179Z",
     "start_time": "2020-04-07T01:11:01.287Z"
    }
   },
   "outputs": [],
   "source": [
    "df_n_countries.genre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.012083Z",
     "start_time": "2020-04-07T01:11:01.303Z"
    }
   },
   "outputs": [],
   "source": [
    "df_n_countries.genre.head().apply(genre_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.012960Z",
     "start_time": "2020-04-07T01:11:01.319Z"
    }
   },
   "outputs": [],
   "source": [
    "genre_matrix = df_n_countries.genre.apply(genre_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.013828Z",
     "start_time": "2020-04-07T01:11:01.334Z"
    }
   },
   "outputs": [],
   "source": [
    "del df_n_countries['genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.014776Z",
     "start_time": "2020-04-07T01:11:01.350Z"
    }
   },
   "outputs": [],
   "source": [
    "genre_matrix.columns = [\"\".join([\"genre_\", col]) for col in genre_matrix.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.015958Z",
     "start_time": "2020-04-07T01:11:01.366Z"
    }
   },
   "outputs": [],
   "source": [
    "df_encoded_genres = pd.concat([df_n_countries,genre_matrix],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.016757Z",
     "start_time": "2020-04-07T01:11:01.382Z"
    }
   },
   "outputs": [],
   "source": [
    "del df_n_countries\n",
    "del genre_matrix\n",
    "del genre_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.017362Z",
     "start_time": "2020-04-07T01:11:01.398Z"
    }
   },
   "outputs": [],
   "source": [
    "df_encoded_genres.to_pickle(\"../data/pickles/df_encoded_genres.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.018256Z",
     "start_time": "2020-04-07T01:11:01.414Z"
    }
   },
   "outputs": [],
   "source": [
    "df_encoded_genres = pd.read_pickle(\"../data/pickles/df_encoded_genres.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.019459Z",
     "start_time": "2020-04-07T01:11:01.432Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_encoded_genres.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facebook Likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.020454Z",
     "start_time": "2020-04-07T01:11:01.447Z"
    }
   },
   "outputs": [],
   "source": [
    "likes = df_encoded_genres[[col for col in df_encoded_genres.columns if \"likes\" in col]]\n",
    "likes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.021359Z",
     "start_time": "2020-04-07T01:11:01.464Z"
    }
   },
   "outputs": [],
   "source": [
    "likes.actor_1_facebook_likes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.022393Z",
     "start_time": "2020-04-07T01:11:01.479Z"
    }
   },
   "outputs": [],
   "source": [
    "likes.actor_1_facebook_likes.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could probably use a log transform or something. Or is it just full of zeroes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.023465Z",
     "start_time": "2020-04-07T01:11:01.495Z"
    }
   },
   "outputs": [],
   "source": [
    "likes.actor_1_facebook_likes[likes.actor_1_facebook_likes < 5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.024430Z",
     "start_time": "2020-04-07T01:11:01.510Z"
    }
   },
   "outputs": [],
   "source": [
    "likes.director_facebook_likes[likes.director_facebook_likes == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.025448Z",
     "start_time": "2020-04-07T01:11:01.525Z"
    }
   },
   "outputs": [],
   "source": [
    "likes.director_facebook_likes.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm willing to believe that directors are just generally not as popular as their actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.026196Z",
     "start_time": "2020-04-07T01:11:01.541Z"
    }
   },
   "outputs": [],
   "source": [
    "# +1 like for boxcox, does not like zeroes\n",
    "pd.Series(boxcox(likes.actor_1_facebook_likes+1)[0]).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.027391Z",
     "start_time": "2020-04-07T01:11:01.565Z"
    }
   },
   "outputs": [],
   "source": [
    "all_boxcoxed = [pd.Series(boxcox(likes[col]+1)[0], name=f\"{col}_box\") for col in likes.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.028101Z",
     "start_time": "2020-04-07T01:11:01.586Z"
    }
   },
   "outputs": [],
   "source": [
    "boxed_df = pd.concat(all_boxcoxed,axis=1)\n",
    "boxed_df.index = df_encoded_genres.index\n",
    "boxed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.028797Z",
     "start_time": "2020-04-07T01:11:01.602Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in boxed_df:\n",
    "    plt.figure()\n",
    "    plt.hist(boxed_df[col])\n",
    "    print(col)\n",
    "    plt.show()\n",
    "del col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.029381Z",
     "start_time": "2020-04-07T01:11:01.672Z"
    }
   },
   "outputs": [],
   "source": [
    "no_likes = df_encoded_genres.drop([col for col in df_encoded_genres if \"likes\" in col], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.030014Z",
     "start_time": "2020-04-07T01:11:01.688Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boxed_df.index = no_likes.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.030789Z",
     "start_time": "2020-04-07T01:11:01.705Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_likes = pd.concat([no_likes, boxed_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.031441Z",
     "start_time": "2020-04-07T01:11:01.721Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_likes.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.032340Z",
     "start_time": "2020-04-07T01:11:01.738Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_likes.filled_budget.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also pretty skewed up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.033133Z",
     "start_time": "2020-04-07T01:11:01.757Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_likes.filled_budget.transform(np.log).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not perfect, boxcox again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.033755Z",
     "start_time": "2020-04-07T01:11:01.774Z"
    }
   },
   "outputs": [],
   "source": [
    "budget_boxed = pd.Series(boxcox(df_boxcoxed_likes.filled_budget)[0], name=\"budget_boxed\")\n",
    "budget_boxed.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.034615Z",
     "start_time": "2020-04-07T01:11:01.789Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget = df_boxcoxed_likes.assign(budget_boxed=budget_boxed.values).drop(['filled_budget'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.035162Z",
     "start_time": "2020-04-07T01:11:01.805Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.035974Z",
     "start_time": "2020-04-07T01:11:01.821Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget.durations.hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems pretty tightly clustered around feature length film length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.037238Z",
     "start_time": "2020-04-07T01:11:01.839Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget.durations.plot(kind='box',figsize=(2,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.038118Z",
     "start_time": "2020-04-07T01:11:01.858Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(boxcox(df_boxcoxed_budget.durations+1)[0], name=f\"duration_box\").hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think we can just stick with the original durations, no transform needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Production Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.039385Z",
     "start_time": "2020-04-07T01:11:01.876Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget.n_production_countries.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I should lump together 5+ perhaps...it gets a bit sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.040105Z",
     "start_time": "2020-04-07T01:11:01.894Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget.n_production_countries.apply(lambda x: 5 if x >= 5 else x).value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.040937Z",
     "start_time": "2020-04-07T01:11:01.910Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget[\"n_prod_locs_trunc\"] = df_boxcoxed_budget.n_production_countries.apply(\n",
    "                                                                                    lambda x: 5 if x >= 5 else x\n",
    "                                                                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to remember that here, the int 5 represents 5 or more countries of filming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.041712Z",
     "start_time": "2020-04-07T01:11:01.927Z"
    }
   },
   "outputs": [],
   "source": [
    "del df_boxcoxed_budget[\"n_production_countries\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revenue (Secondary Response Variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My understanding is that response variables do not need to be normally distributed, for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.042538Z",
     "start_time": "2020-04-07T01:11:01.946Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget.revenue.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.043166Z",
     "start_time": "2020-04-07T01:11:01.963Z"
    }
   },
   "outputs": [],
   "source": [
    "(df_boxcoxed_budget[\"revenue\"]+1).transform(np.log).hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hrmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMdB Score (Response Variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.044671Z",
     "start_time": "2020-04-07T01:11:01.981Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget.imdb_score.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.045615Z",
     "start_time": "2020-04-07T01:11:02.001Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget.imdb_score.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.046327Z",
     "start_time": "2020-04-07T01:11:02.017Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget.to_pickle(\"../data/pickles/df_boxcoxed_budget.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free Text Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.047462Z",
     "start_time": "2020-04-07T01:11:02.034Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget = pd.read_pickle(\"../data/pickles/df_boxcoxed_budget.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.048470Z",
     "start_time": "2020-04-07T01:11:02.052Z"
    }
   },
   "outputs": [],
   "source": [
    "titles = df_boxcoxed_budget[\"title movie_title original_title\".split()]\n",
    "titles.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.049547Z",
     "start_time": "2020-04-07T01:11:02.070Z"
    }
   },
   "outputs": [],
   "source": [
    "titles['title'].iloc[0] == titles[\"movie_title\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.050320Z",
     "start_time": "2020-04-07T01:11:02.086Z"
    }
   },
   "outputs": [],
   "source": [
    "titles['title'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.050969Z",
     "start_time": "2020-04-07T01:11:02.103Z"
    }
   },
   "outputs": [],
   "source": [
    "titles[\"movie_title\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.051567Z",
     "start_time": "2020-04-07T01:11:02.119Z"
    }
   },
   "outputs": [],
   "source": [
    "titles['movie_title'] = titles['movie_title'].apply(lambda title: normalize('NFKD', title).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.052299Z",
     "start_time": "2020-04-07T01:11:02.134Z"
    }
   },
   "outputs": [],
   "source": [
    "titles['title'].iloc[0] == titles[\"movie_title\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.052859Z",
     "start_time": "2020-04-07T01:11:02.150Z"
    }
   },
   "outputs": [],
   "source": [
    "titles[titles.title != titles.movie_title].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.053694Z",
     "start_time": "2020-04-07T01:11:02.165Z"
    }
   },
   "outputs": [],
   "source": [
    "titles[titles.title != titles.movie_title].head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can't tell just from looking which of these is the definitive \"right\" column to use. Original_title seems more likely to be in a foreign language..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.054310Z",
     "start_time": "2020-04-07T01:11:02.183Z"
    }
   },
   "outputs": [],
   "source": [
    "titles[titles.title != titles.movie_title].tail(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't think there is going to be predictive information in the title itself. Maybe I'll just grab one as a plaintext reference to the datapoint..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.055123Z",
     "start_time": "2020-04-07T01:11:02.200Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget.drop(['movie_title', \"original_title\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.055788Z",
     "start_time": "2020-04-07T01:11:02.218Z"
    }
   },
   "outputs": [],
   "source": [
    "del titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview / Plot Synopsis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we need to get into real NLP stuff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a peek at our plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.056315Z",
     "start_time": "2020-04-07T01:11:02.237Z"
    }
   },
   "outputs": [],
   "source": [
    "[print(_,\"\\n\") for _ in df_boxcoxed_budget.overview.head(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing stopwords, POS lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.057092Z",
     "start_time": "2020-04-07T01:11:02.257Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def process_plot(plot):\n",
    "    tokens = word_tokenize(plot)\n",
    "    stops_removed = [w for w in tokens if w not in stop_words]\n",
    "    punc_removed = [w.lower() for w in stops_removed if w.isalpha()]\n",
    "    tagged = [(w, get_wordnet_pos(w)) for w in punc_removed]\n",
    "    return \" \".join([lemmatizer.lemmatize(word[0], pos=word[1]) for word in tagged])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.057743Z",
     "start_time": "2020-04-07T01:11:02.274Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget['plot_prepped'] = df_boxcoxed_budget.overview.apply(process_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Count Vectorizing, TF-IDF Normalizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the [sklearn docs](https://scikit-learn.org/stable/modules/feature_extraction.html#):\n",
    "\n",
    "\"The word boundaries-aware variant `char_wb` is especially interesting for languages that use white-spaces for word separation...as it...can increase both the predictive accuracy and convergence speed of classifiers trained using such features while retaining the robustness with regards to misspellings and word derivations.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.058360Z",
     "start_time": "2020-04-07T01:11:02.292Z"
    }
   },
   "outputs": [],
   "source": [
    "bigram_vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(5, 5),#ngram_range=(1, 2),\n",
    "                                    token_pattern=r'\\b\\w+\\b', \n",
    "                                    min_df=1,\n",
    "                                    binary=True)\n",
    "\n",
    "# Plot synopsis texts are not very long: Using binary countvectorizer to help reduce noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.059305Z",
     "start_time": "2020-04-07T01:11:02.310Z"
    }
   },
   "outputs": [],
   "source": [
    "bigram_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.059995Z",
     "start_time": "2020-04-07T01:11:02.326Z"
    }
   },
   "outputs": [],
   "source": [
    "analyze = bigram_vectorizer.build_analyzer()\n",
    "analyze('Bi-grams are cool!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.060616Z",
     "start_time": "2020-04-07T01:11:02.342Z"
    }
   },
   "outputs": [],
   "source": [
    "sparse_plots = bigram_vectorizer.fit_transform(df_boxcoxed_budget['plot_prepped'])\n",
    "sparse_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.061453Z",
     "start_time": "2020-04-07T01:11:02.358Z"
    }
   },
   "outputs": [],
   "source": [
    "bigram_columns = bigram_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.062278Z",
     "start_time": "2020-04-07T01:11:02.373Z"
    }
   },
   "outputs": [],
   "source": [
    "bigram_counts = pd.DataFrame(sparse_plots.toarray(),\n",
    "                             columns=bigram_columns)\n",
    "\n",
    "bigram_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.064091Z",
     "start_time": "2020-04-07T01:11:02.389Z"
    }
   },
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer(smooth_idf=False)\n",
    "tfidf = transformer.fit_transform(bigram_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.064897Z",
     "start_time": "2020-04-07T01:11:02.405Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tfidf = pd.DataFrame(tfidf.toarray(), columns=bigram_columns)\n",
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.065616Z",
     "start_time": "2020-04-07T01:11:02.422Z"
    }
   },
   "outputs": [],
   "source": [
    "del bigram_columns\n",
    "del bigram_counts\n",
    "del stop_words\n",
    "del analyze\n",
    "del df_boxcoxed_budget['overview']\n",
    "del df_boxcoxed_budget['plot_prepped']\n",
    "del tfidf\n",
    "del transformer\n",
    "del wordnet\n",
    "del lemmatizer\n",
    "del languages\n",
    "del sparse_plots\n",
    "del bigram_vectorizer\n",
    "del stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.066447Z",
     "start_time": "2020-04-07T01:11:02.438Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tfidf.columns[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.067172Z",
     "start_time": "2020-04-07T01:11:02.454Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tfidf.columns[5000:5100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.067990Z",
     "start_time": "2020-04-07T01:11:02.470Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty large feature space there. Maybe I'll incorporate some PCA in the modeling pipeline..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.068742Z",
     "start_time": "2020-04-07T01:11:02.487Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.069515Z",
     "start_time": "2020-04-07T01:11:02.503Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.070300Z",
     "start_time": "2020-04-07T01:11:02.518Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.071049Z",
     "start_time": "2020-04-07T01:11:02.534Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget.to_pickle('../data/pickles/df_mostly_ready_metadata.pkl')\n",
    "df_tfidf.to_pickle('../data/pickles/df_tfidf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.071823Z",
     "start_time": "2020-04-07T01:11:02.554Z"
    }
   },
   "outputs": [],
   "source": [
    "df_mostly_ready_metadata = pd.read_pickle('../data/pickles/df_mostly_ready_metadata.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.072598Z",
     "start_time": "2020-04-07T01:11:02.575Z"
    }
   },
   "outputs": [],
   "source": [
    "df_mostly_ready_metadata.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.073469Z",
     "start_time": "2020-04-07T01:11:02.590Z"
    }
   },
   "outputs": [],
   "source": [
    "df_mostly_ready_metadata.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.074261Z",
     "start_time": "2020-04-07T01:11:02.605Z"
    }
   },
   "outputs": [],
   "source": [
    "lang_matrix = pd.get_dummies(df_mostly_ready_metadata['original_language'],\n",
    "                             prefix=\"lang\")\n",
    "lang_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.074964Z",
     "start_time": "2020-04-07T01:11:02.621Z"
    }
   },
   "outputs": [],
   "source": [
    "df_mostly_ready_metadata.drop(['original_language'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.075890Z",
     "start_time": "2020-04-07T01:11:02.637Z"
    }
   },
   "outputs": [],
   "source": [
    "df_mostly_ready_metadata = pd.concat([df_mostly_ready_metadata, \n",
    "                                      lang_matrix],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.076653Z",
     "start_time": "2020-04-07T01:11:02.652Z"
    }
   },
   "outputs": [],
   "source": [
    "df_mostly_ready_metadata['color'] = df_mostly_ready_metadata['color'].map({\"Color\":1,\n",
    "                                                                           \"Black and White\":0})\n",
    "\n",
    "df_mostly_ready_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.077495Z",
     "start_time": "2020-04-07T01:11:02.668Z"
    }
   },
   "outputs": [],
   "source": [
    "del df_mostly_ready_metadata['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.078215Z",
     "start_time": "2020-04-07T01:11:02.686Z"
    }
   },
   "outputs": [],
   "source": [
    "df_some_binarized = pd.concat([df_mostly_ready_metadata.drop(['fixed_aspect'],axis=1), \n",
    "                                pd.get_dummies(df_mostly_ready_metadata.fixed_aspect, prefix=\"ratio\")],axis=1\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.078937Z",
     "start_time": "2020-04-07T01:11:02.702Z"
    }
   },
   "outputs": [],
   "source": [
    "del df_mostly_ready_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.079788Z",
     "start_time": "2020-04-07T01:11:02.720Z"
    }
   },
   "outputs": [],
   "source": [
    "df_some_binarized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.080489Z",
     "start_time": "2020-04-07T01:11:02.736Z"
    }
   },
   "outputs": [],
   "source": [
    "content_ratings = pd.get_dummies(df_some_binarized.content_rating,prefix=\"content\")\n",
    "content_ratings.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.081023Z",
     "start_time": "2020-04-07T01:11:02.751Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ratings_binarized = pd.concat([df_some_binarized.drop(['content_rating'],\n",
    "                                                         axis=1\n",
    "                                                        ), \n",
    "                                  content_ratings],\n",
    "                                  axis=1\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.081816Z",
     "start_time": "2020-04-07T01:11:02.768Z"
    }
   },
   "outputs": [],
   "source": [
    "del content_ratings\n",
    "del df_some_binarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.082969Z",
     "start_time": "2020-04-07T01:11:02.783Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ratings_binarized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.083838Z",
     "start_time": "2020-04-07T01:11:02.799Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ratings_binarized.to_pickle('../data/pickles/df_structured.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.084880Z",
     "start_time": "2020-04-07T01:11:02.817Z"
    }
   },
   "outputs": [],
   "source": [
    "df_structured = pd.read_pickle('../data/pickles/df_structured.pkl')\n",
    "df_tfidf = pd.read_pickle('../data/pickles/df_tfidf.pkl')\n",
    "\n",
    "df_tfidf.index = df_structured.index\n",
    "\n",
    "df_structured.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.085757Z",
     "start_time": "2020-04-07T01:11:02.834Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.086590Z",
     "start_time": "2020-04-07T01:11:02.850Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_colnames = ['revenue', 'imdb_score']\n",
    "\n",
    "X_structured = df_structured.drop(y_colnames,axis=1)\n",
    "\n",
    "y_structured = df_structured[y_colnames]\n",
    "\n",
    "y_structured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.087207Z",
     "start_time": "2020-04-07T01:11:02.865Z"
    }
   },
   "outputs": [],
   "source": [
    "X_structured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not fit the scaler on the test set. Do not fit PCA on test set. Do not do feature selection based on anything in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.088122Z",
     "start_time": "2020-04-07T01:11:02.883Z"
    }
   },
   "outputs": [],
   "source": [
    "X_struct_train, X_struct_test, y_train, y_test = train_test_split(X_structured, \n",
    "                                                                  y_structured, \n",
    "                                                                  test_size=0.3, \n",
    "                                                                  shuffle=True,\n",
    "                                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think my approach is going to be to use an ensemble to combine two regressors, one for the structured data and one for the unstructured plot texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.088936Z",
     "start_time": "2020-04-07T01:11:02.902Z"
    }
   },
   "outputs": [],
   "source": [
    "X_plots_train = df_tfidf.loc[y_train.index]\n",
    "X_plots_test = df_tfidf.loc[y_test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.089743Z",
     "start_time": "2020-04-07T01:11:02.917Z"
    }
   },
   "outputs": [],
   "source": [
    "del y_structured\n",
    "del df_structured\n",
    "del df_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.090519Z",
     "start_time": "2020-04-07T01:11:02.933Z"
    }
   },
   "outputs": [],
   "source": [
    "X_plots_train.to_pickle('../data/pickles/X_plots_train.pkl')\n",
    "X_plots_test.to_pickle('../data/pickles/X_plots_test.pkl')\n",
    "y_train.to_pickle('../data/pickles/y_train.pkl')\n",
    "y_test.to_pickle('../data/pickles/y_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.091326Z",
     "start_time": "2020-04-07T01:11:02.950Z"
    }
   },
   "outputs": [],
   "source": [
    "del X_plots_train\n",
    "del X_plots_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there any redundant features? Are there any features obviously correlated with our dependent var?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.092112Z",
     "start_time": "2020-04-07T01:11:02.967Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def draw_correlation_heatmap(features):\n",
    "    # Creating a multi-scatter plot\n",
    "    corr =  features.corr()\n",
    "    mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
    "\n",
    "    # Set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "    # Generate a custom diverging colormap\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    sns.heatmap(corr, \n",
    "                mask=mask, \n",
    "                cmap=cmap,\n",
    "                vmax=1, \n",
    "                center=0,\n",
    "                square=True, \n",
    "                linewidths=.5, \n",
    "                cbar_kws={\"shrink\": .5}).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.093009Z",
     "start_time": "2020-04-07T01:11:02.984Z"
    }
   },
   "outputs": [],
   "source": [
    "draw_correlation_heatmap(X_struct_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some obviously multicollinear features to lose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.093849Z",
     "start_time": "2020-04-07T01:11:03.000Z"
    }
   },
   "outputs": [],
   "source": [
    "multicollinear_features = [\"shot_only_in_USA\", \n",
    "                           \"shot_in_USA_and_abroad\", \n",
    "                           \"cast_total_facebook_likes_box\",\n",
    "                           \"actor_2_facebook_likes_box\",\n",
    "                           \"actor_3_facebook_likes_box\",\n",
    "                           \"lang_Other\",\n",
    "                           \"ratio_1.85\",\n",
    "                           \"content_PG-13\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.094624Z",
     "start_time": "2020-04-07T01:11:03.016Z"
    }
   },
   "outputs": [],
   "source": [
    "X_struct_train.drop(multicollinear_features, axis=1, inplace=True)\n",
    "\n",
    "# Drop from the test set as well, to maintain same dimensionality\n",
    "X_struct_test.drop(multicollinear_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.095341Z",
     "start_time": "2020-04-07T01:11:03.032Z"
    }
   },
   "outputs": [],
   "source": [
    "draw_correlation_heatmap(X_struct_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better! I would use a more mathematically rigorous feature elimination technique, but honestly I'm just planning to try regression models with inherent feature elimination like lasso and random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Interaction Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've removed the most obviously redundant terms, it might be helpful to generate a number of interaction terms, in case their interplay has some special significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.096259Z",
     "start_time": "2020-04-07T01:11:03.050Z"
    }
   },
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(2, \n",
    "                          interaction_only=True,\n",
    "                          include_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.097079Z",
     "start_time": "2020-04-07T01:11:03.067Z"
    }
   },
   "outputs": [],
   "source": [
    "poly.fit(X_struct_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.097898Z",
     "start_time": "2020-04-07T01:11:03.083Z"
    }
   },
   "outputs": [],
   "source": [
    "interaction_term_names = [\"*\".join(col.split()) for col in poly.get_feature_names(X_struct_train.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.098924Z",
     "start_time": "2020-04-07T01:11:03.100Z"
    }
   },
   "outputs": [],
   "source": [
    "X_struct_train_poly = pd.DataFrame(poly.transform(X_struct_train), \n",
    "                                   columns = interaction_term_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.099592Z",
     "start_time": "2020-04-07T01:11:03.116Z"
    }
   },
   "outputs": [],
   "source": [
    "X_struct_test_poly = pd.DataFrame(poly.transform(X_struct_test), \n",
    "                                  columns = interaction_term_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.100296Z",
     "start_time": "2020-04-07T01:11:03.132Z"
    }
   },
   "outputs": [],
   "source": [
    "del X_struct_test\n",
    "del X_struct_train\n",
    "del X_structured\n",
    "del interaction_term_names\n",
    "del multicollinear_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.101091Z",
     "start_time": "2020-04-07T01:11:03.149Z"
    }
   },
   "outputs": [],
   "source": [
    "X_struct_train_poly.to_pickle('../data/pickles/X_struct_train_poly.pkl')\n",
    "X_struct_test_poly.to_pickle('../data/pickles/X_struct_test_poly.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.101698Z",
     "start_time": "2020-04-07T01:11:03.167Z"
    }
   },
   "outputs": [],
   "source": [
    "X_struct_train_poly = pd.read_pickle('../data/pickles/X_struct_train_poly.pkl')\n",
    "X_struct_test_poly = pd.read_pickle('../data/pickles/X_struct_test_poly.pkl')\n",
    "X_plots_train = pd.read_pickle('../data/pickles/X_plots_train.pkl')\n",
    "X_plots_test = pd.read_pickle('../data/pickles/X_plots_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make 2 scalers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.102256Z",
     "start_time": "2020-04-07T01:11:03.187Z"
    }
   },
   "outputs": [],
   "source": [
    "struct_scaler = MinMaxScaler()\n",
    "plots_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit scaler on training set, apply to both training and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.102829Z",
     "start_time": "2020-04-07T01:11:03.203Z"
    }
   },
   "outputs": [],
   "source": [
    "X_struct_train_poly_scaled = pd.DataFrame(struct_scaler.fit_transform(X_struct_train_poly), \n",
    "                                         columns = X_struct_train_poly.columns,\n",
    "                                         index = X_struct_train_poly.index)\n",
    "\n",
    "X_struct_train_poly_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.103734Z",
     "start_time": "2020-04-07T01:11:03.220Z"
    }
   },
   "outputs": [],
   "source": [
    "# Just transform() test set, not fit_transform()\n",
    "X_struct_test_poly_scaled = pd.DataFrame(struct_scaler.transform(X_struct_test_poly), \n",
    "                                         columns = X_struct_test_poly.columns,\n",
    "                                         index = X_struct_test_poly.index)\n",
    "\n",
    "X_struct_test_poly_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.104529Z",
     "start_time": "2020-04-07T01:11:03.236Z"
    }
   },
   "outputs": [],
   "source": [
    "del X_struct_test_poly\n",
    "del X_struct_train_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also for plot synopsis data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.105938Z",
     "start_time": "2020-04-07T01:11:03.253Z"
    }
   },
   "outputs": [],
   "source": [
    "X_plots_train_scaled = pd.DataFrame(plots_scaler.fit_transform(X_plots_train), \n",
    "                                    columns = X_plots_train.columns,\n",
    "                                    index = X_plots_train.index)\n",
    "\n",
    "X_plots_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.106761Z",
     "start_time": "2020-04-07T01:11:03.270Z"
    }
   },
   "outputs": [],
   "source": [
    "# Againâ€” only transform(), no fit_transform() here\n",
    "X_plots_test_scaled = pd.DataFrame(plots_scaler.transform(X_plots_test), \n",
    "                                   columns = X_plots_test.columns,\n",
    "                                   index = X_plots_test.index)\n",
    "\n",
    "X_plots_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.107515Z",
     "start_time": "2020-04-07T01:11:03.286Z"
    }
   },
   "outputs": [],
   "source": [
    "del X_plots_test\n",
    "del X_plots_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.108306Z",
     "start_time": "2020-04-07T01:11:03.307Z"
    }
   },
   "outputs": [],
   "source": [
    "X_plots_train_scaled.to_pickle(\"../data/pickles/X_plots_train_scaled.pkl\")\n",
    "X_plots_test_scaled.to_pickle('../data/pickles/X_plots_test_scaled.pkl')\n",
    "\n",
    "X_struct_train_poly_scaled.to_pickle(\"../data/pickles/X_struct_train_poly_scaled.pkl\")\n",
    "X_struct_test_poly_scaled.to_pickle(\"../data/pickles/X_struct_test_poly_scaled.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building / Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.109085Z",
     "start_time": "2020-04-07T01:11:03.326Z"
    }
   },
   "outputs": [],
   "source": [
    "X_struct_train_poly_scaled = pd.read_pickle(\"../data/pickles/X_struct_train_poly_scaled.pkl\")\n",
    "X_struct_test_poly_scaled = pd.read_pickle(\"../data/pickles/X_struct_test_poly_scaled.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.109874Z",
     "start_time": "2020-04-07T01:11:03.344Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train = pd.read_pickle('../data/pickles/y_train.pkl')\n",
    "y_test = pd.read_pickle('../data/pickles/y_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.110621Z",
     "start_time": "2020-04-07T01:11:03.360Z"
    }
   },
   "outputs": [],
   "source": [
    "X_struct_train_poly_scaled.shape[0], X_struct_test_poly_scaled.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.111421Z",
     "start_time": "2020-04-07T01:11:03.376Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train.shape[0], y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.112167Z",
     "start_time": "2020-04-07T01:11:03.393Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_error_metrics(y_actual, y_preds, name, draw_scatter=True):\n",
    "    ys = (y_actual, y_preds)\n",
    "    metrics = dict()\n",
    "    metrics[\"r^2\"] = r2_score(*ys)\n",
    "    metrics[\"MSE\"] = mean_squared_error(*ys)\n",
    "    metrics[\"Med_AE\"] = median_absolute_error(*ys) # Nicely robust to outliers\n",
    "    rounded_metrics = {k:round(v,3) for k,v in metrics.items()}\n",
    "    if draw_scatter:\n",
    "        colors = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "        for y, c in zip(ys, colors):\n",
    "            plt.scatter(range(len(y)), y, color=c)\n",
    "    return pd.Series(rounded_metrics, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very very naive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.112892Z",
     "start_time": "2020-04-07T01:11:03.413Z"
    }
   },
   "outputs": [],
   "source": [
    "dummy_regr_critics = DummyRegressor(strategy=\"median\")\n",
    "dummy_regr_revenue = DummyRegressor(strategy=\"mean\")\n",
    "\n",
    "dummy_regr_critics.fit(X_struct_train_poly_scaled, y_train.imdb_score)\n",
    "dummy_regr_revenue.fit(X_struct_train_poly_scaled, y_train.revenue)\n",
    "\n",
    "ypred_critics_dummy = pd.Series(dummy_regr_critics.predict(X_struct_test_poly_scaled),\n",
    "                                index=y_test.index)\n",
    "\n",
    "del dummy_regr_critics\n",
    "\n",
    "ypred_revenue_dummy = pd.Series(dummy_regr_revenue.predict(X_struct_test_poly_scaled),\n",
    "                                index=y_test.index)\n",
    "\n",
    "del dummy_regr_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.113776Z",
     "start_time": "2020-04-07T01:11:03.433Z"
    }
   },
   "outputs": [],
   "source": [
    "scores_critics_dummy = get_error_metrics(y_test.imdb_score, ypred_critics_dummy, \"critics_dummy\")\n",
    "del ypred_critics_dummy\n",
    "scores_critics_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.114570Z",
     "start_time": "2020-04-07T01:11:03.449Z"
    }
   },
   "outputs": [],
   "source": [
    "scores_revenue_dummy = get_error_metrics(y_test.revenue, ypred_revenue_dummy, \"revenue_dummy\")\n",
    "del ypred_revenue_dummy\n",
    "scores_revenue_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a linear regressor, but one that can prune out seemingly irrelevant features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear: Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.115355Z",
     "start_time": "2020-04-07T01:11:03.468Z"
    }
   },
   "outputs": [],
   "source": [
    "lasso_regr_critics = LassoCV(cv=5, random_state=0)\n",
    "lasso_regr_revenue = LassoCV(cv=5, random_state=0)\n",
    "\n",
    "lasso_regr_critics.fit(X_struct_train_poly_scaled, y_train.imdb_score)\n",
    "lasso_regr_revenue.fit(X_struct_train_poly_scaled, y_train.revenue)\n",
    "\n",
    "ypred_critics_lasso = pd.Series(lasso_regr_critics.predict(X_struct_test_poly_scaled),\n",
    "                                index=y_test.index)\n",
    "\n",
    "del lasso_regr_critics\n",
    "\n",
    "ypred_revenue_lasso = pd.Series(lasso_regr_revenue.predict(X_struct_test_poly_scaled),\n",
    "                                index=y_test.index)\n",
    "\n",
    "del lasso_regr_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.116153Z",
     "start_time": "2020-04-07T01:11:03.486Z"
    }
   },
   "outputs": [],
   "source": [
    "scores_critics_lasso = get_error_metrics(y_test.imdb_score, \n",
    "                                         ypred_critics_lasso, \n",
    "                                         \"critics_lasso\")\n",
    "del ypred_critics_lasso\n",
    "\n",
    "scores_critics_lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow kinda decent at predicting critic scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.116940Z",
     "start_time": "2020-04-07T01:11:03.503Z"
    }
   },
   "outputs": [],
   "source": [
    "scores_revenue_lasso = get_error_metrics(y_test.revenue, \n",
    "                                         ypred_revenue_lasso, \n",
    "                                         \"revenue_lasso\")\n",
    "\n",
    "del ypred_revenue_lasso\n",
    "\n",
    "scores_revenue_lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes, significant error on box office scores. Probably has to do with all the zero values in the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People online say that if you have lots of zeroes in your dependent continuous variable, then maybe you should just make a classifier which buckets things into (hopefully) zero and non-zero samples, then train and run your regression model on the non-zero samples. Cool idea, but this is my secondary DV and I'd like to focus on IMdB critic scores for now, so I'll just move on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding in Plot Synopsis Decomposition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.117727Z",
     "start_time": "2020-04-07T01:11:03.522Z"
    }
   },
   "outputs": [],
   "source": [
    "X_struct_train_poly_scaled = pd.read_pickle(\"../data/pickles/X_struct_train_poly_scaled.pkl\")\n",
    "X_struct_test_poly_scaled = pd.read_pickle(\"../data/pickles/X_struct_test_poly_scaled.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.118532Z",
     "start_time": "2020-04-07T01:11:03.537Z"
    }
   },
   "outputs": [],
   "source": [
    "X_plots_train_scaled = pd.read_pickle('../data/pickles/X_plots_train_scaled.pkl')\n",
    "X_plots_test_scaled  = pd.read_pickle('../data/pickles/X_plots_test_scaled.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.119385Z",
     "start_time": "2020-04-07T01:11:03.552Z"
    }
   },
   "outputs": [],
   "source": [
    "n_text_cols = X_plots_train_scaled.shape[1]\n",
    "n_text_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.120136Z",
     "start_time": "2020-04-07T01:11:03.569Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_struct_train_poly_scaled, \n",
    "                     X_plots_train_scaled],\n",
    "              axis=1)\n",
    "\n",
    "del X_struct_train_poly_scaled\n",
    "del X_plots_train_scaled\n",
    "\n",
    "X_test = pd.concat([X_struct_test_poly_scaled,\n",
    "                    X_plots_test_scaled],\n",
    "                   axis=1)\n",
    "\n",
    "\n",
    "del X_struct_test_poly_scaled\n",
    "del X_plots_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.120848Z",
     "start_time": "2020-04-07T01:11:03.585Z"
    }
   },
   "outputs": [],
   "source": [
    "len(X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do some PCA on the text features, given the large feature space with the plot text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.121668Z",
     "start_time": "2020-04-07T01:11:03.613Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.122405Z",
     "start_time": "2020-04-07T01:11:03.629Z"
    }
   },
   "outputs": [],
   "source": [
    "lasso_critics_withplots = LassoCV(cv=5, random_state=0)\n",
    "\n",
    "# ypred_critics_withplots = pd.Series(lasso_regr_critics.predict(X_struct_test_poly_scaled),\n",
    "#                                 index=y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.123201Z",
     "start_time": "2020-04-07T01:11:03.647Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a pipeline to search for the best PCA truncation\n",
    "pca = PCA()\n",
    "pipe = Pipeline(steps=[('pca', pca), \n",
    "                       ('lasso', lasso_critics_withplots)])\n",
    "\n",
    "X_digits, y_digits = datasets.load_digits(return_X_y=True)\n",
    "\n",
    "# Parameters of pipelines can be set using â€˜__â€™ separated parameter names:\n",
    "param_grid = {\n",
    "    'pca__n_components': [5, 15, 30, 45, 64],\n",
    "    'logistic__C': np.logspace(-4, 4, 4),\n",
    "}\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
    "search.fit(X_struct_train_poly_scaled, y_train.imdb_score)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Parametric: Linear SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heavyweight Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Text as Predictive Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.123971Z",
     "start_time": "2020-04-07T01:11:03.726Z"
    }
   },
   "outputs": [],
   "source": [
    "X_plots_test_scaled = pd.read_pickle('../data/pickles/X_plots_test_scaled.pkl')\n",
    "X_plots_train_scaled = pd.read_pickle(\"../data/pickles/X_plots_train_scaled.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "513px",
    "left": "1548px",
    "right": "20px",
    "top": "115px",
    "width": "355px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
