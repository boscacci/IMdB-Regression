{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good Film // Bad Film\n",
    "## Predicting IMdB Critic Scores with Pre-Release Movie Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook builds and evaluates a handful of regression models which predict critical reception scores for films. Independent variables include plot synopsis free text, social media metrics on the leading actors, and other categorical variables such as film genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:49:26.378537Z",
     "start_time": "2020-04-07T01:49:26.372514Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Data Wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "# Viz\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# Python Extras\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "from unicodedata import normalize\n",
    "\n",
    "# API Calls and Parsing\n",
    "import requests\n",
    "from pycountry import languages\n",
    "\n",
    "# NLP Tools\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Model Building and Prep\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import mean_squared_error, median_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From https://www.kaggle.com/tmdb/tmdb-movie-metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:00.273372Z",
     "start_time": "2020-04-07T01:11:00.247461Z"
    }
   },
   "outputs": [],
   "source": [
    "kaggle_data = pd.read_csv('../data/imdb_5000_movies.csv') # Just a big Kaggle dataset full of movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:00.278981Z",
     "start_time": "2020-04-07T01:11:00.274614Z"
    }
   },
   "outputs": [],
   "source": [
    "kaggle_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Metadata from TheMovieDB.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One good thing about this dataset is that it provides the unique IMdB movie ID's, which we can pass to a third-party API in order to supplement our data with more features. Here we parse out those IMdB ID's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:00.301058Z",
     "start_time": "2020-04-07T01:11:00.280095Z"
    }
   },
   "outputs": [],
   "source": [
    "kaggle_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab IMdB ID numbers for each film and append to dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:00.306106Z",
     "start_time": "2020-04-07T01:11:00.302109Z"
    }
   },
   "outputs": [],
   "source": [
    "imdb_ids = kaggle_data['movie_imdb_link'].str[26:35]\n",
    "# imdb_ids[3000:3005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:00.310073Z",
     "start_time": "2020-04-07T01:11:00.307260Z"
    }
   },
   "outputs": [],
   "source": [
    "kaggle_data['imdb_ids'] = imdb_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we make the API calls, and persist our data to little .json files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:00.314222Z",
     "start_time": "2020-04-07T01:11:00.312112Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('../data/movie_metadata')\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__This will make lots of API calls, be warned and use sparingly__, to avoid burning out your API key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to enter your own API key in the API_KEY.py file (remove the .template suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:00.317605Z",
     "start_time": "2020-04-07T01:11:00.315610Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from API_KEY import API_KEY\n",
    "# i=0; j=0; total=len(imdb_ids)\n",
    "\n",
    "# for id in imdb_ids:\n",
    "#     print(f\"Downloading movie {i} of {total}...\")\n",
    "#     i+=1\n",
    "#     query_string = f'https://api.themoviedb.org/3/movie/{id}?api_key={API_KEY}'\n",
    "#     json = requests.get(query_string).text\n",
    "#     if \"could not be found\" in json:\n",
    "#         j+=1\n",
    "#         print(f\"{round(j/i, 2)}% of movies not found\")\n",
    "#         continue\n",
    "#     f = open(f'../data/movie_metadata/movie_{id}.json', 'w+')\n",
    "#     f.write(json)\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Kaggle Dataset and TheMovieDB API Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:10.482000Z",
     "start_time": "2020-04-07T01:14:08.924524Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tmdb_movies = pd.DataFrame()\n",
    "\n",
    "for filename in os.listdir(path='../data/movie_metadata/'):\n",
    "    if \"movie\" in filename:\n",
    "        this_movie = pd.read_json(f\"../data/movie_metadata/{filename}\", lines=True)\n",
    "        tmdb_movies = pd.concat([this_movie,tmdb_movies], axis=0)\n",
    "\n",
    "tmdb_movies = tmdb_movies.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:10.506267Z",
     "start_time": "2020-04-07T01:15:10.483244Z"
    }
   },
   "outputs": [],
   "source": [
    "df_merged = tmdb_movies.merge(kaggle_data, \n",
    "                              how='left',\n",
    "                              left_on='imdb_id',\n",
    "                              right_on='imdb_ids',\n",
    "                              suffixes=(\"_kaggle\",\"_api\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:10.511729Z",
     "start_time": "2020-04-07T01:15:10.508047Z"
    }
   },
   "outputs": [],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep only interesting columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:10.517811Z",
     "start_time": "2020-04-07T01:15:10.513525Z"
    }
   },
   "outputs": [],
   "source": [
    "df_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:10.521906Z",
     "start_time": "2020-04-07T01:15:10.519322Z"
    }
   },
   "outputs": [],
   "source": [
    "desired_cols = (\"imdb_id duration adult budget_api budget_kaggle language original_language \"\n",
    "                \"production_countries runtime spoken_languages color genres_api \"\n",
    "                \"title movie_title original_title overview content_rating \"\n",
    "                \"actor_1_facebook_likes actor_2_facebook_likes actor_3_facebook_likes \"\n",
    "                \"director_facebook_likes cast_total_facebook_likes facenumber_in_poster \"\n",
    "                \"aspect_ratio imdb_score revenue\").split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:10.561276Z",
     "start_time": "2020-04-07T01:15:10.523489Z"
    }
   },
   "outputs": [],
   "source": [
    "df_lesscols = df_merged[desired_cols]\n",
    "df_lesscols.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:10.579129Z",
     "start_time": "2020-04-07T01:15:10.562422Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_lesscols[\n",
    "    df_lesscols.imdb_id.duplicated(keep=False)\n",
    "].sort_values('imdb_id')[\n",
    "    \"imdb_id duration title language\".split()\n",
    "].head(51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:10.598160Z",
     "start_time": "2020-04-07T01:15:10.581499Z"
    }
   },
   "outputs": [],
   "source": [
    "df_lesscols[\n",
    "    df_lesscols.imdb_id.duplicated(keep=False)\n",
    "].sort_values('imdb_id')[\n",
    "    \"imdb_id duration title language\".split()\n",
    "].tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:10.607928Z",
     "start_time": "2020-04-07T01:15:10.599659Z"
    }
   },
   "outputs": [],
   "source": [
    "df_lesscols = df_lesscols.drop_duplicates(subset='imdb_id').set_index(\"imdb_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:10.633442Z",
     "start_time": "2020-04-07T01:15:10.608969Z"
    }
   },
   "outputs": [],
   "source": [
    "df_lesscols.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null Values Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are all of the truly \"null\" values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:10.872217Z",
     "start_time": "2020-04-07T01:15:10.634636Z"
    }
   },
   "outputs": [],
   "source": [
    "nulls = df_lesscols.isna().sum()[df_lesscols.isna().sum() > 0].sort_values(ascending=False)\n",
    "\n",
    "nulls.plot(kind='bar', figsize=(15,8)).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gotta start somewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Budget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two disparate budget columns to draw from. We want whatever seems most plausible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:10.880680Z",
     "start_time": "2020-04-07T01:15:10.873566Z"
    }
   },
   "outputs": [],
   "source": [
    "df_lesscols[[\"budget_api\", \"budget_kaggle\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of nulls in budget_api, lots of zeroes in budget_kaggle. How best to handle this? And are there other columns where we just have a bunch of zero values instead of nulls (revenue??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:10.885836Z",
     "start_time": "2020-04-07T01:15:10.881974Z"
    }
   },
   "outputs": [],
   "source": [
    "def best_guess_budget(row):\n",
    "    # When budget_api is NaN and budget_kaggle is non-zero, take budget_kaggle.\n",
    "    if row.isna()[\"budget_api\"] and row['budget_kaggle'] != 0:\n",
    "        return row['budget_kaggle']\n",
    "    \n",
    "    # When budget_api is not NaN but budget_kaggle is zero, take budget_api.\n",
    "    elif not row.isna()[\"budget_api\"] and row['budget_kaggle'] == 0:\n",
    "        return row['budget_api']\n",
    "    \n",
    "    # When both values are not NaN / non-zero, take the mean?\n",
    "    elif not row.isna()[\"budget_api\"] and row['budget_kaggle'] != 0:\n",
    "        return np.mean((row['budget_kaggle'], row['budget_api']))\n",
    "        \n",
    "    # When budget_api is NaN AND budget_kaggle is zero...that's tough. Maybe drop row. Consider imputing values?\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:10.896154Z",
     "start_time": "2020-04-07T01:15:10.887252Z"
    }
   },
   "outputs": [],
   "source": [
    "df_lesscols.head(10).apply(best_guess_budget, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the desired behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:12.373924Z",
     "start_time": "2020-04-07T01:15:10.897132Z"
    }
   },
   "outputs": [],
   "source": [
    "best_budget = df_lesscols.apply(best_guess_budget, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:12.381047Z",
     "start_time": "2020-04-07T01:15:12.375054Z"
    }
   },
   "outputs": [],
   "source": [
    "df_best_guess_budget = df_lesscols.assign(best_budget=best_budget\n",
    "                                         ).drop(\"budget_api budget_kaggle\".split(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:12.386343Z",
     "start_time": "2020-04-07T01:15:12.382393Z"
    }
   },
   "outputs": [],
   "source": [
    "df_best_guess_budget.best_budget.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5% of budget values are missing. I think I will in fact impute the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:12.392988Z",
     "start_time": "2020-04-07T01:15:12.387582Z"
    }
   },
   "outputs": [],
   "source": [
    "budget_med = df_best_guess_budget.best_budget.dropna().median()\n",
    "budget_mean = df_best_guess_budget.best_budget.dropna().mean()\n",
    "budget_med, budget_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:12.400542Z",
     "start_time": "2020-04-07T01:15:12.393988Z"
    }
   },
   "outputs": [],
   "source": [
    "df_filled_budget = df_best_guess_budget.assign(\n",
    "    filled_budget = df_best_guess_budget[\"best_budget\"].fillna(budget_med)\n",
    ").drop([\"best_budget\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:12.405690Z",
     "start_time": "2020-04-07T01:15:12.401986Z"
    }
   },
   "outputs": [],
   "source": [
    "df_filled_budget.filled_budget.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:12.410752Z",
     "start_time": "2020-04-07T01:15:12.406991Z"
    }
   },
   "outputs": [],
   "source": [
    "df_filled_budget.filled_budget.median(), df_filled_budget.filled_budget.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't seem to have shifted the mean much, that's good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aspect Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:12.416026Z",
     "start_time": "2020-04-07T01:15:12.412115Z"
    }
   },
   "outputs": [],
   "source": [
    "df_filled_budget.aspect_ratio.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6% of aspect ratios are null."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a categorical describing the dimensions of the projected image. Your TV set is 16x9 aka 1.77 aspect ratio, whereas lots of hollywood films are 1.85 ratio or 2.40, much \"wider-screen\". 2.40 might be \"artsier\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:12.628947Z",
     "start_time": "2020-04-07T01:15:12.419729Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aspect ratio of 16 I take to mean 16x9 aka 1.77:\n",
    "df_filled_budget.aspect_ratio = df_filled_budget.aspect_ratio.apply(lambda x: 1.77 if x==16 else x)\n",
    "df_filled_budget.aspect_ratio.value_counts().sort_index().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think I will lump some of these together and impute 1.85 on null values. It's not *quite* the mode but it's a sort of middle-of-the road aspect ratio. The DCI standard lists 2.39 and 1.85 for theatrical projection. 16x9 or 1.77 is also common, and 4/3 or 1.33 is like an old-timey boxey aspect ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:12.634262Z",
     "start_time": "2020-04-07T01:15:12.631392Z"
    }
   },
   "outputs": [],
   "source": [
    "aspect_bins = [0, np.mean((1.33, 1.77)), np.mean((1.77,1.85)), np.mean((1.85,2.39)), np.inf]\n",
    "aspect_labels = \"1.33 1.77 1.85 2.39\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:12.643377Z",
     "start_time": "2020-04-07T01:15:12.635665Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.cut(df_filled_budget.aspect_ratio, \n",
    "       bins=aspect_bins, \n",
    "       labels=aspect_labels,\n",
    "       include_lowest=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lump values and impute 1.85:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:12.652701Z",
     "start_time": "2020-04-07T01:15:12.644801Z"
    }
   },
   "outputs": [],
   "source": [
    "df_fixed_aspect = df_filled_budget.assign(fixed_aspect = pd.cut(df_filled_budget.aspect_ratio, \n",
    "                                                         bins=aspect_bins, \n",
    "                                                         labels=aspect_labels,\n",
    "                                                         include_lowest=True\n",
    "                                                               ).fillna(\"1.85\")\n",
    "                                         ).drop([\"aspect_ratio\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:12.762940Z",
     "start_time": "2020-04-07T01:15:12.653932Z"
    }
   },
   "outputs": [],
   "source": [
    "df_fixed_aspect.fixed_aspect.value_counts().sort_index().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:12.767773Z",
     "start_time": "2020-04-07T01:15:12.764005Z"
    }
   },
   "outputs": [],
   "source": [
    "df_fixed_aspect.content_rating.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:12.953754Z",
     "start_time": "2020-04-07T01:15:12.769272Z"
    }
   },
   "outputs": [],
   "source": [
    "df_fixed_aspect.content_rating.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just gonna fill nulls with PG-13 and condense redundant ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:12.958929Z",
     "start_time": "2020-04-07T01:15:12.954867Z"
    }
   },
   "outputs": [],
   "source": [
    "df_content_rating_filled = df_fixed_aspect.assign(\n",
    "                                content_rating=df_fixed_aspect.content_rating.fillna(\"PG-13\")\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:12.963619Z",
     "start_time": "2020-04-07T01:15:12.960335Z"
    }
   },
   "outputs": [],
   "source": [
    "def rating_mapper(rating):\n",
    "    if rating == \"Not Rated\":\n",
    "        return \"Unrated\"\n",
    "    elif rating in \"Approved Passed M TV-14\".split():\n",
    "        return \"PG-13\"\n",
    "    elif rating in \"TV-G GP G TV-PG\".split():\n",
    "        return \"PG\"\n",
    "    elif rating in [\"NC-17\"]:\n",
    "        return \"X\"\n",
    "    else:\n",
    "        return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:12.972097Z",
     "start_time": "2020-04-07T01:15:12.964766Z"
    }
   },
   "outputs": [],
   "source": [
    "df_content_rating_condensed = df_content_rating_filled.assign(\n",
    "                                content_rating = df_content_rating_filled.content_rating.map(rating_mapper)\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:13.109139Z",
     "start_time": "2020-04-07T01:15:12.973342Z"
    }
   },
   "outputs": [],
   "source": [
    "df_content_rating_condensed.content_rating.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:13.113747Z",
     "start_time": "2020-04-07T01:15:13.110253Z"
    }
   },
   "outputs": [],
   "source": [
    "df_content_rating_condensed.content_rating.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are we doing on null values globally?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:13.323566Z",
     "start_time": "2020-04-07T01:15:13.114899Z"
    }
   },
   "outputs": [],
   "source": [
    "nulls_update = df_content_rating_condensed.isna().sum()[\n",
    "    df_content_rating_condensed.isna().sum() > 0\n",
    "].sort_values(ascending=False)\n",
    "\n",
    "nulls_update.plot(kind='bar', figsize=(15,8), rot=45).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearing some memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:13.328670Z",
     "start_time": "2020-04-07T01:15:13.324585Z"
    }
   },
   "outputs": [],
   "source": [
    "del nulls\n",
    "del imdb_ids\n",
    "del kaggle_data\n",
    "del best_budget\n",
    "del df_lesscols\n",
    "del df_best_guess_budget\n",
    "del df_filled_budget\n",
    "del df_content_rating_filled\n",
    "del df_fixed_aspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facebook Like Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:13.341915Z",
     "start_time": "2020-04-07T01:15:13.330131Z"
    }
   },
   "outputs": [],
   "source": [
    "facebook_like_cols = [col for col in df_content_rating_condensed if \"facebook\" in col]\n",
    "likes = df_content_rating_condensed[facebook_like_cols]\n",
    "\n",
    "df_content_rating_condensed.drop(facebook_like_cols, axis=1, inplace=True)\n",
    "\n",
    "likes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:13.350172Z",
     "start_time": "2020-04-07T01:15:13.342949Z"
    }
   },
   "outputs": [],
   "source": [
    "(round(likes.isna().mean()*100,2)).sort_values(ascending=False).astype('str')+\"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not that many values are missing. Will just use the medians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:13.358537Z",
     "start_time": "2020-04-07T01:15:13.351177Z"
    }
   },
   "outputs": [],
   "source": [
    "likes.fillna({col:likes[col].median() for col in likes.columns}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:13.364113Z",
     "start_time": "2020-04-07T01:15:13.359682Z"
    }
   },
   "outputs": [],
   "source": [
    "df_likes_filled = pd.concat([df_content_rating_condensed,\n",
    "                             likes], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:13.367504Z",
     "start_time": "2020-04-07T01:15:13.365097Z"
    }
   },
   "outputs": [],
   "source": [
    "del df_content_rating_condensed\n",
    "del likes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time for another check-in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:13.532437Z",
     "start_time": "2020-04-07T01:15:13.368605Z"
    }
   },
   "outputs": [],
   "source": [
    "nulls_update = df_likes_filled.isna().sum()[\n",
    "    df_likes_filled.isna().sum() > 0\n",
    "].sort_values(ascending=False)\n",
    "\n",
    "nulls_update.plot(kind='bar', figsize=(15,8), rot=45).plot()\n",
    "\n",
    "del nulls_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:13.541557Z",
     "start_time": "2020-04-07T01:15:13.534152Z"
    }
   },
   "outputs": [],
   "source": [
    "df_likes_filled.color = df_likes_filled.color.str.lstrip()\n",
    "df_likes_filled.color.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems safe to assume that the last dozen films are in color..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:13.547344Z",
     "start_time": "2020-04-07T01:15:13.542717Z"
    }
   },
   "outputs": [],
   "source": [
    "df_likes_filled.color = df_likes_filled.color.fillna(df_likes_filled.color.mode()[0])\n",
    "df_color_filled = df_likes_filled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:13.550791Z",
     "start_time": "2020-04-07T01:15:13.548413Z"
    }
   },
   "outputs": [],
   "source": [
    "del df_likes_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:13.575494Z",
     "start_time": "2020-04-07T01:15:13.551930Z"
    }
   },
   "outputs": [],
   "source": [
    "df_color_filled.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:13.580722Z",
     "start_time": "2020-04-07T01:15:13.576636Z"
    }
   },
   "outputs": [],
   "source": [
    "df_color_filled.color.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Number in Poster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:13.775031Z",
     "start_time": "2020-04-07T01:15:13.581760Z"
    }
   },
   "outputs": [],
   "source": [
    "df_color_filled.facenumber_in_poster.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero seems to be a placeholder for \"idk\" in this dataset, I'll drop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:13.803415Z",
     "start_time": "2020-04-07T01:15:13.776068Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_facenums = df_color_filled.drop(['facenumber_in_poster'],axis=1)\n",
    "del df_color_filled\n",
    "df_no_facenums.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language (\"original... spoken... language\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:13.822414Z",
     "start_time": "2020-04-07T01:15:13.804845Z"
    }
   },
   "outputs": [],
   "source": [
    "langs = df_no_facenums[[col for col in df_no_facenums.columns if \"language\" in col]]\n",
    "langs.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:13.829051Z",
     "start_time": "2020-04-07T01:15:13.823539Z"
    }
   },
   "outputs": [],
   "source": [
    "langs.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:13.836144Z",
     "start_time": "2020-04-07T01:15:13.830317Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_facenums.iloc[13,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"language\" column looks not great. \"original language\" is probably a better bet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:13.842905Z",
     "start_time": "2020-04-07T01:15:13.837369Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_facenums.spoken_languages.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:13.848608Z",
     "start_time": "2020-04-07T01:15:13.844521Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_facenums.original_language.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah I think that's probably the best column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:13.855375Z",
     "start_time": "2020-04-07T01:15:13.849686Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_facenums.original_language.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a python package to make language codes human-readable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:13.895409Z",
     "start_time": "2020-04-07T01:15:13.856471Z"
    }
   },
   "outputs": [],
   "source": [
    "lang_decoder = {lang.alpha_2: lang.name for lang in languages if hasattr(lang,'alpha_2')}\n",
    "list(lang_decoder.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:14.215543Z",
     "start_time": "2020-04-07T01:15:13.896417Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_facenums.original_language = df_no_facenums.original_language.map(lang_decoder)\n",
    "df_no_facenums.original_language.value_counts()[2:].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just eyeballing it...I think anything after German, in terms of frequency, is gonna have to go in \"other\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grabbing most popular languages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:14.221171Z",
     "start_time": "2020-04-07T01:15:14.216767Z"
    }
   },
   "outputs": [],
   "source": [
    "top_langs = df_no_facenums.original_language.value_counts().index[:3].tolist()\n",
    "top_langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:14.224999Z",
     "start_time": "2020-04-07T01:15:14.222550Z"
    }
   },
   "outputs": [],
   "source": [
    "def language_lumper(lang):\n",
    "    if lang not in top_langs:\n",
    "        return \"Other\"\n",
    "    else:\n",
    "        return lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:14.229290Z",
     "start_time": "2020-04-07T01:15:14.226155Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_facenums.original_language = df_no_facenums.original_language.apply(language_lumper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:14.234576Z",
     "start_time": "2020-04-07T01:15:14.230825Z"
    }
   },
   "outputs": [],
   "source": [
    "df_langs_lumped = df_no_facenums.drop(\"language spoken_languages\".split(),axis=1)\n",
    "del df_no_facenums\n",
    "del langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:14.259399Z",
     "start_time": "2020-04-07T01:15:14.235668Z"
    }
   },
   "outputs": [],
   "source": [
    "df_langs_lumped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:14.459339Z",
     "start_time": "2020-04-07T01:15:14.260541Z"
    }
   },
   "outputs": [],
   "source": [
    "df_langs_lumped.original_language.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:14.601958Z",
     "start_time": "2020-04-07T01:15:14.460542Z"
    }
   },
   "outputs": [],
   "source": [
    "nulls = df_langs_lumped.isna().sum()[df_langs_lumped.isna().sum() > 0].sort_values(ascending=False)\n",
    "\n",
    "nulls.plot(kind='bar', figsize=(15,8)).plot()\n",
    "\n",
    "del nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration / Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:14.610078Z",
     "start_time": "2020-04-07T01:15:14.603151Z"
    }
   },
   "outputs": [],
   "source": [
    "durs = df_langs_lumped[\"duration runtime\".split()]\n",
    "durs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T02:47:21.610275Z",
     "start_time": "2020-04-02T02:47:21.606596Z"
    }
   },
   "source": [
    "How different are these columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:14.797632Z",
     "start_time": "2020-04-07T01:15:14.611155Z"
    }
   },
   "outputs": [],
   "source": [
    "(durs.duration - durs.runtime).plot(kind='hist')\n",
    "(durs.duration - durs.runtime).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not very."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:14.802899Z",
     "start_time": "2020-04-07T01:15:14.798876Z"
    }
   },
   "outputs": [],
   "source": [
    "df_langs_lumped.drop([\"duration\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:14.819636Z",
     "start_time": "2020-04-07T01:15:14.811678Z"
    }
   },
   "outputs": [],
   "source": [
    "df_runtimes_filled = df_langs_lumped.assign(\n",
    "    durations=df_langs_lumped.runtime.fillna(\n",
    "        df_langs_lumped.runtime.median()\n",
    "    )\n",
    ").drop([\"runtime\"],axis=1)\n",
    "\n",
    "del df_langs_lumped\n",
    "del durs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:14.832878Z",
     "start_time": "2020-04-07T01:15:14.824418Z"
    }
   },
   "outputs": [],
   "source": [
    "df_runtimes_filled.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No more obvious nulls!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:14.850010Z",
     "start_time": "2020-04-07T01:15:14.833972Z"
    }
   },
   "outputs": [],
   "source": [
    "df_runtimes_filled.to_pickle(\"../data/pickles/df_no_nulls.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:14.868483Z",
     "start_time": "2020-04-07T01:15:14.851086Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_nulls = pd.read_pickle(\"../data/pickles/df_no_nulls.pkl\")\n",
    "df_no_nulls.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Adult\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:14.874422Z",
     "start_time": "2020-04-07T01:15:14.869626Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_nulls.adult.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single-value column. Drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:14.879316Z",
     "start_time": "2020-04-07T01:15:14.875471Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_adult = df_no_nulls.drop([\"adult\"],axis=1)\n",
    "del df_no_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:14.883684Z",
     "start_time": "2020-04-07T01:15:14.880430Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_adult.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Production Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:14.889775Z",
     "start_time": "2020-04-07T01:15:14.884835Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_adult['production_countries'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm list of dict. Let's just grab the human-readable names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:14.893456Z",
     "start_time": "2020-04-07T01:15:14.890886Z"
    }
   },
   "outputs": [],
   "source": [
    "def prod_countries_extractor(countries):\n",
    "    if len(countries)!=0:\n",
    "        return {country['name'] for country in countries}\n",
    "    else:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:14.901480Z",
     "start_time": "2020-04-07T01:15:14.894557Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_adult.production_countries = df_no_adult.production_countries.apply(prod_countries_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:14.907109Z",
     "start_time": "2020-04-07T01:15:14.902602Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_adult.production_countries.iloc[29:34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:15.055032Z",
     "start_time": "2020-04-07T01:15:14.908196Z"
    }
   },
   "outputs": [],
   "source": [
    "# Turns out pandas vectorized string operations work on lists too\n",
    "ax = df_no_adult.production_countries.str.len().value_counts().sort_index().plot(kind='bar')\n",
    "ax.set_xlabel(\"N countries\")\n",
    "ax.set_ylabel(\"N Films\")\n",
    "ax.plot()\n",
    "del ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I feel like that ^ can become an int column, after the zeroes are fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:15.075260Z",
     "start_time": "2020-04-07T01:15:15.056170Z"
    }
   },
   "outputs": [],
   "source": [
    "# If it's not in English, can we guess where it was filmed?\n",
    "df_no_adult[(\n",
    "                df_no_adult.production_countries.str.len()==0\n",
    "            )&(\n",
    "                df_no_adult.original_language!=\"English\"\n",
    "            )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:15.081145Z",
     "start_time": "2020-04-07T01:15:15.076646Z"
    }
   },
   "outputs": [],
   "source": [
    "guesses = {480:\"Germany\", \n",
    "           2051:\"Germany\",\n",
    "           2260:\"India\",\n",
    "           3242:\"India\"}\n",
    "\n",
    "for index, country in guesses.items():\n",
    "    df_no_adult['production_countries'].iloc[index] = country\n",
    "    \n",
    "del index\n",
    "del country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:15.100789Z",
     "start_time": "2020-04-07T01:15:15.082333Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame([df_no_adult.iloc[i,:] for i in guesses.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:15.104501Z",
     "start_time": "2020-04-07T01:15:15.101919Z"
    }
   },
   "outputs": [],
   "source": [
    "del guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:15.126164Z",
     "start_time": "2020-04-07T01:15:15.105750Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_adult.production_countries.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:15.129690Z",
     "start_time": "2020-04-07T01:15:15.127412Z"
    }
   },
   "outputs": [],
   "source": [
    "def fill_with_USA(country_set):\n",
    "    return {\"United States of America\"} if country_set == {} else country_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:15.134409Z",
     "start_time": "2020-04-07T01:15:15.130844Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_adult[\"production_countries\"] = df_no_adult.production_countries.apply(fill_with_USA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:15.138590Z",
     "start_time": "2020-04-07T01:15:15.135508Z"
    }
   },
   "outputs": [],
   "source": [
    "df_filled_USA = df_no_adult.copy()\n",
    "del df_no_adult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Might need to split into USA and not-USA to deal with class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:15.142677Z",
     "start_time": "2020-04-07T01:15:15.139961Z"
    }
   },
   "outputs": [],
   "source": [
    "def usa_or_not(country_set):\n",
    "    return 0 if country_set=={\"United States of America\"} else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:15.239203Z",
     "start_time": "2020-04-07T01:15:15.143857Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = df_filled_USA.production_countries.apply(usa_or_not).value_counts().plot(kind='bar')\n",
    "ax.set_xlabel(\"Shot only in USA\")\n",
    "del ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:15.245038Z",
     "start_time": "2020-04-07T01:15:15.240386Z"
    }
   },
   "outputs": [],
   "source": [
    "df_filled_USA['shot_only_in_USA'] = df_filled_USA.production_countries.apply(usa_or_not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:15.248774Z",
     "start_time": "2020-04-07T01:15:15.246242Z"
    }
   },
   "outputs": [],
   "source": [
    "def shot_in_usa_and_abroad(country_set):\n",
    "    if len(country_set)>1 and \"United States of America\" in country_set:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:15.254487Z",
     "start_time": "2020-04-07T01:15:15.249731Z"
    }
   },
   "outputs": [],
   "source": [
    "df_filled_USA['shot_in_USA_and_abroad'] = df_filled_USA.production_countries.apply(shot_in_usa_and_abroad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:15.369390Z",
     "start_time": "2020-04-07T01:15:15.255781Z"
    }
   },
   "outputs": [],
   "source": [
    "df_filled_USA['shot_in_USA_and_abroad'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:15.471663Z",
     "start_time": "2020-04-07T01:15:15.370496Z"
    }
   },
   "outputs": [],
   "source": [
    "df_filled_USA['n_production_countries'] = df_filled_USA.production_countries.str.len()\n",
    "df_filled_USA['n_production_countries'].plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:15.477152Z",
     "start_time": "2020-04-07T01:15:15.473080Z"
    }
   },
   "outputs": [],
   "source": [
    "df_n_countries = df_filled_USA.drop([\"production_countries\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:15.480591Z",
     "start_time": "2020-04-07T01:15:15.478210Z"
    }
   },
   "outputs": [],
   "source": [
    "del df_filled_USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:15.485129Z",
     "start_time": "2020-04-07T01:15:15.481778Z"
    }
   },
   "outputs": [],
   "source": [
    "df_n_countries.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:15.497967Z",
     "start_time": "2020-04-07T01:15:15.486652Z"
    }
   },
   "outputs": [],
   "source": [
    "df_n_countries['genre'] = df_n_countries['genres_api'].str.split(\"|\")\n",
    "df_n_countries['genre'] = df_n_countries['genre'].apply(lambda x: set(x))\n",
    "del df_n_countries[\"genres_api\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:15.544834Z",
     "start_time": "2020-04-07T01:15:15.499120Z"
    }
   },
   "outputs": [],
   "source": [
    "df_n_countries['genre'].apply(lambda x: set(x)).value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:15.548192Z",
     "start_time": "2020-04-07T01:15:15.545915Z"
    }
   },
   "outputs": [],
   "source": [
    "genre_cats = \"Drama Comedy Romance Crime Thriller Horror Action Mystery Sci-Fi Adventure Documentary\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:15.552177Z",
     "start_time": "2020-04-07T01:15:15.549272Z"
    }
   },
   "outputs": [],
   "source": [
    "def genre_encoder(genre_set):\n",
    "    new = pd.Series(0, index=genre_cats)\n",
    "    for genre in genre_set:\n",
    "        if genre in genre_cats:\n",
    "            new[genre] = 1\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:15.557852Z",
     "start_time": "2020-04-07T01:15:15.553458Z"
    }
   },
   "outputs": [],
   "source": [
    "df_n_countries.genre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:15.569581Z",
     "start_time": "2020-04-07T01:15:15.559005Z"
    }
   },
   "outputs": [],
   "source": [
    "df_n_countries.genre.head().apply(genre_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:17.025595Z",
     "start_time": "2020-04-07T01:15:15.570710Z"
    }
   },
   "outputs": [],
   "source": [
    "genre_matrix = df_n_countries.genre.apply(genre_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:17.028899Z",
     "start_time": "2020-04-07T01:15:17.026679Z"
    }
   },
   "outputs": [],
   "source": [
    "del df_n_countries['genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:17.032912Z",
     "start_time": "2020-04-07T01:15:17.030014Z"
    }
   },
   "outputs": [],
   "source": [
    "genre_matrix.columns = [\"\".join([\"genre_\", col]) for col in genre_matrix.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:17.038373Z",
     "start_time": "2020-04-07T01:15:17.033888Z"
    }
   },
   "outputs": [],
   "source": [
    "df_encoded_genres = pd.concat([df_n_countries,genre_matrix],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:17.041891Z",
     "start_time": "2020-04-07T01:15:17.039615Z"
    }
   },
   "outputs": [],
   "source": [
    "del df_n_countries\n",
    "del genre_matrix\n",
    "del genre_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:17.053009Z",
     "start_time": "2020-04-07T01:15:17.043118Z"
    }
   },
   "outputs": [],
   "source": [
    "df_encoded_genres.to_pickle(\"../data/pickles/df_encoded_genres.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:17.063873Z",
     "start_time": "2020-04-07T01:15:17.054186Z"
    }
   },
   "outputs": [],
   "source": [
    "df_encoded_genres = pd.read_pickle(\"../data/pickles/df_encoded_genres.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:17.068428Z",
     "start_time": "2020-04-07T01:15:17.064956Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_encoded_genres.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facebook Likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:17.079274Z",
     "start_time": "2020-04-07T01:15:17.069485Z"
    }
   },
   "outputs": [],
   "source": [
    "likes = df_encoded_genres[[col for col in df_encoded_genres.columns if \"likes\" in col]]\n",
    "likes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:17.086914Z",
     "start_time": "2020-04-07T01:15:17.080409Z"
    }
   },
   "outputs": [],
   "source": [
    "likes.actor_1_facebook_likes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:17.292078Z",
     "start_time": "2020-04-07T01:15:17.087954Z"
    }
   },
   "outputs": [],
   "source": [
    "likes.actor_1_facebook_likes.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could probably use a log transform or something. Or is it just full of zeroes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:17.297048Z",
     "start_time": "2020-04-07T01:15:17.293105Z"
    }
   },
   "outputs": [],
   "source": [
    "likes.actor_1_facebook_likes[likes.actor_1_facebook_likes < 5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:17.302352Z",
     "start_time": "2020-04-07T01:15:17.298295Z"
    }
   },
   "outputs": [],
   "source": [
    "likes.director_facebook_likes[likes.director_facebook_likes == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:17.309811Z",
     "start_time": "2020-04-07T01:15:17.303425Z"
    }
   },
   "outputs": [],
   "source": [
    "likes.director_facebook_likes.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm willing to believe that directors are just generally not as popular as their actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:17.527395Z",
     "start_time": "2020-04-07T01:15:17.310801Z"
    }
   },
   "outputs": [],
   "source": [
    "# +1 like for boxcox, does not like zeroes\n",
    "pd.Series(boxcox(likes.actor_1_facebook_likes+1)[0]).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:17.552729Z",
     "start_time": "2020-04-07T01:15:17.528617Z"
    }
   },
   "outputs": [],
   "source": [
    "all_boxcoxed = [pd.Series(boxcox(likes[col]+1)[0], name=f\"{col}_box\") for col in likes.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:17.562711Z",
     "start_time": "2020-04-07T01:15:17.553788Z"
    }
   },
   "outputs": [],
   "source": [
    "boxed_df = pd.concat(all_boxcoxed,axis=1)\n",
    "boxed_df.index = df_encoded_genres.index\n",
    "boxed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:18.548613Z",
     "start_time": "2020-04-07T01:15:17.563829Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in boxed_df:\n",
    "    plt.figure()\n",
    "    plt.hist(boxed_df[col])\n",
    "    print(col)\n",
    "    plt.show()\n",
    "del col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:18.553653Z",
     "start_time": "2020-04-07T01:15:18.549910Z"
    }
   },
   "outputs": [],
   "source": [
    "no_likes = df_encoded_genres.drop([col for col in df_encoded_genres if \"likes\" in col], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:18.557177Z",
     "start_time": "2020-04-07T01:15:18.555019Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boxed_df.index = no_likes.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:18.562646Z",
     "start_time": "2020-04-07T01:15:18.558490Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_likes = pd.concat([no_likes, boxed_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:18.583427Z",
     "start_time": "2020-04-07T01:15:18.564842Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_likes.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:18.774482Z",
     "start_time": "2020-04-07T01:15:18.584607Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_likes.filled_budget.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also pretty skewed up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:18.989660Z",
     "start_time": "2020-04-07T01:15:18.775795Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_likes.filled_budget.transform(np.log).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not perfect, boxcox again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:19.207817Z",
     "start_time": "2020-04-07T01:15:18.991172Z"
    }
   },
   "outputs": [],
   "source": [
    "budget_boxed = pd.Series(boxcox(df_boxcoxed_likes.filled_budget)[0], name=\"budget_boxed\")\n",
    "budget_boxed.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:19.215661Z",
     "start_time": "2020-04-07T01:15:19.208841Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget = df_boxcoxed_likes.assign(budget_boxed=budget_boxed.values).drop(['filled_budget'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:19.234503Z",
     "start_time": "2020-04-07T01:15:19.216790Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:19.472979Z",
     "start_time": "2020-04-07T01:15:19.235564Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget.durations.hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems pretty tightly clustered around feature length film length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:19.567075Z",
     "start_time": "2020-04-07T01:15:19.474197Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget.durations.plot(kind='box',figsize=(2,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:19.825679Z",
     "start_time": "2020-04-07T01:15:19.568282Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(boxcox(df_boxcoxed_budget.durations+1)[0], name=f\"duration_box\").hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think we can just stick with the original durations, no transform needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Production Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:19.981366Z",
     "start_time": "2020-04-07T01:15:19.827046Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget.n_production_countries.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I should lump together 5+ perhaps...it gets a bit sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:20.117352Z",
     "start_time": "2020-04-07T01:15:19.982542Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget.n_production_countries.apply(lambda x: 5 if x >= 5 else x).value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:20.122924Z",
     "start_time": "2020-04-07T01:15:20.118565Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget[\"n_prod_locs_trunc\"] = df_boxcoxed_budget.n_production_countries.apply(\n",
    "                                                                                    lambda x: 5 if x >= 5 else x\n",
    "                                                                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to remember that here, the int 5 represents 5 or more countries of filming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:20.126994Z",
     "start_time": "2020-04-07T01:15:20.124259Z"
    }
   },
   "outputs": [],
   "source": [
    "del df_boxcoxed_budget[\"n_production_countries\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revenue (Secondary Response Variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My understanding is that response variables do not need to be normally distributed, for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:20.364307Z",
     "start_time": "2020-04-07T01:15:20.128086Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget.revenue.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:20.596508Z",
     "start_time": "2020-04-07T01:15:20.365937Z"
    }
   },
   "outputs": [],
   "source": [
    "(df_boxcoxed_budget[\"revenue\"]+1).transform(np.log).hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hrmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMdB Score (Response Variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:20.603813Z",
     "start_time": "2020-04-07T01:15:20.597538Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget.imdb_score.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:20.828569Z",
     "start_time": "2020-04-07T01:15:20.604933Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget.imdb_score.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:20.840634Z",
     "start_time": "2020-04-07T01:15:20.829927Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget.to_pickle(\"../data/pickles/df_boxcoxed_budget.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free Text Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:20.851782Z",
     "start_time": "2020-04-07T01:15:20.842046Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget = pd.read_pickle(\"../data/pickles/df_boxcoxed_budget.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:20.867795Z",
     "start_time": "2020-04-07T01:15:20.852812Z"
    }
   },
   "outputs": [],
   "source": [
    "titles = df_boxcoxed_budget[\"title movie_title original_title\".split()]\n",
    "titles.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:20.873591Z",
     "start_time": "2020-04-07T01:15:20.869527Z"
    }
   },
   "outputs": [],
   "source": [
    "titles['title'].iloc[0] == titles[\"movie_title\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:20.877904Z",
     "start_time": "2020-04-07T01:15:20.874898Z"
    }
   },
   "outputs": [],
   "source": [
    "titles['title'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:20.882219Z",
     "start_time": "2020-04-07T01:15:20.879105Z"
    }
   },
   "outputs": [],
   "source": [
    "titles[\"movie_title\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:20.889758Z",
     "start_time": "2020-04-07T01:15:20.883570Z"
    }
   },
   "outputs": [],
   "source": [
    "titles['movie_title'] = titles['movie_title'].apply(lambda title: normalize('NFKD', title).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:20.894429Z",
     "start_time": "2020-04-07T01:15:20.890958Z"
    }
   },
   "outputs": [],
   "source": [
    "titles['title'].iloc[0] == titles[\"movie_title\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:20.900247Z",
     "start_time": "2020-04-07T01:15:20.895651Z"
    }
   },
   "outputs": [],
   "source": [
    "titles[titles.title != titles.movie_title].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:20.912495Z",
     "start_time": "2020-04-07T01:15:20.901475Z"
    }
   },
   "outputs": [],
   "source": [
    "titles[titles.title != titles.movie_title].head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can't tell just from looking which of these is the definitive \"right\" column to use. Original_title seems more likely to be in a foreign language..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:20.925022Z",
     "start_time": "2020-04-07T01:15:20.913733Z"
    }
   },
   "outputs": [],
   "source": [
    "titles[titles.title != titles.movie_title].tail(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't think there is going to be predictive information in the title itself. Maybe I'll just grab one as a plaintext reference to the datapoint..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:20.930082Z",
     "start_time": "2020-04-07T01:15:20.926258Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget.drop(['movie_title', \"original_title\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:20.933557Z",
     "start_time": "2020-04-07T01:15:20.931328Z"
    }
   },
   "outputs": [],
   "source": [
    "del titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview / Plot Synopsis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we need to get into real NLP stuff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a peek at our plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:20.940590Z",
     "start_time": "2020-04-07T01:15:20.934761Z"
    }
   },
   "outputs": [],
   "source": [
    "[print(_,\"\\n\") for _ in df_boxcoxed_budget.overview.head(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing stopwords, POS lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:20.947844Z",
     "start_time": "2020-04-07T01:15:20.941717Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def process_plot(plot):\n",
    "    tokens = word_tokenize(plot)\n",
    "    stops_removed = [w for w in tokens if w not in stop_words]\n",
    "    punc_removed = [w.lower() for w in stops_removed if w.isalpha()]\n",
    "    tagged = [(w, get_wordnet_pos(w)) for w in punc_removed]\n",
    "    return \" \".join([lemmatizer.lemmatize(word[0], pos=word[1]) for word in tagged])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:40.713322Z",
     "start_time": "2020-04-07T01:15:20.949345Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget['plot_prepped'] = df_boxcoxed_budget.overview.apply(process_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Count Vectorizing, TF-IDF Normalizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the [sklearn docs](https://scikit-learn.org/stable/modules/feature_extraction.html#):\n",
    "\n",
    "\"The word boundaries-aware variant `char_wb` is especially interesting for languages that use white-spaces for word separation...as it...can increase both the predictive accuracy and convergence speed of classifiers trained using such features while retaining the robustness with regards to misspellings and word derivations.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:40.718191Z",
     "start_time": "2020-04-07T01:15:40.715353Z"
    }
   },
   "outputs": [],
   "source": [
    "bigram_vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(5, 5),#ngram_range=(1, 2),\n",
    "                                    token_pattern=r'\\b\\w+\\b', \n",
    "                                    min_df=1,\n",
    "                                    binary=True)\n",
    "\n",
    "# Plot synopsis texts are not very long: Using binary countvectorizer to help reduce noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:40.724302Z",
     "start_time": "2020-04-07T01:15:40.719813Z"
    }
   },
   "outputs": [],
   "source": [
    "bigram_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:40.729350Z",
     "start_time": "2020-04-07T01:15:40.725582Z"
    }
   },
   "outputs": [],
   "source": [
    "analyze = bigram_vectorizer.build_analyzer()\n",
    "analyze('Bi-grams are cool!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:41.185135Z",
     "start_time": "2020-04-07T01:15:40.730822Z"
    }
   },
   "outputs": [],
   "source": [
    "sparse_plots = bigram_vectorizer.fit_transform(df_boxcoxed_budget['plot_prepped'])\n",
    "sparse_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:41.215654Z",
     "start_time": "2020-04-07T01:15:41.186173Z"
    }
   },
   "outputs": [],
   "source": [
    "bigram_columns = bigram_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:41.604536Z",
     "start_time": "2020-04-07T01:15:41.217449Z"
    }
   },
   "outputs": [],
   "source": [
    "bigram_counts = pd.DataFrame(sparse_plots.toarray(),\n",
    "                             columns=bigram_columns)\n",
    "\n",
    "bigram_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:44.472212Z",
     "start_time": "2020-04-07T01:15:41.605592Z"
    }
   },
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer(smooth_idf=False)\n",
    "tfidf = transformer.fit_transform(bigram_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:44.900504Z",
     "start_time": "2020-04-07T01:15:44.473288Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tfidf = pd.DataFrame(tfidf.toarray(), columns=bigram_columns)\n",
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:44.906993Z",
     "start_time": "2020-04-07T01:15:44.901825Z"
    }
   },
   "outputs": [],
   "source": [
    "del bigram_columns\n",
    "del bigram_counts\n",
    "del stop_words\n",
    "del analyze\n",
    "del df_boxcoxed_budget['overview']\n",
    "del df_boxcoxed_budget['plot_prepped']\n",
    "del tfidf\n",
    "del transformer\n",
    "del wordnet\n",
    "del lemmatizer\n",
    "del languages\n",
    "del sparse_plots\n",
    "del bigram_vectorizer\n",
    "del stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:44.912914Z",
     "start_time": "2020-04-07T01:15:44.908614Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tfidf.columns[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:44.918438Z",
     "start_time": "2020-04-07T01:15:44.914111Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tfidf.columns[5000:5100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:44.922926Z",
     "start_time": "2020-04-07T01:15:44.919615Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty large feature space there. Maybe I'll incorporate some PCA in the modeling pipeline..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:44.943558Z",
     "start_time": "2020-04-07T01:15:44.924295Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:44.948678Z",
     "start_time": "2020-04-07T01:15:44.945105Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:15:44.953536Z",
     "start_time": "2020-04-07T01:15:44.949973Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:16:08.508843Z",
     "start_time": "2020-04-07T01:15:44.954805Z"
    }
   },
   "outputs": [],
   "source": [
    "df_boxcoxed_budget.to_pickle('../data/pickles/df_mostly_ready_metadata.pkl')\n",
    "df_tfidf.to_pickle('../data/pickles/df_tfidf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:16:54.190936Z",
     "start_time": "2020-04-07T01:16:54.184517Z"
    }
   },
   "outputs": [],
   "source": [
    "df_mostly_ready_metadata = pd.read_pickle('../data/pickles/df_mostly_ready_metadata.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:16:56.247950Z",
     "start_time": "2020-04-07T01:16:56.229113Z"
    }
   },
   "outputs": [],
   "source": [
    "df_mostly_ready_metadata.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:16:58.471877Z",
     "start_time": "2020-04-07T01:16:58.467393Z"
    }
   },
   "outputs": [],
   "source": [
    "df_mostly_ready_metadata.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:17:00.600717Z",
     "start_time": "2020-04-07T01:17:00.593588Z"
    }
   },
   "outputs": [],
   "source": [
    "lang_matrix = pd.get_dummies(df_mostly_ready_metadata['original_language'],\n",
    "                             prefix=\"lang\")\n",
    "lang_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:17:02.796142Z",
     "start_time": "2020-04-07T01:17:02.792418Z"
    }
   },
   "outputs": [],
   "source": [
    "df_mostly_ready_metadata.drop(['original_language'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:17:02.801364Z",
     "start_time": "2020-04-07T01:17:02.797517Z"
    }
   },
   "outputs": [],
   "source": [
    "df_mostly_ready_metadata = pd.concat([df_mostly_ready_metadata, \n",
    "                                      lang_matrix],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:17:02.822364Z",
     "start_time": "2020-04-07T01:17:02.802699Z"
    }
   },
   "outputs": [],
   "source": [
    "df_mostly_ready_metadata['color'] = df_mostly_ready_metadata['color'].map({\"Color\":1,\n",
    "                                                                           \"Black and White\":0})\n",
    "\n",
    "df_mostly_ready_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:17:09.491949Z",
     "start_time": "2020-04-07T01:17:09.489199Z"
    }
   },
   "outputs": [],
   "source": [
    "del df_mostly_ready_metadata['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:17:09.499956Z",
     "start_time": "2020-04-07T01:17:09.493089Z"
    }
   },
   "outputs": [],
   "source": [
    "df_some_binarized = pd.concat([df_mostly_ready_metadata.drop(['fixed_aspect'],axis=1), \n",
    "                                pd.get_dummies(df_mostly_ready_metadata.fixed_aspect, prefix=\"ratio\")],axis=1\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:17:12.941676Z",
     "start_time": "2020-04-07T01:17:12.939566Z"
    }
   },
   "outputs": [],
   "source": [
    "del df_mostly_ready_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:17:16.941507Z",
     "start_time": "2020-04-07T01:17:16.925267Z"
    }
   },
   "outputs": [],
   "source": [
    "df_some_binarized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:17:18.931778Z",
     "start_time": "2020-04-07T01:17:18.923993Z"
    }
   },
   "outputs": [],
   "source": [
    "content_ratings = pd.get_dummies(df_some_binarized.content_rating,prefix=\"content\")\n",
    "content_ratings.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:17:21.249902Z",
     "start_time": "2020-04-07T01:17:21.243313Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ratings_binarized = pd.concat([df_some_binarized.drop(['content_rating'],\n",
    "                                                         axis=1\n",
    "                                                        ), \n",
    "                                  content_ratings],\n",
    "                                  axis=1\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:17:27.982761Z",
     "start_time": "2020-04-07T01:17:27.980641Z"
    }
   },
   "outputs": [],
   "source": [
    "del content_ratings\n",
    "del df_some_binarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:17:24.606286Z",
     "start_time": "2020-04-07T01:17:24.590724Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ratings_binarized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:17:30.412867Z",
     "start_time": "2020-04-07T01:17:30.408925Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ratings_binarized.to_pickle('../data/pickles/df_structured.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:36:13.864321Z",
     "start_time": "2020-04-07T01:36:12.455672Z"
    }
   },
   "outputs": [],
   "source": [
    "df_structured = pd.read_pickle('../data/pickles/df_structured.pkl')\n",
    "df_tfidf = pd.read_pickle('../data/pickles/df_tfidf.pkl')\n",
    "\n",
    "df_tfidf.index = df_structured.index\n",
    "\n",
    "df_structured.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:36:16.288701Z",
     "start_time": "2020-04-07T01:36:16.268937Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:36:17.553913Z",
     "start_time": "2020-04-07T01:36:17.543780Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_colnames = ['revenue', 'imdb_score']\n",
    "\n",
    "X_structured = df_structured.drop(y_colnames,axis=1)\n",
    "\n",
    "y_structured = df_structured[y_colnames]\n",
    "\n",
    "y_structured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:36:18.895996Z",
     "start_time": "2020-04-07T01:36:18.874742Z"
    }
   },
   "outputs": [],
   "source": [
    "X_structured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not fit the scaler on the test set. Do not fit PCA on test set. Do not do feature nor model selection based on anything in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:36:20.221791Z",
     "start_time": "2020-04-07T01:36:20.216799Z"
    }
   },
   "outputs": [],
   "source": [
    "X_struct_train, X_struct_test, y_train, y_test = train_test_split(X_structured, \n",
    "                                                                  y_structured, \n",
    "                                                                  test_size=0.3, \n",
    "                                                                  shuffle=True,\n",
    "                                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think my approach is going to be to use an ensemble to combine two regressors, one for the structured data and one for the unstructured plot texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:36:22.360577Z",
     "start_time": "2020-04-07T01:36:21.652852Z"
    }
   },
   "outputs": [],
   "source": [
    "X_plots_train = df_tfidf.loc[y_train.index]\n",
    "X_plots_test = df_tfidf.loc[y_test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:36:28.448639Z",
     "start_time": "2020-04-07T01:36:28.430741Z"
    }
   },
   "outputs": [],
   "source": [
    "del y_structured\n",
    "del df_structured\n",
    "del df_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:36:49.065772Z",
     "start_time": "2020-04-07T01:36:30.954948Z"
    }
   },
   "outputs": [],
   "source": [
    "X_plots_train.to_pickle('../data/pickles/X_plots_train.pkl')\n",
    "X_plots_test.to_pickle('../data/pickles/X_plots_test.pkl')\n",
    "\n",
    "X_struct_train.to_pickle(\"../data/pickles/X_struct_train.pkl\")\n",
    "X_struct_test.to_pickle(\"../data/pickles/X_struct_test.pkl\")\n",
    "\n",
    "y_train.to_pickle('../data/pickles/y_train.pkl')\n",
    "y_test.to_pickle('../data/pickles/y_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:36:51.660177Z",
     "start_time": "2020-04-07T01:36:51.557204Z"
    }
   },
   "outputs": [],
   "source": [
    "del X_plots_train\n",
    "del X_plots_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:36:51.860807Z",
     "start_time": "2020-04-07T01:36:51.855530Z"
    }
   },
   "outputs": [],
   "source": [
    "X_struct_train = pd.read_pickle(\"../data/pickles/X_struct_train.pkl\")\n",
    "X_struct_test = pd.read_pickle(\"../data/pickles/X_struct_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:36:53.411103Z",
     "start_time": "2020-04-07T01:36:52.053496Z"
    }
   },
   "outputs": [],
   "source": [
    "X_plots_train = pd.read_pickle('../data/pickles/X_plots_train.pkl')\n",
    "X_plots_test = pd.read_pickle('../data/pickles/X_plots_test.pkl')\n",
    "y_train = pd.read_pickle('../data/pickles/y_train.pkl')\n",
    "y_test = pd.read_pickle('../data/pickles/y_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there any redundant features? Are there any features obviously correlated with our dependent var?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:36:58.204154Z",
     "start_time": "2020-04-07T01:36:58.200283Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def draw_correlation_heatmap(features):\n",
    "    # Creating a multi-scatter plot\n",
    "    corr =  features.corr()\n",
    "    mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
    "\n",
    "    # Set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "    # Generate a custom diverging colormap\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    sns.heatmap(corr, \n",
    "                mask=mask, \n",
    "                cmap=cmap,\n",
    "                vmax=1, \n",
    "                center=0,\n",
    "                square=True, \n",
    "                linewidths=.5, \n",
    "                cbar_kws={\"shrink\": .5}).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:37:01.490702Z",
     "start_time": "2020-04-07T01:37:00.754044Z"
    }
   },
   "outputs": [],
   "source": [
    "draw_correlation_heatmap(X_struct_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some obviously multicollinear features to lose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:37:04.056246Z",
     "start_time": "2020-04-07T01:37:04.054041Z"
    }
   },
   "outputs": [],
   "source": [
    "multicollinear_features = [\"shot_only_in_USA\", \n",
    "                           \"shot_in_USA_and_abroad\", \n",
    "                           \"cast_total_facebook_likes_box\",\n",
    "                           \"actor_2_facebook_likes_box\",\n",
    "                           \"actor_3_facebook_likes_box\",\n",
    "                           \"lang_Other\",\n",
    "                           \"ratio_1.85\",\n",
    "                           \"content_PG-13\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:37:06.593936Z",
     "start_time": "2020-04-07T01:37:06.589819Z"
    }
   },
   "outputs": [],
   "source": [
    "X_struct_train.drop(multicollinear_features, axis=1, inplace=True)\n",
    "\n",
    "# Drop from the test set as well, to maintain same dimensionality\n",
    "X_struct_test.drop(multicollinear_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:37:09.742132Z",
     "start_time": "2020-04-07T01:37:09.148443Z"
    }
   },
   "outputs": [],
   "source": [
    "draw_correlation_heatmap(X_struct_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better! I would use a more mathematically rigorous feature elimination technique, but honestly I'm just planning to try regression models with inherent feature elimination like lasso and random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Interaction Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've removed the most obviously redundant terms, it might be helpful to generate a number of interaction terms, in case their interplay has some special significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:37:12.302739Z",
     "start_time": "2020-04-07T01:37:12.300598Z"
    }
   },
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(2, \n",
    "                          interaction_only=True,\n",
    "                          include_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:37:14.853280Z",
     "start_time": "2020-04-07T01:37:14.849048Z"
    }
   },
   "outputs": [],
   "source": [
    "poly.fit(X_struct_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:37:17.390429Z",
     "start_time": "2020-04-07T01:37:17.383539Z"
    }
   },
   "outputs": [],
   "source": [
    "interaction_term_names = [\"*\".join(col.split()) for col in poly.get_feature_names(X_struct_train.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:37:19.916655Z",
     "start_time": "2020-04-07T01:37:19.905848Z"
    }
   },
   "outputs": [],
   "source": [
    "X_struct_train_poly = pd.DataFrame(poly.transform(X_struct_train), \n",
    "                                   columns = interaction_term_names,\n",
    "                                   index = X_struct_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:37:22.511309Z",
     "start_time": "2020-04-07T01:37:22.504070Z"
    }
   },
   "outputs": [],
   "source": [
    "X_struct_test_poly = pd.DataFrame(poly.transform(X_struct_test), \n",
    "                                  columns = interaction_term_names,\n",
    "                                  index = X_struct_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:37:25.299595Z",
     "start_time": "2020-04-07T01:37:25.296817Z"
    }
   },
   "outputs": [],
   "source": [
    "del X_struct_test\n",
    "del X_struct_train\n",
    "del X_structured\n",
    "del interaction_term_names\n",
    "del multicollinear_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:37:27.864849Z",
     "start_time": "2020-04-07T01:37:27.809452Z"
    }
   },
   "outputs": [],
   "source": [
    "X_struct_train_poly.to_pickle('../data/pickles/X_struct_train_poly.pkl')\n",
    "X_struct_test_poly.to_pickle('../data/pickles/X_struct_test_poly.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:38:22.183344Z",
     "start_time": "2020-04-07T01:38:20.793696Z"
    }
   },
   "outputs": [],
   "source": [
    "X_struct_train_poly = pd.read_pickle('../data/pickles/X_struct_train_poly.pkl')\n",
    "X_struct_test_poly = pd.read_pickle('../data/pickles/X_struct_test_poly.pkl')\n",
    "X_plots_train = pd.read_pickle('../data/pickles/X_plots_train.pkl')\n",
    "X_plots_test = pd.read_pickle('../data/pickles/X_plots_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make 2 scalers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:38:27.846849Z",
     "start_time": "2020-04-07T01:38:27.844546Z"
    }
   },
   "outputs": [],
   "source": [
    "struct_scaler = MinMaxScaler()\n",
    "plots_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit scaler on training set, apply to both training and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:38:31.195663Z",
     "start_time": "2020-04-07T01:38:31.167409Z"
    }
   },
   "outputs": [],
   "source": [
    "X_struct_train_poly_scaled = pd.DataFrame(struct_scaler.fit_transform(X_struct_train_poly), \n",
    "                                         columns = X_struct_train_poly.columns,\n",
    "                                         index = X_struct_train_poly.index)\n",
    "\n",
    "X_struct_train_poly_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:38:34.648886Z",
     "start_time": "2020-04-07T01:38:34.628479Z"
    }
   },
   "outputs": [],
   "source": [
    "# Just transform() test set, not fit_transform()\n",
    "X_struct_test_poly_scaled = pd.DataFrame(struct_scaler.transform(X_struct_test_poly), \n",
    "                                         columns = X_struct_test_poly.columns,\n",
    "                                         index = X_struct_test_poly.index)\n",
    "\n",
    "X_struct_test_poly_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:38:38.223447Z",
     "start_time": "2020-04-07T01:38:38.220900Z"
    }
   },
   "outputs": [],
   "source": [
    "del X_struct_test_poly\n",
    "del X_struct_train_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also for plot synopsis data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:38:42.723196Z",
     "start_time": "2020-04-07T01:38:41.576802Z"
    }
   },
   "outputs": [],
   "source": [
    "X_plots_train_scaled = pd.DataFrame(plots_scaler.fit_transform(X_plots_train), \n",
    "                                    columns = X_plots_train.columns,\n",
    "                                    index = X_plots_train.index)\n",
    "\n",
    "X_plots_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:38:49.128602Z",
     "start_time": "2020-04-07T01:38:48.779964Z"
    }
   },
   "outputs": [],
   "source": [
    "# Again only transform(), no fit_transform() here\n",
    "X_plots_test_scaled = pd.DataFrame(plots_scaler.transform(X_plots_test), \n",
    "                                   columns = X_plots_test.columns,\n",
    "                                   index = X_plots_test.index)\n",
    "\n",
    "X_plots_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:38:56.787059Z",
     "start_time": "2020-04-07T01:38:56.691600Z"
    }
   },
   "outputs": [],
   "source": [
    "del X_plots_test\n",
    "del X_plots_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:39:31.388199Z",
     "start_time": "2020-04-07T01:39:12.977452Z"
    }
   },
   "outputs": [],
   "source": [
    "X_plots_train_scaled.to_pickle(\"../data/pickles/X_plots_train_scaled.pkl\")\n",
    "X_plots_test_scaled.to_pickle('../data/pickles/X_plots_test_scaled.pkl')\n",
    "\n",
    "X_struct_train_poly_scaled.to_pickle(\"../data/pickles/X_struct_train_poly_scaled.pkl\")\n",
    "X_struct_test_poly_scaled.to_pickle(\"../data/pickles/X_struct_test_poly_scaled.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building / Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:39:43.880955Z",
     "start_time": "2020-04-07T01:39:43.863139Z"
    }
   },
   "outputs": [],
   "source": [
    "X_struct_train_poly_scaled = pd.read_pickle(\"../data/pickles/X_struct_train_poly_scaled.pkl\")\n",
    "X_struct_test_poly_scaled = pd.read_pickle(\"../data/pickles/X_struct_test_poly_scaled.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:49:04.050317Z",
     "start_time": "2020-04-07T01:49:04.045790Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train = pd.read_pickle('../data/pickles/y_train.pkl')\n",
    "y_test = pd.read_pickle('../data/pickles/y_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:39:44.572799Z",
     "start_time": "2020-04-07T01:39:44.568779Z"
    }
   },
   "outputs": [],
   "source": [
    "X_struct_train_poly_scaled.shape[0], X_struct_test_poly_scaled.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:39:45.031824Z",
     "start_time": "2020-04-07T01:39:45.028651Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train.shape[0], y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:39:49.295627Z",
     "start_time": "2020-04-07T01:39:49.290928Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_error_metrics(y_actual, y_preds, name, draw_scatter=True):\n",
    "    ys = (y_actual, y_preds)\n",
    "    metrics = dict()\n",
    "    metrics[\"r^2\"] = r2_score(*ys)\n",
    "    metrics[\"MSE\"] = mean_squared_error(*ys)\n",
    "    metrics[\"Med_AE\"] = median_absolute_error(*ys) # Nicely robust to outliers\n",
    "    rounded_metrics = {k:round(v,3) for k,v in metrics.items()}\n",
    "    if draw_scatter:\n",
    "        colors = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "        for y, c in zip(ys, colors):\n",
    "            plt.scatter(range(len(y)), y, color=c)\n",
    "    return pd.Series(rounded_metrics, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very very naive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:39:49.904521Z",
     "start_time": "2020-04-07T01:39:49.900127Z"
    }
   },
   "outputs": [],
   "source": [
    "dummy_regr_critics = DummyRegressor(strategy=\"median\")\n",
    "dummy_regr_revenue = DummyRegressor(strategy=\"mean\")\n",
    "\n",
    "dummy_regr_critics.fit(X_struct_train_poly_scaled, y_train.imdb_score)\n",
    "dummy_regr_revenue.fit(X_struct_train_poly_scaled, y_train.revenue)\n",
    "\n",
    "ypred_critics_dummy = pd.Series(dummy_regr_critics.predict(X_struct_test_poly_scaled),\n",
    "                                index=y_test.index)\n",
    "\n",
    "del dummy_regr_critics\n",
    "\n",
    "ypred_revenue_dummy = pd.Series(dummy_regr_revenue.predict(X_struct_test_poly_scaled),\n",
    "                                index=y_test.index)\n",
    "\n",
    "del dummy_regr_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:39:50.533908Z",
     "start_time": "2020-04-07T01:39:50.329988Z"
    }
   },
   "outputs": [],
   "source": [
    "scores_critics_dummy = get_error_metrics(y_test.imdb_score, ypred_critics_dummy, \"critics_dummy\")\n",
    "del ypred_critics_dummy\n",
    "scores_critics_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:39:51.090436Z",
     "start_time": "2020-04-07T01:39:50.876459Z"
    }
   },
   "outputs": [],
   "source": [
    "scores_revenue_dummy = get_error_metrics(y_test.revenue, ypred_revenue_dummy, \"revenue_dummy\")\n",
    "del ypred_revenue_dummy\n",
    "scores_revenue_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a linear regressor, but one that can prune out seemingly irrelevant features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear: Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:39:58.263958Z",
     "start_time": "2020-04-07T01:39:53.026451Z"
    }
   },
   "outputs": [],
   "source": [
    "lasso_regr_critics = LassoCV(cv=5, random_state=0)\n",
    "lasso_regr_revenue = LassoCV(cv=5, random_state=0)\n",
    "\n",
    "lasso_regr_critics.fit(X_struct_train_poly_scaled, y_train.imdb_score)\n",
    "lasso_regr_revenue.fit(X_struct_train_poly_scaled, y_train.revenue)\n",
    "\n",
    "ypred_critics_lasso = pd.Series(lasso_regr_critics.predict(X_struct_test_poly_scaled),\n",
    "                                index=y_test.index)\n",
    "\n",
    "del lasso_regr_critics\n",
    "\n",
    "ypred_revenue_lasso = pd.Series(lasso_regr_revenue.predict(X_struct_test_poly_scaled),\n",
    "                                index=y_test.index)\n",
    "\n",
    "del lasso_regr_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:39:58.848596Z",
     "start_time": "2020-04-07T01:39:58.638167Z"
    }
   },
   "outputs": [],
   "source": [
    "scores_critics_lasso = get_error_metrics(y_test.imdb_score, \n",
    "                                         ypred_critics_lasso, \n",
    "                                         \"critics_lasso\")\n",
    "del ypred_critics_lasso\n",
    "\n",
    "scores_critics_lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow kinda decent at predicting critic scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:39:59.407703Z",
     "start_time": "2020-04-07T01:39:59.194999Z"
    }
   },
   "outputs": [],
   "source": [
    "scores_revenue_lasso = get_error_metrics(y_test.revenue, \n",
    "                                         ypred_revenue_lasso, \n",
    "                                         \"revenue_lasso\")\n",
    "\n",
    "del ypred_revenue_lasso\n",
    "\n",
    "scores_revenue_lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes, significant error on box office scores. Probably has to do with all the zero values in the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People online say that if you have lots of zeroes in your dependent continuous variable, then maybe you should just make a classifier which buckets things into (hopefully) zero and non-zero samples, then train and run your regression model on the non-zero samples. Cool idea, but this is my secondary DV and I'd like to focus on IMdB critic scores for now, so I'll just move on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding in Plot Synopsis Decomposition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:49:30.270017Z",
     "start_time": "2020-04-07T01:49:30.253550Z"
    }
   },
   "outputs": [],
   "source": [
    "X_struct_train_poly_scaled = pd.read_pickle(\"../data/pickles/X_struct_train_poly_scaled.pkl\")\n",
    "X_struct_test_poly_scaled = pd.read_pickle(\"../data/pickles/X_struct_test_poly_scaled.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:49:32.134239Z",
     "start_time": "2020-04-07T01:49:30.759276Z"
    }
   },
   "outputs": [],
   "source": [
    "X_plots_train_scaled = pd.read_pickle('../data/pickles/X_plots_train_scaled.pkl')\n",
    "X_plots_test_scaled  = pd.read_pickle('../data/pickles/X_plots_test_scaled.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:49:40.788453Z",
     "start_time": "2020-04-07T01:49:40.783746Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train = pd.read_pickle('../data/pickles/y_train.pkl')\n",
    "y_test = pd.read_pickle('../data/pickles/y_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:49:49.646102Z",
     "start_time": "2020-04-07T01:49:47.263656Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_struct_train_poly_scaled, \n",
    "                     X_plots_train_scaled],\n",
    "              axis=1)\n",
    "\n",
    "del X_struct_train_poly_scaled\n",
    "del X_plots_train_scaled\n",
    "\n",
    "X_test = pd.concat([X_struct_test_poly_scaled,\n",
    "                    X_plots_test_scaled],\n",
    "                   axis=1)\n",
    "\n",
    "\n",
    "del X_struct_test_poly_scaled\n",
    "del X_plots_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:50:16.091363Z",
     "start_time": "2020-04-07T01:50:16.087540Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3362"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do some PCA on the text features, given the large feature space with the plot text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:50:42.525151Z",
     "start_time": "2020-04-07T01:50:42.517168Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:51:08.892810Z",
     "start_time": "2020-04-07T01:51:08.890403Z"
    }
   },
   "outputs": [],
   "source": [
    "lasso_critics_withplots = LassoCV(cv=5, random_state=0)\n",
    "\n",
    "# ypred_critics_withplots = pd.Series(lasso_regr_critics.predict(X_struct_test_poly_scaled),\n",
    "#                                 index=y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:51:35.283085Z",
     "start_time": "2020-04-07T01:51:35.279280Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a pipeline to search for the best PCA truncation\n",
    "pca = PCA()\n",
    "pipe = Pipeline(steps=[('pca', pca), \n",
    "                       ('lasso', lasso_critics_withplots)])\n",
    "\n",
    "# Parameters of pipelines can be set using __ separated parameter names:\n",
    "param_grid = {\n",
    "    'pca__n_components': np.arange(100,550,50),\n",
    "    'lasso__n_alphas': np.arange(50, 250, 50),\n",
    "}\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T02:09:22.729105Z",
     "start_time": "2020-04-07T01:52:01.759991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.237):\n",
      "{'lasso__n_alphas': 100, 'pca__n_components': 350}\n"
     ]
    }
   ],
   "source": [
    "search.fit(X_train, y_train.imdb_score)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Parametric: Linear SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heavyweight Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Text as Predictive Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T01:11:27.123971Z",
     "start_time": "2020-04-07T01:11:03.726Z"
    }
   },
   "outputs": [],
   "source": [
    "X_plots_test_scaled = pd.read_pickle('../data/pickles/X_plots_test_scaled.pkl')\n",
    "X_plots_train_scaled = pd.read_pickle(\"../data/pickles/X_plots_train_scaled.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "453px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "513px",
    "left": "1618px",
    "right": "20px",
    "top": "634px",
    "width": "355px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
