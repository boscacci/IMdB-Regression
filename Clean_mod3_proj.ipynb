{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Film Plot Synopses as Predictors of Critical Reception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk import FreqDist, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import enchant\n",
    "english_d = enchant.Dict(\"en_US\")\n",
    "import re\n",
    "import gensim\n",
    "from gensim import corpora, models, similarities\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = pd.read_csv('imdb_5000_movies.csv') # Just a Kaggle dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best part of this kaggle dataset is that it provides 5k+ IMdB movie ID's, which we parse and pass to the Open Movie Database API for an even richer data set. Keys to this API cost a whole dollar. Here we parse out those IMdB ID's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_ids = [imdb.iloc[i]['movie_imdb_link'].split('title/')[1].split('/?')[0] for i in range(len(imdb))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert code into omdb api and turn each one into its own text file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we persist our API queries to files, so that we don't run into query limits and get locked out of our dataset. Our API key has been removed from this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for id in imdb_ids:\n",
    "\n",
    "#     request = requests.get(f'http://www.omdbapi.com/?i={id}&plot=full&apikey={API_KEY}').json()\n",
    "#     text = str(request)  \n",
    "    \n",
    "#     f = open(f'movie_{id}', 'w+')\n",
    "#     f.write(text)\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new dataframe with relevant columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've saved a bunch of files containing data about movies, we'll read them back into pandas in a tidy way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty dataframe with relevant columns\n",
    "\n",
    "df = pd.DataFrame(columns=['Title', 'Year', 'ID', 'Plot', 'Genre', 'Production', \n",
    "                           'Director', 'Actor_1_name', 'Actor_1_fb_likes', 'Actor_2_name', \n",
    "                           'Actor_2_fb_likes', 'Actor_3_name', 'Actor_3_fb_likes', 'Budget', \n",
    "                           'Rated', 'Language', 'imdbRating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing from both the kaggle dataset and the OMdB API Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(imdb_ids)):\n",
    "    id = imdb.iloc[i]['movie_imdb_link'].split('title/')[1].split('/?')[0]\n",
    "    x_file = open(os.path.join('Movies', f\"movie_{id}\"), \"r\")    #open up the movie's text file\n",
    "    movie_text = x_file.readlines()[0]\n",
    "    dict = eval(movie_text)    #turn string back to dictionary\n",
    "    dict['Plot'] = dict['Plot'].replace(\"\\'\", \"'\")    #clean up\n",
    "    df = df.append({'Title': dict['Title'], 'Year': dict['Year'], 'ID': id, \n",
    "                    'Plot': dict['Plot'], 'Genre': dict['Genre'], \n",
    "                    'imdbRating': dict['imdbRating'], \n",
    "                    'Director': imdb.iloc[i,:].loc['director_name'], \n",
    "                    'Actor_1_name':imdb.iloc[i,:].loc['actor_1_name'], \n",
    "                    'Actor_1_fb_likes':imdb.iloc[i,:].loc['actor_1_facebook_likes'], \n",
    "                    'Actor_2_name':imdb.iloc[i,:].loc['actor_2_name'], \n",
    "                    'Actor_2_fb_likes':imdb.iloc[i,:].loc['actor_2_facebook_likes'], \n",
    "                    'Actor_3_name':imdb.iloc[i,:].loc['actor_3_name'], \n",
    "                    'Actor_3_fb_likes':imdb.iloc[i,:].loc['actor_3_facebook_likes'], \n",
    "                    'Budget':imdb.iloc[i,:].loc['budget'], 'Language':dict['Language'], \n",
    "                    'Rated':dict['Rated']}, ignore_index=True)    #add to dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing out Genres as one-hot Columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = []\n",
    "for i in range(len(df)):\n",
    "    movie_genres = df.iloc[i]['Genre'].split(', ')\n",
    "    li.append(movie_genres)\n",
    "    \n",
    "final_genres = ['Action', 'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy', 'History', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci_Fi', 'Sport', 'Thriller', 'War', 'Western']    \n",
    "\n",
    "for genre in final_genres:\n",
    "    list = []\n",
    "    for movie in li:\n",
    "        if genre in movie:\n",
    "            list.append(1)\n",
    "        else:\n",
    "            list.append(0)\n",
    "    df[genre] = list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove movies with null plots and ratings, convert ratings into binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~((df['Plot'] == 'N/A')|(df['imdbRating'] == 'N/A'))] # Drops movies with null plots\n",
    "df.imdbRating = df.imdbRating.astype(float)\n",
    "df['binary_target'] = df['imdbRating'] >= df['imdbRating'].mean()   #binary target column. True = above mean ; False = below mean\n",
    "df['binary_target'] = df['binary_target'].astype(int)\n",
    "df['Actor_1_fb_likes'].fillna((df['Actor_1_fb_likes'].mean()), inplace=True)\n",
    "df['Actor_2_fb_likes'].fillna((df['Actor_2_fb_likes'].mean()), inplace=True)\n",
    "df['Actor_3_fb_likes'].fillna((df['Actor_3_fb_likes'].mean()), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>ID</th>\n",
       "      <th>Plot</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Production</th>\n",
       "      <th>Director</th>\n",
       "      <th>Actor_1_name</th>\n",
       "      <th>Actor_1_fb_likes</th>\n",
       "      <th>Actor_2_name</th>\n",
       "      <th>...</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci_Fi</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "      <th>binary_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avatar</td>\n",
       "      <td>2009</td>\n",
       "      <td>tt0499549</td>\n",
       "      <td>When his brother is killed in a robbery, parap...</td>\n",
       "      <td>Action, Adventure, Fantasy, Sci-Fi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>CCH Pounder</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Joel David Moore</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>2007</td>\n",
       "      <td>tt0449088</td>\n",
       "      <td>After Elizabeth, Will, and Captain Barbossa re...</td>\n",
       "      <td>Action, Adventure, Fantasy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gore Verbinski</td>\n",
       "      <td>Johnny Depp</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>Orlando Bloom</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spectre</td>\n",
       "      <td>2015</td>\n",
       "      <td>tt2379713</td>\n",
       "      <td>A cryptic message from the past sends James Bo...</td>\n",
       "      <td>Action, Adventure, Thriller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sam Mendes</td>\n",
       "      <td>Christoph Waltz</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>Rory Kinnear</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Title  Year         ID  \\\n",
       "0                                    Avatar  2009  tt0499549   \n",
       "1  Pirates of the Caribbean: At World's End  2007  tt0449088   \n",
       "2                                   Spectre  2015  tt2379713   \n",
       "\n",
       "                                                Plot  \\\n",
       "0  When his brother is killed in a robbery, parap...   \n",
       "1  After Elizabeth, Will, and Captain Barbossa re...   \n",
       "2  A cryptic message from the past sends James Bo...   \n",
       "\n",
       "                                Genre  Production        Director  \\\n",
       "0  Action, Adventure, Fantasy, Sci-Fi         NaN   James Cameron   \n",
       "1          Action, Adventure, Fantasy         NaN  Gore Verbinski   \n",
       "2         Action, Adventure, Thriller         NaN      Sam Mendes   \n",
       "\n",
       "      Actor_1_name  Actor_1_fb_likes      Actor_2_name      ...        Horror  \\\n",
       "0      CCH Pounder            1000.0  Joel David Moore      ...             0   \n",
       "1      Johnny Depp           40000.0     Orlando Bloom      ...             0   \n",
       "2  Christoph Waltz           11000.0      Rory Kinnear      ...             0   \n",
       "\n",
       "  Musical  Mystery  Romance Sci_Fi Sport  Thriller  War  Western  \\\n",
       "0       0        0        0      0     0         0    0        0   \n",
       "1       0        0        0      0     0         0    0        0   \n",
       "2       0        0        0      0     0         1    0        0   \n",
       "\n",
       "   binary_target  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "\n",
       "[3 rows x 38 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a fresh DataFrame with Just the Features we Want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = df.iloc[:,-21:]\n",
    "main_df['Year'] = [int(year.split('–')[0]) for year in df['Year'].values]\n",
    "main_df = main_df.join(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Biography</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Family</th>\n",
       "      <th>...</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci_Fi</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "      <th>binary_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Action  Adventure  Animation  Biography  Comedy  Crime  Documentary  \\\n",
       "0  2009       1          1          0          0       0      0            0   \n",
       "1  2007       1          1          0          0       0      0            0   \n",
       "2  2015       1          1          0          0       0      0            0   \n",
       "\n",
       "   Drama  Family      ...        Horror  Musical  Mystery  Romance  Sci_Fi  \\\n",
       "0      0       0      ...             0        0        0        0       0   \n",
       "1      0       0      ...             0        0        0        0       0   \n",
       "2      0       0      ...             0        0        0        0       0   \n",
       "\n",
       "   Sport  Thriller  War  Western  binary_target  \n",
       "0      0         0    0        0              1  \n",
       "1      0         0    0        0              1  \n",
       "2      0         1    0        0              1  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a218bb668>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.plot.scatter(x='Actor_1_fb_likes',\n",
    "                    y='imdbRating') # Just spotting some outliers...this prompted us to log transform fb_likes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Transforming Actor Facebook Likes for use as a Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transform_col(feature, dataframe):\n",
    "    logged = pd.Series(np.log(dataframe[feature].values+1), name=feature+'_logged')\n",
    "    return logged\n",
    "\n",
    "actor_features = ['Actor_1_fb_likes', 'Actor_2_fb_likes','Actor_3_fb_likes']\n",
    "\n",
    "actor_likes = [log_transform_col(actor_features[i], df) for i in range(len(actor_features))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a21d390f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAE7pJREFUeJzt3X9sXfV5x/H3U2joijsIUKyQhCWTsqwprPywUjakySkrBKgaKoQEYjRt6VJNkNKpUhs6TQllbJHWtWs1xpZCRlAZFmqpiGhWmmX1KqTShjCESVJGBAxMMlIKpTVIdHTP/rjHcGMc33sd+15ff98vyfI9z/mee55zZfvj8+OeG5mJJKk8b+t0A5KkzjAAJKlQBoAkFcoAkKRCGQCSVCgDQJIKZQBIUqEMAEkqlAEgSYU6utMNTOSkk07KRYsWtbTMK6+8wrHHHjs9DU0j+26/bu29W/uG7u292/retWvXC5n57kbjZnQALFq0iIceeqilZQYHB+nv75+ehqaRfbdft/berX1D9/bebX1HxH83M85DQJJUKANAkgplAEhSoQwASSqUASBJhTIAJKlQBoAkFcoAkKRCGQCSVKgZ/U5gqZ1O33J6wzFDq4fa0InUHu4BSFKhDABJKpQBIEmFMgAkqVANAyAiFkbE9yNib0TsjojrqvqGiHguIh6pvi6qW+b6iNgXEY9HxAV19ZVVbV9ErJueTZIkNaOZq4BeBz6bmQ9HxLuAXRGxvZr3lcz8Uv3giFgGXA68FzgF+LeI+J1q9s3AB4FhYGdEbM3MPVOxIZKk1jQMgMw8AByoHv8yIvYC8ydYZBUwkJmvAU9FxD5geTVvX2Y+CRARA9VYA0CSOqClcwARsQg4E/hRVbo2Ih6NiM0RMbeqzQeerVtsuKodri5J6oDIzOYGRvQA/wHclJn3REQv8AKQwI3AvMz8RETcDPwwM79RLXcbsI1a2FyQmZ+s6lcByzNz7Zj1rAHWAPT29p49MDDQ0gaNjIzQ09PT0jIzgX2339je9/ys8c7oshOXTWdLTZlNr3m36La+V6xYsSsz+xqNa+qdwBHxduBbwJ2ZeQ9AZj5fN//rwH3V5DCwsG7xBcD+6vHh6m/IzE3AJoC+vr5s9XM4u+2zO0fZd/uN7X3tlrWHH1wZurTz7wSeTa95t+jWvhtp5iqgAG4D9mbml+vq8+qGfQR4rHq8Fbg8Io6JiMXAEuDHwE5gSUQsjog51E4Ub52azZAktaqZPYBzgauAoYh4pKp9AbgiIs6gdgjoaeBTAJm5OyLupnZy93Xgmsz8NUBEXAvcDxwFbM7M3VO4LZKkFjRzFdADQIwza9sEy9wE3DROfdtEy0mS2sd3AktSoQwASSqUASBJhTIAJKlQBoAkFcoAkKRCGQCSVCgDQJIKZQBIUqEMAEkqlAEgSYUyACSpUE19HoA0K2w47tDppTfAhlVvTi8+tb39SB3mHoAkFcoAkKRCGQCSVCgDQJIKZQBIUqEMAEkqlAEgSYUyACSpUAaAJBXKAJCkQhkAklQoA0CSCmUASFKhDABJKpQBIEmFMgAkqVAGgCQVygCQpEI1DICIWBgR34+IvRGxOyKuq+onRMT2iHii+j63qkdEfC0i9kXEoxFxVt1zra7GPxERq6dvsyRJjTSzB/A68NnMfA9wDnBNRCwD1gE7MnMJsKOaBrgQWFJ9rQFugVpgAOuB9wPLgfWjoSFJar+GAZCZBzLz4erxL4G9wHxgFbClGrYFuKR6vAq4I2seBI6PiHnABcD2zHwxM18CtgMrp3RrJElNa+kcQEQsAs4EfgT0ZuYBqIUEcHI1bD7wbN1iw1XtcHVJUgcc3ezAiOgBvgV8JjN/ERGHHTpOLSeoj13PGmqHjujt7WVwcLDZFgEYGRlpeZmZwL7bYOkNh0yOHHMKg3W1P50zp+FTzIRt7arXfIxu7b1b+26kqQCIiLdT++N/Z2beU5Wfj4h5mXmgOsRzsKoPAwvrFl8A7K/q/WPqg2PXlZmbgE0AfX192d/fP3bIhAYHB2l1mZnAvttgw6pDJgeX3kD/4+vfmF67+NSGTzF06dCUt9WqrnrNx+jW3ru170aauQoogNuAvZn55bpZW4HRK3lWA/fW1T9aXQ10DvBydYjofuD8iJhbnfw9v6pJkjqgmT2Ac4GrgKGIeKSqfQHYCNwdEVcDzwCXVfO2ARcB+4BXgY8DZOaLEXEjsLMa98XMfHFKtkKS1LKGAZCZDzD+8XuA88YZn8A1h3muzcDmVhqUJE0P3wksSYUyACSpUAaAJBXKAJCkQhkAklQoA0CSCmUASFKhDABJKpQBIEmFMgAkqVAGgCQVygCQpEIZAJJUKANAkgplAEhSoQwASSqUASBJhTIAJKlQBoAkFcoAkKRCGQCSVCgDQJIKZQBIUqEMAEkqlAEgSYUyACSpUAaAJBXKAJCkQhkAklQoA0CSCnV0owERsRn4EHAwM0+rahuAPwF+Wg37QmZuq+ZdD1wN/Br4dGbeX9VXAl8FjgJuzcyNU7spUucsWvedCec/vfHiNnUiNa+ZPYDbgZXj1L+SmWdUX6N//JcBlwPvrZb5h4g4KiKOAm4GLgSWAVdUYyVJHdJwDyAzfxARi5p8vlXAQGa+BjwVEfuA5dW8fZn5JEBEDFRj97TcsSRpShzJOYBrI+LRiNgcEXOr2nzg2boxw1XtcHVJUodEZjYeVNsDuK/uHEAv8AKQwI3AvMz8RETcDPwwM79RjbsN2EYtaC7IzE9W9auA5Zm5dpx1rQHWAPT29p49MDDQ0gaNjIzQ09PT0jIzgX23wYFHDpkcOeYUel7b/8b0njlzGj7FshPHP3I59NzLEy53+vzjmmiwOV31mo/Rrb13W98rVqzYlZl9jcY1PAQ0nsx8fvRxRHwduK+aHAYW1g1dAIz+hh2uPva5NwGbAPr6+rK/v7+l3gYHB2l1mZnAvttgw6pDJgeX3kD/4+vfmF67+NSGTzF06dC49Y81Ogl8ZX/j/prUVa/5GN3ae7f23cikDgFFxLy6yY8Aj1WPtwKXR8QxEbEYWAL8GNgJLImIxRExh9qJ4q2Tb1uSdKSauQz0LqAfOCkihoH1QH9EnEHtENDTwKcAMnN3RNxN7eTu68A1mfnr6nmuBe6ndhno5szcPeVbI0lqWjNXAV0xTvm2CcbfBNw0Tn0btfMBkqQZwHcCS1KhDABJKpQBIEmFMgAkqVAGgCQVygCQpEIZAJJUqEndCkKaiRrek/8dbWpE6hLuAUhSoQwASSqUASBJhfIcgNQOG5r4PIANE3+mgDTV3AOQpEIZAJJUKANAkgplAEhSoQwASSqUASBJhTIAJKlQBoAkFcoAkKRCGQCSVCgDQJIKZQBIUqEMAEkqlHcDlTRpDT+FbePFbepEk+EegCQVygCQpEIZAJJUKANAkgplAEhSoRoGQERsjoiDEfFYXe2EiNgeEU9U3+dW9YiIr0XEvoh4NCLOqltmdTX+iYhYPT2bI0lqVjN7ALcDK8fU1gE7MnMJsKOaBrgQWFJ9rQFugVpgAOuB9wPLgfWjoSFJ6oyGAZCZPwBeHFNeBWypHm8BLqmr35E1DwLHR8Q84AJge2a+mJkvAdt5a6hIktposucAejPzAED1/eSqPh94tm7ccFU7XF2S1CGRmY0HRSwC7svM06rpn2fm8XXzX8rMuRHxHeCvM/OBqr4D+BzwAeCYzPzLqv4XwKuZ+bfjrGsNtcNH9Pb2nj0wMNDSBo2MjNDT09PSMjOBfdfs+dmehmOWnbhs3PrQcy9PuNzpb3vqkOmRY06h57X9b657zpy2rXtc885oPIaZ9bPScLvnH3fI9EzqvRXd1veKFSt2ZWZfo3GTvRXE8xExLzMPVId4Dlb1YWBh3bgFwP6q3j+mPjjeE2fmJmATQF9fX/b394837LAGBwdpdZmZwL5r1m5Z23DM0KVD49Y/1ui2BO9Yf8j04NIb6H/8zdraxae2bd3jumLiP6ajZtLPSsPtvrL/kOmZ1HsrurXvRiZ7CGgrMHolz2rg3rr6R6urgc4BXq4OEd0PnB8Rc6uTv+dXNUlShzTcA4iIu6j9935SRAxTu5pnI3B3RFwNPANcVg3fBlwE7ANeBT4OkJkvRsSNwM5q3Bczc+yJZUlSGzUMgMy84jCzzhtnbALXHOZ5NgObW+pOkjRtfCewJBXKAJCkQhkAklQoA0CSCmUASFKhDABJKpQBIEmFMgAkqVAGgCQVygCQpEIZAJJUKANAkgplAEhSoQwASSqUASBJhTIAJKlQBoAkFcoAkKRCGQCSVCgDQJIKZQBIUqEMAEkqlAEgSYUyACSpUEd3ugFJNadvOX3C+UOrh9rUiUrhHoAkFcoAkKRCGQCSVCjPAai9Nhw38fzFp7anD0nuAUhSqQwASSrUEQVARDwdEUMR8UhEPFTVToiI7RHxRPV9blWPiPhaROyLiEcj4qyp2ABJ0uRMxR7Aisw8IzP7qul1wI7MXALsqKYBLgSWVF9rgFumYN2SpEmajkNAq4At1eMtwCV19Tuy5kHg+IiYNw3rlyQ1ITJz8gtHPAW8BCTwT5m5KSJ+npnH1415KTPnRsR9wMbMfKCq7wA+n5kPjXnONdT2EOjt7T17YGCgpZ5GRkbo6emZ9DZ1SjF9H3hkwtl75sxp+BTLTlw2bn3ouZcnXO70tz11yPTIMafQ89r+jqx7PI3WP7rusa95w3XPb3Dl1RFodd3F/Jx32IoVK3bVHZU5rCO9DPTczNwfEScD2yPiJxOMjXFqb0mfzNwEbALo6+vL/v7+lhoaHByk1WVmgmL63rBqwtlrm7gMdOjS8W+J8LF135lwuaffsf6Q6cGlN9D/+Ju1dq57PI3WP7rusa95w3Vf2T/h/CPR6rqL+TnvEkd0CCgz91ffDwLfBpYDz48e2qm+H6yGDwML6xZfAOxHktQRkw6AiDg2It41+hg4H3gM2AqsroatBu6tHm8FPlpdDXQO8HJmHph055KkI3Ikh4B6gW9HxOjz/EtmfjcidgJ3R8TVwDPAZdX4bcBFwD7gVeDjR7BuSdIRmnQAZOaTwPvGqf8MOG+cegLXTHZ9kqSp5TuBJalQBoAkFcoAkKRCeTtovUWjjyYEP55Qmg3cA5CkQhkAklQoA0CSCmUASFKhDABJKpQBIEmFMgAkqVAGgCQVyjeCaUotavjBKG1qRFJDBoA0221o4iMhN0z80Y6anTwEJEmFcg+gRI3+I2zis3EldT/3ACSpUAaAJBXKQ0CSps/Yw41Lb4ANq8aM8QR0pxgAM5T35Jc03TwEJEmFMgAkqVAGgCQVygCQpEIZAJJUKK8CmkC3XonjDdkkNcMA6JRG10d7OwZJ08wAkNRwb3cm7unqyJUdAN4UTVLBPAksSYVq+x5ARKwEvgocBdyamRvb3YOk7tfwYoeNF7epk+7V1gCIiKOAm4EPAsPAzojYmpl7pmN9nbwaxitxpOZ4/qFz2n0IaDmwLzOfzMxfAQPAqgbLSJKmQbsPAc0Hnq2bHgbe3+YeJOmIzJbDT5GZ7VtZxGXABZn5yWr6KmB5Zq6tG7MGWFNNLgUeb3E1JwEvTEG77Wbf7detvXdr39C9vXdb37+Vme9uNKjdewDDwMK66QXA/voBmbkJ2DTZFUTEQ5nZN9nlO8W+269be+/WvqF7e+/Wvhtp9zmAncCSiFgcEXOAy4Gtbe5BkkSb9wAy8/WIuBa4n9ploJszc3c7e5Ak1bT9fQCZuQ3YNo2rmPThow6z7/br1t67tW/o3t67te8JtfUksCRp5vBWEJJUqFkTABGxMiIej4h9EbGu0/00KyIWRsT3I2JvROyOiOs63VMrIuKoiPjPiLiv0720IiKOj4hvRsRPqtf+9zvdUzMi4s+qn5PHIuKuiJix7ymPiM0RcTAiHqurnRAR2yPiier73E72OJ7D9P031c/KoxHx7Yg4vpM9TpVZEQB1t5i4EFgGXBERyzrbVdNeBz6bme8BzgGu6aLeAa4D9na6iUn4KvDdzPxd4H10wTZExHzg00BfZp5G7UKKyzvb1YRuB1aOqa0DdmTmEmBHNT3T3M5b+94OnJaZvwf8F3B9u5uaDrMiAOjiW0xk5oHMfLh6/Etqf4jmd7ar5kTEAuBi4NZO99KKiPhN4A+B2wAy81eZ+fPOdtW0o4HfiIijgXcy5n00M0lm/gB4cUx5FbClerwFuKStTTVhvL4z83uZ+Xo1+SC19zB1vdkSAOPdYqIr/ojWi4hFwJnAjzrbSdP+Dvgc8H+dbqRFvw38FPjn6vDVrRFxbKebaiQznwO+BDwDHABezszvdbarlvVm5gGo/fMDnNzhfibjE8C/drqJqTBbAiDGqXXV5U0R0QN8C/hMZv6i0/00EhEfAg5m5q5O9zIJRwNnAbdk5pnAK8zMQxGHqI6XrwIWA6cAx0bEH3e2q7JExJ9TO2x7Z6d7mQqzJQAa3mJiJouIt1P7439nZt7T6X6adC7w4Yh4mtohtw9ExDc621LThoHhzBzd0/omtUCY6f4IeCozf5qZ/wvcA/xBh3tq1fMRMQ+g+n6ww/00LSJWAx8CrsxZcv38bAmArr3FREQEtWPRezPzy53up1mZeX1mLsjMRdRe73/PzK74bzQz/wd4NiKWVqXzgGn5TIop9gxwTkS8s/q5OY8uOHk9xlZgdfV4NXBvB3tpWvVBVp8HPpyZr3a6n6kyKwKgOjkzeouJvcDdXXSLiXOBq6j9B/1I9XVRp5sqwFrgzoh4FDgD+KsO99NQtcfyTeBhYIja7++MfYdqRNwF/BBYGhHDEXE1sBH4YEQ8Qe2DoWbcJwIepu+/B94FbK9+R/+xo01OEd8JLEmFmhV7AJKk1hkAklQoA0CSCmUASFKhDABJKpQBIEmFMgAkqVAGgCQV6v8B5ggH51NLawYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(actor_likes).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = main_df.join(actor_likes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Biography</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Family</th>\n",
       "      <th>...</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci_Fi</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "      <th>binary_target</th>\n",
       "      <th>Actor_1_fb_likes_logged</th>\n",
       "      <th>Actor_2_fb_likes_logged</th>\n",
       "      <th>Actor_3_fb_likes_logged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.908755</td>\n",
       "      <td>6.842683</td>\n",
       "      <td>6.752270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.596660</td>\n",
       "      <td>8.517393</td>\n",
       "      <td>6.908755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.305741</td>\n",
       "      <td>5.976351</td>\n",
       "      <td>5.087596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Action  Adventure  Animation  Biography  Comedy  Crime  Documentary  \\\n",
       "0  2009       1          1          0          0       0      0            0   \n",
       "1  2007       1          1          0          0       0      0            0   \n",
       "2  2015       1          1          0          0       0      0            0   \n",
       "\n",
       "   Drama  Family           ...             Romance  Sci_Fi  Sport  Thriller  \\\n",
       "0      0       0           ...                   0       0      0         0   \n",
       "1      0       0           ...                   0       0      0         0   \n",
       "2      0       0           ...                   0       0      0         1   \n",
       "\n",
       "   War  Western  binary_target  Actor_1_fb_likes_logged  \\\n",
       "0    0        0              1                 6.908755   \n",
       "1    0        0              1                10.596660   \n",
       "2    0        0              1                 9.305741   \n",
       "\n",
       "   Actor_2_fb_likes_logged  Actor_3_fb_likes_logged  \n",
       "0                 6.842683                 6.752270  \n",
       "1                 8.517393                 6.908755  \n",
       "2                 5.976351                 5.087596  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorporating Natural Language Processing with Plot Synopses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up Lemmatization / Normalization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "\n",
    "def lemmatize(plot_list):\n",
    "    lemmatized_plots = []\n",
    "    for plot in plot_list:\n",
    "        tokenized_lower = word_tokenize(plot.lower())   #make plot summary all lowercase and lemmatize\n",
    "        \n",
    "        tokenized_lower =[word for word in tokenized_lower if english_d.check(word)] # Make sure it's an english word\n",
    "        \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        dirty_lemma = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in tokenized_lower]    #lemmatize each word based on part of speech\n",
    "        dirty_lemma_string = ' '.join(dirty_lemma)\n",
    "        \n",
    "        #filter for words that match regex pattern\n",
    "        reg = re.compile((r\"([a-zA-Z]+(?:'[a-z]+)?)\"))    #define regular expression pattern\n",
    "        lemmatized_regex = [word_lem for word_lem in dirty_lemma if word_lem in reg.findall(dirty_lemma_string)]\n",
    "        \n",
    "        #filter out stop words\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        lemmatized = [word_lem for word_lem in lemmatized_regex if not word_lem in stop_words]\n",
    "        lemmatized_string = ' '.join(lemmatized)\n",
    "        \n",
    "        lemmatized_plots.append(lemmatized_string)\n",
    "        \n",
    "        \n",
    "    return lemmatized_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plots = [plot for plot in df.loc[:,'Plot'].values] # Get all the plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = lemmatize(all_plots) # Lemmatize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5037, 13807)\n"
     ]
    }
   ],
   "source": [
    "#term frequency = number of times a word appears in a document / number of words in document\n",
    "#inverse document frequency = log base e(number of ducuments / number of documents with word in it)\n",
    "# tf:idf = tf * idf\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "response = tfidf.fit_transform(plots)\n",
    "print(response.shape)\n",
    "\n",
    "tfidf_df = pd.DataFrame(response.toarray(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all plots lemmatized as \"plots\" and vectorized / weighted as \"tfidf_df\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorporating some LDA - Clustering Documents by Topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried running a topic modeling algorithm over our corpus of text. \"Gensim\" clusters words that appear together frequently across several documents. The clusters can be interpreted as general themes, and each movie has weights of how much it belongs to each theme. These weights are then re-incorporated as features in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = [plot.split(' ') for plot in plots] # Just formatting our corpus how Gensim wants it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(all_words)\n",
    "corpus = [dictionary.doc2bow(text) for text in all_words]\n",
    "pickle.dump(corpus, open('corpus.pkl', 'wb'))\n",
    "dictionary.save('dictionary.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOPICS = 30 # This value was arbitrarily chosen.\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=10) # Also arb\n",
    "ldamodel.save('model5.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(19, '0.031*\"life\" + 0.018*\"family\" + 0.014*\"relationship\" + 0.013*\"love\"'),\n",
       " (7, '0.027*\"john\" + 0.013*\"child\" + 0.009*\"grace\" + 0.007*\"call\"'),\n",
       " (13, '0.024*\"life\" + 0.017*\"town\" + 0.010*\"car\" + 0.009*\"girlfriend\"'),\n",
       " (17, '0.013*\"man\" + 0.012*\"kill\" + 0.012*\"police\" + 0.010*\"one\"'),\n",
       " (18, '0.035*\"school\" + 0.021*\"high\" + 0.012*\"go\" + 0.012*\"life\"'),\n",
       " (3, '0.015*\"harry\" + 0.011*\"documentary\" + 0.010*\"make\" + 0.010*\"go\"'),\n",
       " (24, '0.040*\"war\" + 0.021*\"world\" + 0.013*\"soldier\" + 0.013*\"army\"'),\n",
       " (25, '0.018*\"mike\" + 0.011*\"gang\" + 0.010*\"drug\" + 0.007*\"money\"'),\n",
       " (4, '0.018*\"film\" + 0.017*\"world\" + 0.017*\"vampire\" + 0.012*\"human\"'),\n",
       " (8, '0.018*\"jerry\" + 0.014*\"big\" + 0.012*\"story\" + 0.011*\"dance\"'),\n",
       " (23, '0.013*\"road\" + 0.012*\"trip\" + 0.011*\"get\" + 0.009*\"family\"'),\n",
       " (12, '0.025*\"dog\" + 0.014*\"series\" + 0.014*\"josh\" + 0.014*\"jenny\"'),\n",
       " (5, '0.009*\"world\" + 0.009*\"nuclear\" + 0.009*\"gold\" + 0.008*\"dragon\"'),\n",
       " (6, '0.027*\"earth\" + 0.019*\"alien\" + 0.016*\"planet\" + 0.012*\"human\"'),\n",
       " (15, '0.010*\"town\" + 0.008*\"lure\" + 0.007*\"rise\" + 0.007*\"game\"'),\n",
       " (26, '0.016*\"friend\" + 0.015*\"find\" + 0.013*\"get\" + 0.011*\"town\"'),\n",
       " (10, '0.017*\"love\" + 0.017*\"life\" + 0.012*\"year\" + 0.012*\"young\"'),\n",
       " (21, '0.016*\"nick\" + 0.010*\"island\" + 0.009*\"find\" + 0.008*\"love\"'),\n",
       " (0, '0.043*\"jack\" + 0.009*\"movie\" + 0.009*\"team\" + 0.008*\"new\"'),\n",
       " (16, '0.020*\"zombie\" + 0.011*\"cabin\" + 0.011*\"secret\" + 0.010*\"ability\"')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = ldamodel.print_topics(num_words=4)\n",
    "topics # These are examples of some of the clusters created by Gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = pd.DataFrame()\n",
    "for i in range(len(corpus)):\n",
    "    new_row = np.zeros(30)\n",
    "    for toop in ldamodel.get_document_topics(corpus[i]): # These two lines are where you do what you need to do\n",
    "        new_row[toop[0]] = toop[1]                       # to flip zeroes to ones if the genre appears\n",
    "    tm = tm.append(pd.Series(new_row), ignore_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107644</td>\n",
       "      <td>0.071717</td>\n",
       "      <td>0.018075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.339374</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.213315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.306839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.253508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.588396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2    3         4         5         6         7    8   \\\n",
       "0  0.0  0.000000  0.038795  0.0  0.000000  0.107644  0.071717  0.018075  0.0   \n",
       "1  0.0  0.000000  0.000000  0.0  0.073714  0.000000  0.000000  0.000000  0.0   \n",
       "2  0.0  0.131099  0.000000  0.0  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "3  0.0  0.000000  0.000000  0.0  0.000000  0.000000  0.306839  0.000000  0.0   \n",
       "4  0.0  0.000000  0.000000  0.0  0.000000  0.253508  0.000000  0.000000  0.0   \n",
       "\n",
       "        9     ...      20        21   22   23        24   25   26   27  \\\n",
       "0  0.00000    ...     0.0  0.000000  0.0  0.0  0.171745  0.0  0.0  0.0   \n",
       "1  0.00000    ...     0.0  0.555946  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
       "2  0.09667    ...     0.0  0.000000  0.0  0.0  0.059236  0.0  0.0  0.0   \n",
       "3  0.00000    ...     0.0  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
       "4  0.00000    ...     0.0  0.000000  0.0  0.0  0.059439  0.0  0.0  0.0   \n",
       "\n",
       "         28        29  \n",
       "0  0.339374  0.000000  \n",
       "1  0.000000  0.000000  \n",
       "2  0.000000  0.213315  \n",
       "3  0.000000  0.000000  \n",
       "4  0.000000  0.588396  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.head() # This is a DataFrame with the weights from the GenSim clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining GenSim Results with Vectorized Plot Synopses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_and_topics = tfidf_df.join(tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aardvark</th>\n",
       "      <th>aback</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abate</th>\n",
       "      <th>abatement</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abdicate</th>\n",
       "      <th>abduct</th>\n",
       "      <th>abduction</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.339374</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.213315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.588396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 13837 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aardvark  aback  abandon  abandonment  abate  abatement  abbey  abdicate  \\\n",
       "0       0.0    0.0      0.0          0.0    0.0        0.0    0.0       0.0   \n",
       "1       0.0    0.0      0.0          0.0    0.0        0.0    0.0       0.0   \n",
       "2       0.0    0.0      0.0          0.0    0.0        0.0    0.0       0.0   \n",
       "3       0.0    0.0      0.0          0.0    0.0        0.0    0.0       0.0   \n",
       "4       0.0    0.0      0.0          0.0    0.0        0.0    0.0       0.0   \n",
       "\n",
       "   abduct  abduction    ...      20        21   22   23        24   25   26  \\\n",
       "0     0.0        0.0    ...     0.0  0.000000  0.0  0.0  0.171745  0.0  0.0   \n",
       "1     0.0        0.0    ...     0.0  0.555946  0.0  0.0  0.000000  0.0  0.0   \n",
       "2     0.0        0.0    ...     0.0  0.000000  0.0  0.0  0.059236  0.0  0.0   \n",
       "3     0.0        0.0    ...     0.0  0.000000  0.0  0.0  0.000000  0.0  0.0   \n",
       "4     0.0        0.0    ...     0.0  0.000000  0.0  0.0  0.059439  0.0  0.0   \n",
       "\n",
       "    27        28        29  \n",
       "0  0.0  0.339374  0.000000  \n",
       "1  0.0  0.000000  0.000000  \n",
       "2  0.0  0.000000  0.213315  \n",
       "3  0.0  0.000000  0.000000  \n",
       "4  0.0  0.000000  0.588396  \n",
       "\n",
       "[5 rows x 13837 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plots_and_topics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA with Non-PlotText Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as sm\n",
    "from patsy import dmatrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.588562\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:          binary_target   No. Observations:                 4029\n",
      "Model:                          Logit   Df Residuals:                     4005\n",
      "Method:                           MLE   Df Model:                           23\n",
      "Date:                Tue, 08 Jan 2019   Pseudo R-squ.:                  0.1485\n",
      "Time:                        19:16:06   Log-Likelihood:                -2371.3\n",
      "converged:                       True   LL-Null:                       -2784.7\n",
      "                                        LLR p-value:                7.246e-160\n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "Intercept                  85.6656      6.990     12.255      0.000      71.965      99.367\n",
      "C(Action)[T.1]             -0.3644      0.099     -3.671      0.000      -0.559      -0.170\n",
      "C(Adventure)[T.1]           0.0709      0.109      0.650      0.516      -0.143       0.285\n",
      "C(Animation)[T.1]           1.2592      0.202      6.242      0.000       0.864       1.655\n",
      "C(Biography)[T.1]           1.2190      0.211      5.775      0.000       0.805       1.633\n",
      "C(Comedy)[T.1]             -0.5765      0.089     -6.494      0.000      -0.750      -0.402\n",
      "C(Crime)[T.1]              -0.0173      0.101     -0.171      0.864      -0.215       0.181\n",
      "C(Documentary)[T.1]         2.1884      0.336      6.511      0.000       1.530       2.847\n",
      "C(Drama)[T.1]               0.8694      0.085     10.178      0.000       0.702       1.037\n",
      "C(Family)[T.1]             -0.5333      0.146     -3.655      0.000      -0.819      -0.247\n",
      "C(Fantasy)[T.1]            -0.0419      0.118     -0.354      0.723      -0.274       0.190\n",
      "C(History)[T.1]             0.0461      0.213      0.217      0.828      -0.371       0.463\n",
      "C(Horror)[T.1]             -0.9116      0.132     -6.889      0.000      -1.171      -0.652\n",
      "C(Musical)[T.1]            -0.0695      0.237     -0.294      0.769      -0.534       0.395\n",
      "C(Mystery)[T.1]             0.1778      0.122      1.460      0.144      -0.061       0.417\n",
      "C(Romance)[T.1]            -0.2442      0.092     -2.643      0.008      -0.425      -0.063\n",
      "C(Sport)[T.1]              -0.0697      0.212     -0.329      0.742      -0.485       0.345\n",
      "C(Thriller)[T.1]           -0.2650      0.098     -2.694      0.007      -0.458      -0.072\n",
      "C(War)[T.1]                -0.0415      0.204     -0.203      0.839      -0.442       0.359\n",
      "C(Western)[T.1]            -0.1854      0.279     -0.665      0.506      -0.732       0.361\n",
      "Year                       -0.0430      0.003    -12.290      0.000      -0.050      -0.036\n",
      "Actor_1_fb_likes_logged     0.1678      0.029      5.782      0.000       0.111       0.225\n",
      "Actor_2_fb_likes_logged     0.0445      0.049      0.911      0.362      -0.051       0.140\n",
      "Actor_3_fb_likes_logged    -0.1697      0.045     -3.770      0.000      -0.258      -0.081\n",
      "===========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6865079365079365"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check LogReg with all initial variables from main_df (note: no plot)\n",
    "s = (\"binary_target ~ Year + C(Action) + C(Adventure) + C(Animation) + C(Biography) + C(Comedy)\"\n",
    "                 \"+ C(Crime) + C(Documentary) + C(Drama) + C(Family) + C(Fantasy) + C(History)\"\n",
    "                 \"+ C(Horror) + C(Musical) + C(Mystery) + C(Romance) + C(Sci_Fi) + C(Sport)\"\n",
    "                 \"+ C(Thriller) + C(War)+ C(Western)\"\n",
    "                 \"+ Actor_1_fb_likes_logged + Actor_2_fb_likes_logged\"\n",
    "                 \"+ Actor_3_fb_likes_logged\")\n",
    "\n",
    "y, X = dmatrices(s, main_df, return_type=\"dataframe\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =  0.2, random_state=16)\n",
    "\n",
    "logit_model = sm.Logit(y_train.iloc[:,0], X_train)\n",
    "result = logit_model.fit()\n",
    "\n",
    "print(result.summary())\n",
    "\n",
    "y_preds = result.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_preds >=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Crime' 'Fantasy' 'History' 'Musical' 'Sport' 'War' 'Western'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-b279e89dbf8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                  \"+ Actor_3_fb_likes_logged\")\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Crime'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Fantasy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'History'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Musical'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sport'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'War'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Western'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Adventure'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdmatrices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"dataframe\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3695\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3696\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3697\u001b[0;31m                                            errors=errors)\n\u001b[0m\u001b[1;32m   3698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3699\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3109\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3111\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3141\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3143\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3144\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   4402\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4403\u001b[0m                 raise KeyError(\n\u001b[0;32m-> 4404\u001b[0;31m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[1;32m   4405\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4406\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Crime' 'Fantasy' 'History' 'Musical' 'Sport' 'War' 'Western'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Rerun LogReg by dropping the features with high p_values in the prior model (see above)\n",
    "\n",
    "s = (\"binary_target ~ Year + C(Action) + C(Animation) + C(Biography) + C(Comedy)\"\n",
    "                 \"+ C(Documentary) + C(Drama) + C(Family)\"\n",
    "                 \"+ C(Horror) + C(Mystery) + C(Romance) + C(Sci_Fi)\"\n",
    "                 \"+ C(Thriller)\"\n",
    "                 \"+ Actor_1_fb_likes_logged + Actor_2_fb_likes_logged\"\n",
    "                 \"+ Actor_3_fb_likes_logged\")\n",
    "\n",
    "main_df = main_df.drop(['Adventure','Crime', 'Fantasy', 'History', 'Musical', 'Sport', 'War', 'Western'], axis=1)\n",
    "\n",
    "y, X = dmatrices(s, main_df, return_type = \"dataframe\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =  0.2, random_state=16)\n",
    "\n",
    "logit_model = sm.Logit(y_train.iloc[:,0], X_train)\n",
    "result = logit_model.fit()\n",
    "\n",
    "print(result.summary())\n",
    "\n",
    "y_preds = result.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_preds >=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Action', 'Adventure', 'Animation', 'Biography', 'Comedy',\n",
       "       'Documentary', 'Drama', 'Family', 'Horror', 'Mystery', 'Romance',\n",
       "       'Sci_Fi', 'Thriller', 'binary_target', 'Actor_1_fb_likes_logged',\n",
       "       'Actor_2_fb_likes_logged', 'Actor_3_fb_likes_logged'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction with SVD - For the PlotText Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=100, n_iter=7, random_state=42)\n",
    "plots_and_topics_pca = svd.fit_transform(plots_and_topics)\n",
    "\n",
    "print(svd.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
