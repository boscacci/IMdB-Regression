{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk import FreqDist, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import enchant\n",
    "english_d = enchant.Dict(\"en_US\")\n",
    "import re\n",
    "import gensim\n",
    "from gensim import corpora, models, similarities\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = pd.read_csv('imdb_5000_movies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab all of the movie codes from the 'imdb_movie_link' column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_ids = [imdb.iloc[i]['movie_imdb_link'].split('title/')[1].split('/?')[0] for i in range(len(imdb))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert code into omdb api and turn each one into its own text file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we persist our API queries to files, so that we don't run into query limits and get locked out of our dataset. Our API key has been removed from this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for id in imdb_ids:\n",
    "\n",
    "#     request = requests.get(f'http://www.omdbapi.com/?i={id}&plot=full&apikey={API_KEY}').json()\n",
    "#     text = str(request)  \n",
    "    \n",
    "#     f = open(f'movie_{id}', 'w+')\n",
    "#     f.write(text)\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new dataframe with relevant columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've saved a bunch of files containing data about movies, we'll read them back into pandas in a tidy way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty dataframe with relevant columns\n",
    "\n",
    "df = pd.DataFrame(columns=['Title', 'Year', 'ID', 'Plot', 'Genre', 'Production', \n",
    "                           'Director', 'Actor_1_name', 'Actor_1_fb_likes', 'Actor_2_name', \n",
    "                           'Actor_2_fb_likes', 'Actor_3_name', 'Actor_3_fb_likes', 'Budget', \n",
    "                           'Rated', 'Language', 'imdbRating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing from both a kaggle dataset and the OMdB API data we downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(imdb_ids)):\n",
    "    id = imdb.iloc[i]['movie_imdb_link'].split('title/')[1].split('/?')[0]\n",
    "    x_file = open(os.path.join('Movies', f\"movie_{id}\"), \"r\")    #open up the movie's text file\n",
    "    movie_text = x_file.readlines()[0]\n",
    "    dict = eval(movie_text)    #turn string back to dictionary\n",
    "    dict['Plot'] = dict['Plot'].replace(\"\\'\", \"'\")    #clean up\n",
    "    df = df.append({'Title': dict['Title'], 'Year': dict['Year'], 'ID': id, \n",
    "                    'Plot': dict['Plot'], 'Genre': dict['Genre'], \n",
    "                    'imdbRating': dict['imdbRating'], \n",
    "                    'Director': imdb.iloc[i,:].loc['director_name'], \n",
    "                    'Actor_1_name':imdb.iloc[i,:].loc['actor_1_name'], \n",
    "                    'Actor_1_fb_likes':imdb.iloc[i,:].loc['actor_1_facebook_likes'], \n",
    "                    'Actor_2_name':imdb.iloc[i,:].loc['actor_2_name'], \n",
    "                    'Actor_2_fb_likes':imdb.iloc[i,:].loc['actor_2_facebook_likes'], \n",
    "                    'Actor_3_name':imdb.iloc[i,:].loc['actor_3_name'], \n",
    "                    'Actor_3_fb_likes':imdb.iloc[i,:].loc['actor_3_facebook_likes'], \n",
    "                    'Budget':imdb.iloc[i,:].loc['budget'], 'Language':dict['Language'], \n",
    "                    'Rated':dict['Rated']}, ignore_index=True)    #add to dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing out Genres as one-hot Columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = []\n",
    "for i in range(len(df)):\n",
    "    movie_genres = df.iloc[i]['Genre'].split(', ')\n",
    "    li.append(movie_genres)\n",
    "    \n",
    "final_genres = ['Action', 'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy', 'History', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci_Fi', 'Sport', 'Thriller', 'War', 'Western']    \n",
    "\n",
    "for genre in final_genres:\n",
    "    list = []\n",
    "    for movie in li:\n",
    "        if genre in movie:\n",
    "            list.append(1)\n",
    "        else:\n",
    "            list.append(0)\n",
    "    df[genre] = list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove movies with null plots and ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~((df['Plot'] == 'N/A')|(df['imdbRating'] == 'N/A'))] # Drops movies with null plots\n",
    "df.imdbRating = df.imdbRating.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>ID</th>\n",
       "      <th>Plot</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Production</th>\n",
       "      <th>Director</th>\n",
       "      <th>Actor_1_name</th>\n",
       "      <th>Actor_1_fb_likes</th>\n",
       "      <th>Actor_2_name</th>\n",
       "      <th>...</th>\n",
       "      <th>History</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci_Fi</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avatar</td>\n",
       "      <td>2009</td>\n",
       "      <td>tt0499549</td>\n",
       "      <td>When his brother is killed in a robbery, parap...</td>\n",
       "      <td>Action, Adventure, Fantasy, Sci-Fi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>CCH Pounder</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Joel David Moore</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>2007</td>\n",
       "      <td>tt0449088</td>\n",
       "      <td>After Elizabeth, Will, and Captain Barbossa re...</td>\n",
       "      <td>Action, Adventure, Fantasy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gore Verbinski</td>\n",
       "      <td>Johnny Depp</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>Orlando Bloom</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spectre</td>\n",
       "      <td>2015</td>\n",
       "      <td>tt2379713</td>\n",
       "      <td>A cryptic message from the past sends James Bo...</td>\n",
       "      <td>Action, Adventure, Thriller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sam Mendes</td>\n",
       "      <td>Christoph Waltz</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>Rory Kinnear</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Title  Year         ID  \\\n",
       "0                                    Avatar  2009  tt0499549   \n",
       "1  Pirates of the Caribbean: At World's End  2007  tt0449088   \n",
       "2                                   Spectre  2015  tt2379713   \n",
       "\n",
       "                                                Plot  \\\n",
       "0  When his brother is killed in a robbery, parap...   \n",
       "1  After Elizabeth, Will, and Captain Barbossa re...   \n",
       "2  A cryptic message from the past sends James Bo...   \n",
       "\n",
       "                                Genre  Production        Director  \\\n",
       "0  Action, Adventure, Fantasy, Sci-Fi         NaN   James Cameron   \n",
       "1          Action, Adventure, Fantasy         NaN  Gore Verbinski   \n",
       "2         Action, Adventure, Thriller         NaN      Sam Mendes   \n",
       "\n",
       "      Actor_1_name  Actor_1_fb_likes      Actor_2_name   ...     History  \\\n",
       "0      CCH Pounder            1000.0  Joel David Moore   ...           0   \n",
       "1      Johnny Depp           40000.0     Orlando Bloom   ...           0   \n",
       "2  Christoph Waltz           11000.0      Rory Kinnear   ...           0   \n",
       "\n",
       "  Horror  Musical  Mystery Romance Sci_Fi  Sport  Thriller  War  Western  \n",
       "0      0        0        0       0      0      0         0    0        0  \n",
       "1      0        0        0       0      0      0         0    0        0  \n",
       "2      0        0        0       0      0      0         1    0        0  \n",
       "\n",
       "[3 rows x 37 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:3] # Our source data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Pristine and Beautiful NEW DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = df.iloc[:,-20:]\n",
    "main_df['Year'] = [int(year.split('–')[0]) for year in df['Year'].values]\n",
    "main_df = main_df.join(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Biography</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Family</th>\n",
       "      <th>...</th>\n",
       "      <th>History</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci_Fi</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Action  Adventure  Animation  Biography  Comedy  Crime  Documentary  \\\n",
       "0  2009       1          1          0          0       0      0            0   \n",
       "1  2007       1          1          0          0       0      0            0   \n",
       "2  2015       1          1          0          0       0      0            0   \n",
       "\n",
       "   Drama  Family   ...     History  Horror  Musical  Mystery  Romance  Sci_Fi  \\\n",
       "0      0       0   ...           0       0        0        0        0       0   \n",
       "1      0       0   ...           0       0        0        0        0       0   \n",
       "2      0       0   ...           0       0        0        0        0       0   \n",
       "\n",
       "   Sport  Thriller  War  Western  \n",
       "0      0         0    0        0  \n",
       "1      0         0    0        0  \n",
       "2      0         1    0        0  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11b43e240>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.plot.scatter(x='Actor_1_fb_likes',\n",
    "                    y='imdbRating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Transforming Actor Facebook Likes for use as a Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transform_col(feature, dataframe):\n",
    "    logged = pd.Series(np.log(dataframe[feature].values+1), name=feature+'_logged')\n",
    "    return logged\n",
    "\n",
    "actor_features = ['Actor_1_fb_likes', 'Actor_2_fb_likes','Actor_3_fb_likes']\n",
    "\n",
    "actor_likes = [log_transform_col(actor_features[i], df) for i in range(len(actor_features))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = main_df.join(actor_likes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df['ratings'] = df['imdbRating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Biography</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Family</th>\n",
       "      <th>...</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci_Fi</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "      <th>Actor_1_fb_likes_logged</th>\n",
       "      <th>Actor_2_fb_likes_logged</th>\n",
       "      <th>Actor_3_fb_likes_logged</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.908755</td>\n",
       "      <td>6.842683</td>\n",
       "      <td>6.752270</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.596660</td>\n",
       "      <td>8.517393</td>\n",
       "      <td>6.908755</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.305741</td>\n",
       "      <td>5.976351</td>\n",
       "      <td>5.087596</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Action  Adventure  Animation  Biography  Comedy  Crime  Documentary  \\\n",
       "0  2009       1          1          0          0       0      0            0   \n",
       "1  2007       1          1          0          0       0      0            0   \n",
       "2  2015       1          1          0          0       0      0            0   \n",
       "\n",
       "   Drama  Family   ...     Romance  Sci_Fi  Sport  Thriller  War  Western  \\\n",
       "0      0       0   ...           0       0      0         0    0        0   \n",
       "1      0       0   ...           0       0      0         0    0        0   \n",
       "2      0       0   ...           0       0      0         1    0        0   \n",
       "\n",
       "   Actor_1_fb_likes_logged  Actor_2_fb_likes_logged  Actor_3_fb_likes_logged  \\\n",
       "0                 6.908755                 6.842683                 6.752270   \n",
       "1                10.596660                 8.517393                 6.908755   \n",
       "2                 9.305741                 5.976351                 5.087596   \n",
       "\n",
       "   ratings  \n",
       "0      7.8  \n",
       "1      7.1  \n",
       "2      6.8  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorporating Natural Language Processing with Plot Synopses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up Lemmatization / Normalization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "\n",
    "def lemmatize(plot_list):\n",
    "    lemmatized_plots = []\n",
    "    for plot in plot_list:\n",
    "        tokenized_lower = word_tokenize(plot.lower())   #make plot summary all lowercase and lemmatize\n",
    "        \n",
    "        tokenized_lower =[word for word in tokenized_lower if english_d.check(word)] # Make sure it's an english word\n",
    "        \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        dirty_lemma = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in tokenized_lower]    #lemmatize each word based on part of speech\n",
    "        dirty_lemma_string = ' '.join(dirty_lemma)\n",
    "        \n",
    "        #filter for words that match regex pattern\n",
    "        reg = re.compile((r\"([a-zA-Z]+(?:'[a-z]+)?)\"))    #define regular expression pattern\n",
    "        lemmatized_regex = [word_lem for word_lem in dirty_lemma if word_lem in reg.findall(dirty_lemma_string)]\n",
    "        \n",
    "        #filter out stop words\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        lemmatized = [word_lem for word_lem in lemmatized_regex if not word_lem in stop_words]\n",
    "        lemmatized_string = ' '.join(lemmatized)\n",
    "        \n",
    "        lemmatized_plots.append(lemmatized_string)\n",
    "        \n",
    "        \n",
    "    return lemmatized_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plots = [plot for plot in df.loc[:,'Plot'].values] # Get all the plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = lemmatize(all_plots) # Lemmatize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5037, 13807)\n"
     ]
    }
   ],
   "source": [
    "#term frequency = number of times a word appears in a document / number of words in document\n",
    "#inverse document frequency = log base e(number of ducuments / number of documents with word in it)\n",
    "# tf:idf = tf * idf\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "response = tfidf.fit_transform(plots)\n",
    "print(response.shape)\n",
    "\n",
    "tfidf_df = pd.DataFrame(response.toarray(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all plots lemmatized as \"plots\" and vectorized / weighted as \"tfidf_df\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorporating some LDA - Clustering Documents by Topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried running a topic modeling algorithm over our corpus of text. \"Gensim\" clusters words that appear together frequently across several documents. The clusters can be interpreted as general themes, and each movie has weights of how much it belongs to each theme. These weights are then re-incorporated as features in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = [plot.split(' ') for plot in plots] # Just formatting our corpus how Gensim wants it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(all_words)\n",
    "corpus = [dictionary.doc2bow(text) for text in all_words]\n",
    "pickle.dump(corpus, open('corpus.pkl', 'wb'))\n",
    "dictionary.save('dictionary.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOPICS = 30 # This value was arbitrarily chosen.\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=10) # Also arb\n",
    "ldamodel.save('model5.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, '0.024*\"murder\" + 0.018*\"police\" + 0.015*\"killer\" + 0.014*\"case\"'),\n",
       " (17, '0.011*\"bond\" + 0.008*\"world\" + 0.008*\"face\" + 0.008*\"one\"'),\n",
       " (5, '0.012*\"kill\" + 0.009*\"gay\" + 0.008*\"local\" + 0.007*\"seek\"'),\n",
       " (16, '0.013*\"team\" + 0.010*\"find\" + 0.007*\"father\" + 0.007*\"game\"'),\n",
       " (11, '0.009*\"dancer\" + 0.008*\"town\" + 0.008*\"faith\" + 0.007*\"box\"'),\n",
       " (18, '0.011*\"prince\" + 0.008*\"new\" + 0.008*\"neighborhood\" + 0.008*\"school\"'),\n",
       " (19, '0.024*\"peter\" + 0.016*\"one\" + 0.016*\"story\" + 0.013*\"world\"'),\n",
       " (29, '0.009*\"murder\" + 0.009*\"show\" + 0.009*\"death\" + 0.008*\"town\"'),\n",
       " (13, '0.010*\"terry\" + 0.008*\"game\" + 0.007*\"mob\" + 0.007*\"bos\"'),\n",
       " (28, '0.015*\"new\" + 0.014*\"film\" + 0.013*\"show\" + 0.013*\"record\"'),\n",
       " (20, '0.025*\"frank\" + 0.023*\"life\" + 0.015*\"year\" + 0.011*\"old\"'),\n",
       " (25, '0.009*\"new\" + 0.008*\"victor\" + 0.007*\"night\" + 0.007*\"food\"'),\n",
       " (7, '0.019*\"friend\" + 0.017*\"school\" + 0.013*\"get\" + 0.011*\"family\"'),\n",
       " (15, '0.011*\"group\" + 0.009*\"undercover\" + 0.009*\"molly\" + 0.009*\"lesbian\"'),\n",
       " (23, '0.017*\"earth\" + 0.013*\"team\" + 0.012*\"alien\" + 0.010*\"find\"'),\n",
       " (2, '0.019*\"life\" + 0.016*\"love\" + 0.015*\"young\" + 0.015*\"mother\"'),\n",
       " (21, '0.016*\"world\" + 0.014*\"band\" + 0.014*\"rock\" + 0.012*\"become\"'),\n",
       " (12, '0.018*\"harry\" + 0.015*\"grace\" + 0.010*\"captain\" + 0.009*\"jay\"'),\n",
       " (9, '0.022*\"get\" + 0.014*\"go\" + 0.011*\"find\" + 0.009*\"make\"'),\n",
       " (22, '0.019*\"animal\" + 0.013*\"hotel\" + 0.011*\"season\" + 0.010*\"great\"')]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = ldamodel.print_topics(num_words=4)\n",
    "topics # These are examples of some of the clusters created by Gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = pd.DataFrame()\n",
    "for i in range(len(corpus)):\n",
    "    new_row = np.zeros(30)\n",
    "    for toop in ldamodel.get_document_topics(corpus[i]): # These two lines are where you do what you need to do\n",
    "        new_row[toop[0]] = toop[1]                       # to flip zeroes to ones if the genre appears\n",
    "    tm = tm.append(pd.Series(new_row), ignore_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.452292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.11327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021481</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.143831</td>\n",
       "      <td>0.164722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216339</td>\n",
       "      <td>0.028442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.254436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.12850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105058</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.065696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.48191</td>\n",
       "      <td>0.215647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2        3         4    5         6        7   \\\n",
       "0  0.000000  0.000000  0.000000  0.00000  0.000000  0.0  0.000000  0.00000   \n",
       "1  0.000000  0.000000  0.000000  0.00000  0.000000  0.0  0.000000  0.00000   \n",
       "2  0.000000  0.112485  0.000000  0.11327  0.000000  0.0  0.021481  0.00000   \n",
       "3  0.254436  0.000000  0.000000  0.12850  0.000000  0.0  0.000000  0.00000   \n",
       "4  0.000000  0.000000  0.105058  0.00000  0.065696  0.0  0.000000  0.48191   \n",
       "\n",
       "         8         9  ...    20        21   22        23        24        25  \\\n",
       "0  0.452292  0.000000 ...   0.0  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000 ...   0.0  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "2  0.143831  0.164722 ...   0.0  0.020978  0.0  0.000000  0.000000  0.216339   \n",
       "3  0.000000  0.000000 ...   0.0  0.000000  0.0  0.000000  0.099967  0.000000   \n",
       "4  0.215647  0.000000 ...   0.0  0.000000  0.0  0.115349  0.000000  0.000000   \n",
       "\n",
       "         26   27   28   29  \n",
       "0  0.137938  0.0  0.0  0.0  \n",
       "1  0.000000  0.0  0.0  0.0  \n",
       "2  0.028442  0.0  0.0  0.0  \n",
       "3  0.000000  0.0  0.0  0.0  \n",
       "4  0.000000  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.head() # This is a DataFrame with the weights from the GenSim clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining GenSim Results with Vectorized Plot Synopses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_and_topics = tfidf_df.join(tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aardvark</th>\n",
       "      <th>aback</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abate</th>\n",
       "      <th>abatement</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abdicate</th>\n",
       "      <th>abduct</th>\n",
       "      <th>abduction</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216339</td>\n",
       "      <td>0.028442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 13837 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aardvark  aback  abandon  abandonment  abate  abatement  abbey  abdicate  \\\n",
       "0       0.0    0.0      0.0          0.0    0.0        0.0    0.0       0.0   \n",
       "1       0.0    0.0      0.0          0.0    0.0        0.0    0.0       0.0   \n",
       "2       0.0    0.0      0.0          0.0    0.0        0.0    0.0       0.0   \n",
       "3       0.0    0.0      0.0          0.0    0.0        0.0    0.0       0.0   \n",
       "4       0.0    0.0      0.0          0.0    0.0        0.0    0.0       0.0   \n",
       "\n",
       "   abduct  abduction ...    20        21   22        23        24        25  \\\n",
       "0     0.0        0.0 ...   0.0  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "1     0.0        0.0 ...   0.0  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "2     0.0        0.0 ...   0.0  0.020978  0.0  0.000000  0.000000  0.216339   \n",
       "3     0.0        0.0 ...   0.0  0.000000  0.0  0.000000  0.099967  0.000000   \n",
       "4     0.0        0.0 ...   0.0  0.000000  0.0  0.115349  0.000000  0.000000   \n",
       "\n",
       "         26   27   28   29  \n",
       "0  0.137938  0.0  0.0  0.0  \n",
       "1  0.000000  0.0  0.0  0.0  \n",
       "2  0.028442  0.0  0.0  0.0  \n",
       "3  0.000000  0.0  0.0  0.0  \n",
       "4  0.000000  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 13837 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plots_and_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
