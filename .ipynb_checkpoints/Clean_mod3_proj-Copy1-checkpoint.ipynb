{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Film Plot Synopses as Predictors of Critical Reception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk import FreqDist, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import enchant\n",
    "english_d = enchant.Dict(\"en_US\")\n",
    "import re\n",
    "import gensim\n",
    "from gensim import corpora, models, similarities\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = pd.read_csv('imdb_5000_movies.csv') # Just a Kaggle dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best part of this kaggle dataset is that it provides 5k+ IMdB movie ID's, which we parse and pass to the Open Movie Database API for an even richer data set. Keys to this API cost a whole dollar. Here we parse out those IMdB ID's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_ids = [imdb.iloc[i]['movie_imdb_link'].split('title/')[1].split('/?')[0] for i in range(len(imdb))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert code into omdb api and turn each one into its own text file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we persist our API queries to files, so that we don't run into query limits and get locked out of our dataset. Our API key has been removed from this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for id in imdb_ids:\n",
    "\n",
    "#     request = requests.get(f'http://www.omdbapi.com/?i={id}&plot=full&apikey={API_KEY}').json()\n",
    "#     text = str(request)  \n",
    "    \n",
    "#     f = open(f'movie_{id}', 'w+')\n",
    "#     f.write(text)\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new dataframe with relevant columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've saved a bunch of files containing data about movies, we'll read them back into pandas in a tidy way with the features that we want to look at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty dataframe with relevant columns\n",
    "\n",
    "df = pd.DataFrame(columns=['Title', 'Year', 'ID', 'Plot', 'Genre', 'Production', \n",
    "                           'Director', 'Actor_1_name', 'Actor_1_fb_likes', 'Actor_2_name', \n",
    "                           'Actor_2_fb_likes', 'Actor_3_name', 'Actor_3_fb_likes', 'Budget', \n",
    "                           'Rated', 'Language', 'imdbRating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing from both the kaggle dataset and the OMdB API Data to populate dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(imdb_ids)):\n",
    "    id = imdb.iloc[i]['movie_imdb_link'].split('title/')[1].split('/?')[0]\n",
    "    x_file = open(os.path.join('Movies', f\"movie_{id}\"), \"r\")    #open up the movie's text file\n",
    "    movie_text = x_file.readlines()[0]\n",
    "    dict = eval(movie_text)    #turn string back to dictionary\n",
    "    dict['Plot'] = dict['Plot'].replace(\"\\'\", \"'\")    #clean up\n",
    "    df = df.append({'Title': dict['Title'], 'Year': dict['Year'], 'ID': id, \n",
    "                    'Plot': dict['Plot'], 'Genre': dict['Genre'], \n",
    "                    'imdbRating': dict['imdbRating'], \n",
    "                    'Director': imdb.iloc[i,:].loc['director_name'], \n",
    "                    'Actor_1_name':imdb.iloc[i,:].loc['actor_1_name'], \n",
    "                    'Actor_1_fb_likes':imdb.iloc[i,:].loc['actor_1_facebook_likes'], \n",
    "                    'Actor_2_name':imdb.iloc[i,:].loc['actor_2_name'], \n",
    "                    'Actor_2_fb_likes':imdb.iloc[i,:].loc['actor_2_facebook_likes'], \n",
    "                    'Actor_3_name':imdb.iloc[i,:].loc['actor_3_name'], \n",
    "                    'Actor_3_fb_likes':imdb.iloc[i,:].loc['actor_3_facebook_likes'], \n",
    "                    'Budget':imdb.iloc[i,:].loc['budget'], 'Language':dict['Language'], \n",
    "                    'Rated':dict['Rated']}, ignore_index=True)    #add to dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove movies with null plots and ratings, convert ratings into binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the instances with null 'imdbRating', since that is our target variable. We then change this column into 'binary_target' which tells whether or not the 'imdbRating' is above the mean.\n",
    "\n",
    "The number of instances with null 'Plot' was minimal, and therefore we could remove them from our dataframe without losing much data.\n",
    "\n",
    "Lastly, we replaced null values from the 'actor facebook likes' with the column's mean number of likes, rather than replacing them with zero or dropping the instances altogether. This allows us to do a log transformation on these features later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~((df['Plot'] == 'N/A')|(df['imdbRating'] == 'N/A'))] # Drops movies with null plots\n",
    "df.imdbRating = df.imdbRating.astype(float)\n",
    "df['binary_target'] = df['imdbRating'] >= df['imdbRating'].mean()   #binary target column. True = above mean ; False = below mean\n",
    "df['binary_target'] = df['binary_target'].astype(int)\n",
    "df['Actor_1_fb_likes'].fillna((df['Actor_1_fb_likes'].mean()), inplace=True)\n",
    "df['Actor_2_fb_likes'].fillna((df['Actor_2_fb_likes'].mean()), inplace=True)\n",
    "df['Actor_3_fb_likes'].fillna((df['Actor_3_fb_likes'].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>ID</th>\n",
       "      <th>Plot</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Production</th>\n",
       "      <th>Director</th>\n",
       "      <th>Actor_1_name</th>\n",
       "      <th>Actor_1_fb_likes</th>\n",
       "      <th>Actor_2_name</th>\n",
       "      <th>Actor_2_fb_likes</th>\n",
       "      <th>Actor_3_name</th>\n",
       "      <th>Actor_3_fb_likes</th>\n",
       "      <th>Budget</th>\n",
       "      <th>Rated</th>\n",
       "      <th>Language</th>\n",
       "      <th>imdbRating</th>\n",
       "      <th>binary_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avatar</td>\n",
       "      <td>2009</td>\n",
       "      <td>tt0499549</td>\n",
       "      <td>When his brother is killed in a robbery, parap...</td>\n",
       "      <td>Action, Adventure, Fantasy, Sci-Fi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>CCH Pounder</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Joel David Moore</td>\n",
       "      <td>936.0</td>\n",
       "      <td>Wes Studi</td>\n",
       "      <td>855.0</td>\n",
       "      <td>237000000.0</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>English, Spanish</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>2007</td>\n",
       "      <td>tt0449088</td>\n",
       "      <td>After Elizabeth, Will, and Captain Barbossa re...</td>\n",
       "      <td>Action, Adventure, Fantasy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gore Verbinski</td>\n",
       "      <td>Johnny Depp</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>Orlando Bloom</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>Jack Davenport</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>300000000.0</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>English</td>\n",
       "      <td>7.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spectre</td>\n",
       "      <td>2015</td>\n",
       "      <td>tt2379713</td>\n",
       "      <td>A cryptic message from the past sends James Bo...</td>\n",
       "      <td>Action, Adventure, Thriller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sam Mendes</td>\n",
       "      <td>Christoph Waltz</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>Rory Kinnear</td>\n",
       "      <td>393.0</td>\n",
       "      <td>Stephanie Sigman</td>\n",
       "      <td>161.0</td>\n",
       "      <td>245000000.0</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>English, Spanish, Italian, German, French</td>\n",
       "      <td>6.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Title  Year         ID  \\\n",
       "0                                    Avatar  2009  tt0499549   \n",
       "1  Pirates of the Caribbean: At World's End  2007  tt0449088   \n",
       "2                                   Spectre  2015  tt2379713   \n",
       "\n",
       "                                                Plot  \\\n",
       "0  When his brother is killed in a robbery, parap...   \n",
       "1  After Elizabeth, Will, and Captain Barbossa re...   \n",
       "2  A cryptic message from the past sends James Bo...   \n",
       "\n",
       "                                Genre  Production        Director  \\\n",
       "0  Action, Adventure, Fantasy, Sci-Fi         NaN   James Cameron   \n",
       "1          Action, Adventure, Fantasy         NaN  Gore Verbinski   \n",
       "2         Action, Adventure, Thriller         NaN      Sam Mendes   \n",
       "\n",
       "      Actor_1_name  Actor_1_fb_likes      Actor_2_name  Actor_2_fb_likes  \\\n",
       "0      CCH Pounder            1000.0  Joel David Moore             936.0   \n",
       "1      Johnny Depp           40000.0     Orlando Bloom            5000.0   \n",
       "2  Christoph Waltz           11000.0      Rory Kinnear             393.0   \n",
       "\n",
       "       Actor_3_name  Actor_3_fb_likes       Budget  Rated  \\\n",
       "0         Wes Studi             855.0  237000000.0  PG-13   \n",
       "1    Jack Davenport            1000.0  300000000.0  PG-13   \n",
       "2  Stephanie Sigman             161.0  245000000.0  PG-13   \n",
       "\n",
       "                                    Language  imdbRating  binary_target  \n",
       "0                           English, Spanish         7.8              1  \n",
       "1                                    English         7.1              1  \n",
       "2  English, Spanish, Italian, German, French         6.8              1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reset indices\n",
    "df = df.reset_index()\n",
    "df = df.drop(['index'], axis=1)\n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing out Genres as one-hot Columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_genres = ['Action', 'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy', 'History', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci_Fi', 'Sport', 'Thriller', 'War', 'Western']    \n",
    "\n",
    "#create a list of lists, where each element is a list of a movie's classified genres\n",
    "li = []\n",
    "[li.append(df.iloc[i]['Genre'].split(', ')) for i in range(len(df))]\n",
    "\n",
    "#adding columns to df for each genre, 1 represents the movie is classified under that genre, 0 is that it is not\n",
    "for genre in final_genres:\n",
    "    list = []\n",
    "    [list.append(1) if genre in movie\n",
    "    else list.append(0) for movie in li]\n",
    "    df[genre] = list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a fresh DataFrame with Just the Features we Want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = df.iloc[:,-21:]\n",
    "main_df['Year'] = [int(year.split('–')[0]) for year in df['Year'].values]\n",
    "main_df = main_df.join(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>binary_target</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Biography</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>...</th>\n",
       "      <th>History</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci_Fi</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  binary_target  Action  Adventure  Animation  Biography  Comedy  \\\n",
       "0  2009              1       1          1          0          0       0   \n",
       "1  2007              1       1          1          0          0       0   \n",
       "2  2015              1       1          1          0          0       0   \n",
       "\n",
       "   Crime  Documentary  Drama   ...     History  Horror  Musical  Mystery  \\\n",
       "0      0            0      0   ...           0       0        0        0   \n",
       "1      0            0      0   ...           0       0        0        0   \n",
       "2      0            0      0   ...           0       0        0        0   \n",
       "\n",
       "   Romance  Sci_Fi  Sport  Thriller  War  Western  \n",
       "0        0       0      0         0    0        0  \n",
       "1        0       0      0         0    0        0  \n",
       "2        0       0      0         1    0        0  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1f42cfd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.plot.scatter(x='Actor_1_fb_likes',\n",
    "                    y='imdbRating') # Just spotting some outliers...this prompted us to log transform fb_likes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Transforming Actor Facebook Likes for use as a Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transform_col(feature, dataframe):\n",
    "    logged = pd.Series(np.log(dataframe[feature].values+1), name=feature+'_logged')\n",
    "    return logged\n",
    "\n",
    "actor_features = ['Actor_1_fb_likes', 'Actor_2_fb_likes','Actor_3_fb_likes']\n",
    "\n",
    "actor_likes = [log_transform_col(actor_features[i], df) for i in range(len(actor_features))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1f6b0b70>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(actor_likes).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = main_df.join(actor_likes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>binary_target</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Biography</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>...</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci_Fi</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "      <th>Actor_1_fb_likes_logged</th>\n",
       "      <th>Actor_2_fb_likes_logged</th>\n",
       "      <th>Actor_3_fb_likes_logged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.908755</td>\n",
       "      <td>6.842683</td>\n",
       "      <td>6.752270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.596660</td>\n",
       "      <td>8.517393</td>\n",
       "      <td>6.908755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.305741</td>\n",
       "      <td>5.976351</td>\n",
       "      <td>5.087596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  binary_target  Action  Adventure  Animation  Biography  Comedy  \\\n",
       "0  2009              1       1          1          0          0       0   \n",
       "1  2007              1       1          1          0          0       0   \n",
       "2  2015              1       1          1          0          0       0   \n",
       "\n",
       "   Crime  Documentary  Drama           ...             Mystery  Romance  \\\n",
       "0      0            0      0           ...                   0        0   \n",
       "1      0            0      0           ...                   0        0   \n",
       "2      0            0      0           ...                   0        0   \n",
       "\n",
       "   Sci_Fi  Sport  Thriller  War  Western  Actor_1_fb_likes_logged  \\\n",
       "0       0      0         0    0        0                 6.908755   \n",
       "1       0      0         0    0        0                10.596660   \n",
       "2       0      0         1    0        0                 9.305741   \n",
       "\n",
       "   Actor_2_fb_likes_logged  Actor_3_fb_likes_logged  \n",
       "0                 6.842683                 6.752270  \n",
       "1                 8.517393                 6.908755  \n",
       "2                 5.976351                 5.087596  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorporating Natural Language Processing with Plot Synopses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up Lemmatization / Normalization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "\n",
    "def lemmatize(plot_list):\n",
    "    lemmatized_plots = []\n",
    "    for plot in plot_list:\n",
    "        tokenized_lower = word_tokenize(plot.lower())   #make plot summary all lowercase and lemmatize\n",
    "        \n",
    "        tokenized_lower =[word for word in tokenized_lower if english_d.check(word)] # Make sure it's an english word\n",
    "        \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        dirty_lemma = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in tokenized_lower]    #lemmatize each word based on part of speech\n",
    "        dirty_lemma_string = ' '.join(dirty_lemma)\n",
    "        \n",
    "        #filter for words that match regex pattern\n",
    "        reg = re.compile((r\"([a-zA-Z]+(?:'[a-z]+)?)\"))    #define regular expression pattern\n",
    "        lemmatized_regex = [word_lem for word_lem in dirty_lemma if word_lem in reg.findall(dirty_lemma_string)]\n",
    "        \n",
    "        #filter out stop words\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        lemmatized = [word_lem for word_lem in lemmatized_regex if not word_lem in stop_words]\n",
    "        lemmatized_string = ' '.join(lemmatized)\n",
    "        \n",
    "        lemmatized_plots.append(lemmatized_string)\n",
    "        \n",
    "        \n",
    "    return lemmatized_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plots = [plot for plot in df.loc[:,'Plot'].values] # Get all the plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = lemmatize(all_plots) # Lemmatize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5037, 13807)\n"
     ]
    }
   ],
   "source": [
    "#term frequency = number of times a word appears in a document / number of words in document\n",
    "#inverse document frequency = log base e(number of ducuments / number of documents with word in it)\n",
    "# tf:idf = tf * idf\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "response = tfidf.fit_transform(plots)\n",
    "print(response.shape)\n",
    "\n",
    "tfidf_df = pd.DataFrame(response.toarray(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all plots lemmatized as \"plots\" and vectorized / weighted as \"tfidf_df\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorporating some LDA - Clustering Documents by Topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried running a topic modeling algorithm over our corpus of text. \"Gensim\" clusters words that appear together frequently across several documents. The clusters can be interpreted as general themes, and each movie has weights of how much it belongs to each theme. These weights are then re-incorporated as features in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = [plot.split(' ') for plot in plots] # Just formatting our corpus how Gensim wants it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(all_words)\n",
    "corpus = [dictionary.doc2bow(text) for text in all_words]\n",
    "pickle.dump(corpus, open('corpus.pkl', 'wb'))\n",
    "dictionary.save('dictionary.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOPICS = 30 # This value was arbitrarily chosen.\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=10) # Also arb\n",
    "ldamodel.save('model5.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(16, '0.023*\"film\" + 0.022*\"peter\" + 0.020*\"movie\" + 0.008*\"one\"'),\n",
       " (9, '0.010*\"find\" + 0.010*\"town\" + 0.008*\"make\" + 0.008*\"small\"'),\n",
       " (22, '0.014*\"group\" + 0.011*\"terry\" + 0.010*\"team\" + 0.008*\"new\"'),\n",
       " (29, '0.014*\"story\" + 0.009*\"god\" + 0.009*\"president\" + 0.007*\"series\"'),\n",
       " (8, '0.014*\"world\" + 0.012*\"must\" + 0.011*\"evil\" + 0.010*\"fight\"'),\n",
       " (20, '0.017*\"band\" + 0.015*\"story\" + 0.012*\"film\" + 0.012*\"life\"'),\n",
       " (11, '0.018*\"life\" + 0.016*\"father\" + 0.011*\"mother\" + 0.010*\"story\"'),\n",
       " (7, '0.016*\"vampire\" + 0.013*\"find\" + 0.011*\"world\" + 0.011*\"force\"'),\n",
       " (27, '0.017*\"jack\" + 0.012*\"find\" + 0.011*\"man\" + 0.011*\"family\"'),\n",
       " (2, '0.020*\"tom\" + 0.011*\"record\" + 0.010*\"worker\" + 0.009*\"industry\"'),\n",
       " (0, '0.022*\"mike\" + 0.012*\"josh\" + 0.011*\"experiment\" + 0.007*\"new\"'),\n",
       " (6, '0.012*\"john\" + 0.009*\"prince\" + 0.008*\"ape\" + 0.007*\"tree\"'),\n",
       " (28, '0.010*\"john\" + 0.008*\"island\" + 0.007*\"agent\" + 0.006*\"help\"'),\n",
       " (26, '0.012*\"one\" + 0.010*\"life\" + 0.010*\"men\" + 0.009*\"war\"'),\n",
       " (4, '0.013*\"get\" + 0.012*\"woman\" + 0.011*\"find\" + 0.010*\"friend\"'),\n",
       " (1, '0.024*\"family\" + 0.015*\"son\" + 0.012*\"father\" + 0.010*\"friend\"'),\n",
       " (5, '0.016*\"laura\" + 0.014*\"ed\" + 0.010*\"roger\" + 0.009*\"new\"'),\n",
       " (24, '0.010*\"find\" + 0.010*\"documentary\" + 0.009*\"year\" + 0.008*\"begin\"'),\n",
       " (10, '0.022*\"life\" + 0.016*\"get\" + 0.015*\"love\" + 0.012*\"go\"'),\n",
       " (18, '0.026*\"earth\" + 0.024*\"alien\" + 0.014*\"planet\" + 0.009*\"dean\"')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = ldamodel.print_topics(num_words=4)\n",
    "topics # These are examples of some of the clusters created by Gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = pd.DataFrame()\n",
    "for i in range(len(corpus)):\n",
    "    new_row = np.zeros(30)\n",
    "    for toop in ldamodel.get_document_topics(corpus[i]): # These two lines are where you do what you need to do\n",
    "        new_row[toop[0]] = toop[1]                       # to flip zeroes to ones if the genre appears\n",
    "    tm = tm.append(pd.Series(new_row), ignore_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016093</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285199</td>\n",
       "      <td>0.283400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020973</td>\n",
       "      <td>0.063694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.101305</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106829</td>\n",
       "      <td>0.180622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.244995</td>\n",
       "      <td>0.046094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.356960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.316144</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.829319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.30184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252577</td>\n",
       "      <td>0.244878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163114</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1    2         3    4    5    6         7         8    9   \\\n",
       "0  0.016093  0.00000  0.0  0.000000  0.0  0.0  0.0  0.285199  0.283400  0.0   \n",
       "1  0.101305  0.00000  0.0  0.000000  0.0  0.0  0.0  0.106829  0.180622  0.0   \n",
       "2  0.000000  0.00000  0.0  0.000000  0.0  0.0  0.0  0.000000  0.356960  0.0   \n",
       "3  0.000000  0.00000  0.0  0.829319  0.0  0.0  0.0  0.000000  0.133348  0.0   \n",
       "4  0.000000  0.30184  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  0.0   \n",
       "\n",
       "  ...         20        21        22   23   24   25        26        27  \\\n",
       "0 ...   0.020973  0.063694  0.000000  0.0  0.0  0.0  0.000000  0.000000   \n",
       "1 ...   0.000000  0.000000  0.023408  0.0  0.0  0.0  0.244995  0.046094   \n",
       "2 ...   0.000000  0.045466  0.000000  0.0  0.0  0.0  0.000000  0.000000   \n",
       "3 ...   0.000000  0.000000  0.000000  0.0  0.0  0.0  0.000000  0.000000   \n",
       "4 ...   0.000000  0.252577  0.244878  0.0  0.0  0.0  0.000000  0.000000   \n",
       "\n",
       "         28   29  \n",
       "0  0.000000  0.0  \n",
       "1  0.000000  0.0  \n",
       "2  0.316144  0.0  \n",
       "3  0.000000  0.0  \n",
       "4  0.163114  0.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.head() # This is a DataFrame with the weights from the GenSim clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining GenSim Results with Vectorized Plot Synopses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_and_topics = tfidf_df.join(tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aardvark</th>\n",
       "      <th>aback</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abate</th>\n",
       "      <th>abatement</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abdicate</th>\n",
       "      <th>abduct</th>\n",
       "      <th>abduction</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020973</td>\n",
       "      <td>0.063694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.244995</td>\n",
       "      <td>0.046094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.316144</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252577</td>\n",
       "      <td>0.244878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163114</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 13837 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aardvark  aback  abandon  abandonment  abate  abatement  abbey  abdicate  \\\n",
       "0       0.0    0.0      0.0          0.0    0.0        0.0    0.0       0.0   \n",
       "1       0.0    0.0      0.0          0.0    0.0        0.0    0.0       0.0   \n",
       "2       0.0    0.0      0.0          0.0    0.0        0.0    0.0       0.0   \n",
       "3       0.0    0.0      0.0          0.0    0.0        0.0    0.0       0.0   \n",
       "4       0.0    0.0      0.0          0.0    0.0        0.0    0.0       0.0   \n",
       "\n",
       "   abduct  abduction ...         20        21        22   23   24   25  \\\n",
       "0     0.0        0.0 ...   0.020973  0.063694  0.000000  0.0  0.0  0.0   \n",
       "1     0.0        0.0 ...   0.000000  0.000000  0.023408  0.0  0.0  0.0   \n",
       "2     0.0        0.0 ...   0.000000  0.045466  0.000000  0.0  0.0  0.0   \n",
       "3     0.0        0.0 ...   0.000000  0.000000  0.000000  0.0  0.0  0.0   \n",
       "4     0.0        0.0 ...   0.000000  0.252577  0.244878  0.0  0.0  0.0   \n",
       "\n",
       "         26        27        28   29  \n",
       "0  0.000000  0.000000  0.000000  0.0  \n",
       "1  0.244995  0.046094  0.000000  0.0  \n",
       "2  0.000000  0.000000  0.316144  0.0  \n",
       "3  0.000000  0.000000  0.000000  0.0  \n",
       "4  0.000000  0.000000  0.163114  0.0  \n",
       "\n",
       "[5 rows x 13837 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plots_and_topics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA with Non-PlotText Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as sm\n",
    "from patsy import dmatrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.588562\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:          binary_target   No. Observations:                 4029\n",
      "Model:                          Logit   Df Residuals:                     4005\n",
      "Method:                           MLE   Df Model:                           23\n",
      "Date:                Wed, 09 Jan 2019   Pseudo R-squ.:                  0.1485\n",
      "Time:                        01:10:33   Log-Likelihood:                -2371.3\n",
      "converged:                       True   LL-Null:                       -2784.7\n",
      "                                        LLR p-value:                7.246e-160\n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "Intercept                  85.6656      6.990     12.255      0.000      71.965      99.367\n",
      "C(Action)[T.1]             -0.3644      0.099     -3.671      0.000      -0.559      -0.170\n",
      "C(Adventure)[T.1]           0.0709      0.109      0.650      0.516      -0.143       0.285\n",
      "C(Animation)[T.1]           1.2592      0.202      6.242      0.000       0.864       1.655\n",
      "C(Biography)[T.1]           1.2190      0.211      5.775      0.000       0.805       1.633\n",
      "C(Comedy)[T.1]             -0.5765      0.089     -6.494      0.000      -0.750      -0.402\n",
      "C(Crime)[T.1]              -0.0173      0.101     -0.171      0.864      -0.215       0.181\n",
      "C(Documentary)[T.1]         2.1884      0.336      6.511      0.000       1.530       2.847\n",
      "C(Drama)[T.1]               0.8694      0.085     10.178      0.000       0.702       1.037\n",
      "C(Family)[T.1]             -0.5333      0.146     -3.655      0.000      -0.819      -0.247\n",
      "C(Fantasy)[T.1]            -0.0419      0.118     -0.354      0.723      -0.274       0.190\n",
      "C(History)[T.1]             0.0461      0.213      0.217      0.828      -0.371       0.463\n",
      "C(Horror)[T.1]             -0.9116      0.132     -6.889      0.000      -1.171      -0.652\n",
      "C(Musical)[T.1]            -0.0695      0.237     -0.294      0.769      -0.534       0.395\n",
      "C(Mystery)[T.1]             0.1778      0.122      1.460      0.144      -0.061       0.417\n",
      "C(Romance)[T.1]            -0.2442      0.092     -2.643      0.008      -0.425      -0.063\n",
      "C(Sport)[T.1]              -0.0697      0.212     -0.329      0.742      -0.485       0.345\n",
      "C(Thriller)[T.1]           -0.2650      0.098     -2.694      0.007      -0.458      -0.072\n",
      "C(War)[T.1]                -0.0415      0.204     -0.203      0.839      -0.442       0.359\n",
      "C(Western)[T.1]            -0.1854      0.279     -0.665      0.506      -0.732       0.361\n",
      "Year                       -0.0430      0.003    -12.290      0.000      -0.050      -0.036\n",
      "Actor_1_fb_likes_logged     0.1678      0.029      5.782      0.000       0.111       0.225\n",
      "Actor_2_fb_likes_logged     0.0445      0.049      0.911      0.362      -0.051       0.140\n",
      "Actor_3_fb_likes_logged    -0.1697      0.045     -3.770      0.000      -0.258      -0.081\n",
      "===========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6865079365079365"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check LogReg with all initial variables from main_df (note: no plot)\n",
    "s = (\"binary_target ~ Year + C(Action) + C(Adventure) + C(Animation) + C(Biography) + C(Comedy)\"\n",
    "                 \"+ C(Crime) + C(Documentary) + C(Drama) + C(Family) + C(Fantasy) + C(History)\"\n",
    "                 \"+ C(Horror) + C(Musical) + C(Mystery) + C(Romance) + C(Sci_Fi) + C(Sport)\"\n",
    "                 \"+ C(Thriller) + C(War)+ C(Western)\"\n",
    "                 \"+ Actor_1_fb_likes_logged + Actor_2_fb_likes_logged\"\n",
    "                 \"+ Actor_3_fb_likes_logged\")\n",
    "\n",
    "y, X = dmatrices(s, main_df, return_type=\"dataframe\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =  0.2, random_state=16)\n",
    "\n",
    "logit_model = sm.Logit(y_train.iloc[:,0], X_train)\n",
    "result = logit_model.fit()\n",
    "\n",
    "print(result.summary())\n",
    "\n",
    "y_preds = result.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_preds >=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.588716\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:          binary_target   No. Observations:                 4029\n",
      "Model:                          Logit   Df Residuals:                     4013\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Wed, 09 Jan 2019   Pseudo R-squ.:                  0.1482\n",
      "Time:                        01:10:33   Log-Likelihood:                -2371.9\n",
      "converged:                       True   LL-Null:                       -2784.7\n",
      "                                        LLR p-value:                2.871e-166\n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "Intercept                  85.2044      6.931     12.293      0.000      71.620      98.789\n",
      "C(Action)[T.1]             -0.3500      0.095     -3.694      0.000      -0.536      -0.164\n",
      "C(Animation)[T.1]           1.2745      0.197      6.485      0.000       0.889       1.660\n",
      "C(Biography)[T.1]           1.2191      0.205      5.950      0.000       0.818       1.621\n",
      "C(Comedy)[T.1]             -0.5794      0.087     -6.683      0.000      -0.749      -0.409\n",
      "C(Documentary)[T.1]         2.1816      0.335      6.511      0.000       1.525       2.838\n",
      "C(Drama)[T.1]               0.8606      0.083     10.339      0.000       0.697       1.024\n",
      "C(Family)[T.1]             -0.5277      0.139     -3.787      0.000      -0.801      -0.255\n",
      "C(Horror)[T.1]             -0.9153      0.128     -7.163      0.000      -1.166      -0.665\n",
      "C(Mystery)[T.1]             0.1768      0.121      1.456      0.145      -0.061       0.415\n",
      "C(Romance)[T.1]            -0.2454      0.091     -2.700      0.007      -0.424      -0.067\n",
      "C(Thriller)[T.1]           -0.2666      0.093     -2.855      0.004      -0.450      -0.084\n",
      "Year                       -0.0428      0.003    -12.324      0.000      -0.050      -0.036\n",
      "Actor_1_fb_likes_logged     0.1671      0.029      5.782      0.000       0.110       0.224\n",
      "Actor_2_fb_likes_logged     0.0453      0.049      0.929      0.353      -0.050       0.141\n",
      "Actor_3_fb_likes_logged    -0.1701      0.045     -3.785      0.000      -0.258      -0.082\n",
      "===========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6884920634920635"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rerun LogReg by dropping the features with high p_values in the prior model (see above)\n",
    "\n",
    "s = (\"binary_target ~ Year + C(Action) + C(Animation) + C(Biography) + C(Comedy)\"\n",
    "                 \"+ C(Documentary) + C(Drama) + C(Family)\"\n",
    "                 \"+ C(Horror) + C(Mystery) + C(Romance)\"\n",
    "                 \"+ C(Thriller)\"\n",
    "                 \"+ Actor_1_fb_likes_logged + Actor_2_fb_likes_logged\"\n",
    "                 \"+ Actor_3_fb_likes_logged\")\n",
    "\n",
    "main_df = main_df.drop(['Adventure','Crime', 'Fantasy', 'History', 'Musical', 'Sport', 'Sci_Fi', 'War', 'Western'], axis=1)\n",
    "\n",
    "y, X = dmatrices(s, main_df, return_type = \"dataframe\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =  0.2, random_state=16)\n",
    "\n",
    "logit_model = sm.Logit(y_train.iloc[:,0], X_train)\n",
    "result = logit_model.fit()\n",
    "\n",
    "print(result.summary())\n",
    "\n",
    "y_preds = result.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_preds >=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'binary_target', 'Action', 'Animation', 'Biography', 'Comedy',\n",
       "       'Documentary', 'Drama', 'Family', 'Horror', 'Mystery', 'Romance',\n",
       "       'Thriller', 'Actor_1_fb_likes_logged', 'Actor_2_fb_likes_logged',\n",
       "       'Actor_3_fb_likes_logged'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction with SVD - For the PlotText Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3184693417836064\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "svd = TruncatedSVD(n_components=100, n_iter=7, random_state=42)\n",
    "plots_and_topics_pca = svd.fit_transform(plots_and_topics)\n",
    "\n",
    "print(svd.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes with Combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join PlotText df and Main df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Action</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Biography</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Family</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031868</td>\n",
       "      <td>-0.013702</td>\n",
       "      <td>-0.018704</td>\n",
       "      <td>0.007021</td>\n",
       "      <td>-0.001472</td>\n",
       "      <td>-0.014822</td>\n",
       "      <td>-0.012285</td>\n",
       "      <td>0.031899</td>\n",
       "      <td>-0.015287</td>\n",
       "      <td>-0.011133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055456</td>\n",
       "      <td>0.021718</td>\n",
       "      <td>0.061123</td>\n",
       "      <td>-0.021143</td>\n",
       "      <td>0.016467</td>\n",
       "      <td>-0.031610</td>\n",
       "      <td>0.019755</td>\n",
       "      <td>0.044241</td>\n",
       "      <td>-0.012800</td>\n",
       "      <td>0.029889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002617</td>\n",
       "      <td>-0.067944</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>0.033377</td>\n",
       "      <td>-0.053967</td>\n",
       "      <td>0.053528</td>\n",
       "      <td>0.010369</td>\n",
       "      <td>-0.059243</td>\n",
       "      <td>0.063813</td>\n",
       "      <td>-0.046544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028491</td>\n",
       "      <td>-0.068285</td>\n",
       "      <td>0.013205</td>\n",
       "      <td>-0.000515</td>\n",
       "      <td>0.007019</td>\n",
       "      <td>-0.001956</td>\n",
       "      <td>-0.020606</td>\n",
       "      <td>0.020140</td>\n",
       "      <td>-0.019680</td>\n",
       "      <td>-0.007501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056174</td>\n",
       "      <td>-0.005917</td>\n",
       "      <td>0.039041</td>\n",
       "      <td>-0.023314</td>\n",
       "      <td>-0.009599</td>\n",
       "      <td>0.030880</td>\n",
       "      <td>-0.026250</td>\n",
       "      <td>-0.015174</td>\n",
       "      <td>0.050497</td>\n",
       "      <td>-0.019625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Action  Animation  Biography  Comedy  Documentary  Drama  Family  \\\n",
       "0  2009       1          0          0       0            0      0       0   \n",
       "1  2007       1          0          0       0            0      0       0   \n",
       "2  2015       1          0          0       0            0      0       0   \n",
       "3  2012       1          0          0       0            0      0       0   \n",
       "4  2012       1          0          0       0            0      0       0   \n",
       "\n",
       "   Horror  Mystery    ...           90        91        92        93  \\\n",
       "0       0        0    ...     0.031868 -0.013702 -0.018704  0.007021   \n",
       "1       0        0    ...     0.055456  0.021718  0.061123 -0.021143   \n",
       "2       0        0    ...    -0.002617 -0.067944 -0.000018  0.033377   \n",
       "3       0        0    ...    -0.028491 -0.068285  0.013205 -0.000515   \n",
       "4       0        0    ...     0.056174 -0.005917  0.039041 -0.023314   \n",
       "\n",
       "         94        95        96        97        98        99  \n",
       "0 -0.001472 -0.014822 -0.012285  0.031899 -0.015287 -0.011133  \n",
       "1  0.016467 -0.031610  0.019755  0.044241 -0.012800  0.029889  \n",
       "2 -0.053967  0.053528  0.010369 -0.059243  0.063813 -0.046544  \n",
       "3  0.007019 -0.001956 -0.020606  0.020140 -0.019680 -0.007501  \n",
       "4 -0.009599  0.030880 -0.026250 -0.015174  0.050497 -0.019625  \n",
       "\n",
       "[5 rows x 116 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = main_df.join(pd.DataFrame(plots_and_topics_pca))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['binary_target'], axis=1)\n",
    "y = df['binary_target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.81      0.68       469\n",
      "           1       0.75      0.50      0.60       539\n",
      "\n",
      "   micro avg       0.64      0.64      0.64      1008\n",
      "   macro avg       0.67      0.65      0.64      1008\n",
      "weighted avg       0.67      0.64      0.64      1008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = clf.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA with Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9997881267765231\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "svd = TruncatedSVD(n_components=84, n_iter=50, random_state=42)\n",
    "X_train_pca = svd.fit_transform(X_train)\n",
    "\n",
    "print(svd.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-ddb2935439cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'grid_clf' is not defined"
     ]
    }
   ],
   "source": [
    "# grid_clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reduce_dim': TruncatedSVD(algorithm='randomized', n_components=10, n_iter=7,\n",
       "        random_state=None, tol=0.0),\n",
       " 'reduce_dim__n_components': 10,\n",
       " 'reduce_dim__n_iter': 7}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('reduce_dim', TruncatedSVD()),\n",
    "    ('classify', GradientBoostingClassifier())  \n",
    "])\n",
    "score = {'f1': 'f1', 'accuracy': 'accuracy'}\n",
    "N_FEATURES_OPTIONS = [10, 7, 13, 15, 14]\n",
    "itera = [3, 5, 7]\n",
    "# max_dep = [3,4,5,6]\n",
    "# n_est = [50,80,100, 120, 150]\n",
    "# min_samp = [4,5,6,10]\n",
    "param_grid = [\n",
    "    {\n",
    "        'reduce_dim': [TruncatedSVD()],\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "        'reduce_dim__n_iter': itera\n",
    "#         'classify__n_estimators': n_est,\n",
    "#         'classify__max_depth': max_dep,\n",
    "#         'classify__min_samples_split':min_samp\n",
    "    }]\n",
    "reducer_labels = ['TruncatedSVD']\n",
    "\n",
    "grid_adc = GridSearchCV(pipe, cv=5, n_jobs=-1, param_grid=param_grid, scoring=score, refit='accuracy')\n",
    "grid_adc.fit(X_train, y_train)\n",
    "grid_adc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6746031746031746"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = grid_adc.predict(X_test)\n",
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier(n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "training_preds = clf.predict(X_train)\n",
    "test_preds = clf.predict(X_test)\n",
    "\n",
    "training_accuracy = accuracy_score(y_train, training_preds)\n",
    "test_accuracy = accuracy_score(y_test, test_preds)\n",
    "\n",
    "print(\"Training Accuracy: {:.4}%\".format(training_accuracy * 100))\n",
    "print(\"Test accuracy: {:.4}%\".format(test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style='ticks', color_codes=True)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'main_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-731cc8de538a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Creating multi-scatter plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmain_corr\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'binary_target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_corr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'main_df' is not defined"
     ]
    }
   ],
   "source": [
    "#Creating multi-scatter plot\n",
    "main_corr= main_df.drop(['binary_target'], axis=1).iloc[:,:]\n",
    "pd.plotting.scatter_matrix(main_corr, figsize=[15,15]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set correlation above 0.75 and see true/false values\n",
    "abs(main_corr.corr())> 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can see that the greatest collinearity is between the actor media presence\n",
    "sns.heatmap(main_corr.corr(), center=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
